---
title: "Hands-on Exercise 5: Global and Local Measures of Spatial Autocorrelation"
#description: "ddd"
author: "Teo Ren Jie"
date: "2/18/2023"
categories: ["Hands-on Exercise", "sf", "tmap", "maptools", "spatstat", "raster"]
title-block-banner: true
#image: Hands-on_Ex05/preview.png
execute:
  message: false
  warning: false
---

# Getting Started

## Overview

In this hands-on exercise, you will learn how to compute Global and Local Measure of Spatial Autocorrelation (GLSA) by using **spdep** package. By the end to this hands-on exercise, you will be able to:

-   import geospatial data using appropriate function(s) of **sf** package,

-   import csv file using appropriate function of **readr** package,

-   perform relational join using appropriate join function of **dplyr** package,

-   compute Global Spatial Autocorrelation (GSA) statistics by using appropriate functions of **spdep** package,

    -   plot Moran scatterplot,

    -   compute and plot spatial correlogram using appropriate function of **spdep** package.

-   compute Local Indicator of Spatial Association (LISA) statistics for
    detecting clusters and outliers by using appropriate functions **spdep** package;

-   compute Getis-Ord\'s Gi-statistics for detecting hot spot or/and cold spot area by using appropriate functions of **spdep** package; and

-   to visualise the analysis output by using **tmap** package.

## Research Questions

In spatial policy, one of the main development objective of the local government and planners is to ensure equal distribution of development in the province. Our task in this study, hence, is to apply appropriate spatial statistical methods to discover if development are even distributed geographically. If the answer is **No**. Then, our next question will be \"is there sign of spatial clustering?\". And, if the answer for this question is yes, then our next question will be \"where are these clusters?\"

In this case study, we are interested to examine the spatial pattern of a selected development indicator (i.e. GDP per capita) of Hunan Provice, People Republic of China.(https://en.wikipedia.org/wiki/Hunan)

## Installing and Loading Packages

Pacman assists us by helping us load R packages that we require, `sf`, `sfdep`, `tmap` and `tidyverse`.

```{r}
pacman::p_load(sf, sfdep, tmap, tidyverse)
```

The following packages assists us to accomplish the following:

-   *sfdep* helps to compute spatial weights, global and local spatial autocorrelation statistics

-   *tmap* provides functions to allow us to plot high quality static or interactive maps using leaflet API

## Data Acquisition

The following datasets are used:

| Dataset Name                  | Source   |
|-------------------------------|----------|
| Hunan *(Hunan.shp)*           | Prof Kam |
| Hunan 2021 *(Hunan-2021.csv)* | Prof Kam |

# Spatial Data Wrangling

## Importing Geospatial Data

Using the code chunk below, we will import the *Hunan shapefile* into R as *sf data frame*.

```{r}
hunan <- st_read(dsn = "Hands-on_Ex05/data/geospatial",
                 layer = "Hunan")
```

## 
Importing Geospatial Data

Using the code chunk below, we will import *Hunan_2012.csv* into R, which reults in a *R data frame*.

```{r}
hunan2012 <- read_csv("Hands-on_Ex05/data/aspatial/Hunan_2012.csv")
```

## Perfoming Relational Join

The *hunan2012.csv* provides attributes that we want to combine with our shapefile. To do this, we can do a left join as shown in the code chunk, before selecting the columns that we want to retain.

```{r}
hunan <- left_join(hunan, hunan2012) %>%
  select(1:4, 7, 15)
```

## Visualising Regional Development Indicator

Next, we will prepare a chloropleth map to show the distribution of GDPPC in Hunan in 2012.

```{r}
equal <- tm_shape(hunan) +
  tm_fill("GDPPC",
          n = 5,
          style = "equal") +
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "Equal interval classification")

quantile <- tm_shape(hunan) +
  tm_fill("GDPPC",
          n = 5,
          style = "quantile") +
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "Equal quantile classification")

tmap_arrange(equal, 
             quantile, 
             asp=1, 
             ncol=2)
```

# Global Spatial Autocorrelation

In In-Class Exercise 6, we have learnt how to calculate Contiguity Spatial Weights usingt he Queen's method. Now, we will apply that to get our first order neighbours using the Queen criteria.

## Computing Contiguity Spatial Weights

Using the *sfdep* package with with *mutate()* and *st_contiguity()* and *st_weights()*, it performs the necessary tasks, to obtain the contiguity weights and then row-standardised weight matrix.

By default, the code chunk below will assign each neighbouring with equal weight (style="W")

```{r}
wm_q <- hunan %>%
  mutate(nb = st_contiguity(geometry),
         wt = st_weights(nb),
         .before = 1)
```

```{r}
summary(wm_q)
```

From the summary report, we can see that there are 88 area units, with the most connected area unit having 11 neighbours.

## 
Global Spatial Correlation

### Moran's I Test

The code chunk below performs Moran's I statistical testing using *global_moran_test* of **sfdep**.

```{r}
global_moran_test(hunan$GDPPC,
                  wm_q$nb,
                  wm_q$wt)
```
