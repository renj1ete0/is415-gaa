---
title: "Take-Home Exercise 03: Predicting HDB Public Housing Resale Prices Using Geographically Weighted Methods"
description: "Predicting HDB Public Housing Resale Prices Using Geographically Weighted Methods trained using Jan 2020 to Dec 2022 and tested with Jan to Feb 2023"
author: "Teo Ren Jie"
date: "3/12/2023"
date-modified: "3/19/2023"
number-sections: true
categories: ["Take-Home Exercise", "sf", "readXL", "tidyverse", "tmap", "sfdep", "gifski"]
title-block-banner: true
image: Take-Home_Ex03/preview.png
execute:
  message: false
  warning: false
---

# Overview

## Setting the Scene

\<add context\>

bal bla we are lookign at 5 storey HDB bla bla

## Objectives

ABC

## Tasks

In this take-home exercise, you are tasked to predict HDB resale prices at the sub-market level (i.e. HDB 3-room, HDB 4-room and HDB 5-room) for the month of January and February 2023 in Singapore. The predictive models must be built by using by using conventional OLS method and GWR methods. You are also required to compare the performance of the conventional OLS method versus the geographical weighted methods.

# Getting Started

## Installing and Loading Packages

Next, pacman assists us by helping us load R packages that we require, `sf`, `tidyverse` and funModeling.

```{r}
pacman::p_load(readxl, sf, tidyverse, tmap, sfdep, gifski, httr, jsonlite, onemapsgapi, rvest)
```

The following packages assists us to accomplish the following:

-   *readxl* assists us in importing `.xlsx` aspatial data without having to convert to `.csv`

-   *sf* helps to import, manage and process vector-based geospatial data in R

-   *tidyverse* which includes *readr* to import delimited text file, *tidyr* for tidying data and *dplyr* for wrangling data

-   *tmap* provides functions to allow us to plot high quality static or interactive maps using leaflet API

-   *gifski* helps us to handle the GIF animation for tmap

## 

## Data Acquisition

The following datasets would be used to create the predictive models using conventional OLS and GWR methods for HDB Resale Prices.

+--------------+-----------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------+
| Dataset Type | Dataset Name                            | Remarks                                                                                                                                                              | Source                                                                                                          |
+==============+=========================================+======================================================================================================================================================================+=================================================================================================================+
| Geospatial   | URA Master Plan 2019 Subzone Boundary   | For visualisation purposes and extract Central Area                                                                                                                  | Prof Kam                                                                                                        |
+--------------+-----------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------+
| Aspatial     | HDB Resale Flat Prices                  |                                                                                                                                                                      | [data.gov.sg](https://data.gov.sg/dataset/resale-flat-prices)                                                   |
+--------------+-----------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------+
| Aspatial     | HDB MUP/HIP Status                      | Manual Web Scraping                                                                                                                                                  | [hdb.gov.sg](https://services2.hdb.gov.sg/webapp/BB33RESLSTATUS/BB33PReslStatusEnq.jsp)                         |
+--------------+-----------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------+
| Geospatial   | Childcare                               |                                                                                                                                                                      | [onemap.sg Themes](https://www.onemap.gov.sg/docs/#themes)                                                      |
+--------------+-----------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------+
| Geospatial   | Kindergartens                           |                                                                                                                                                                      | [onemap.sg Themes](https://www.onemap.gov.sg/docs/#themes)                                                      |
+--------------+-----------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------+
| Geospatial   | Eldercare                               |                                                                                                                                                                      | [onemap.sg Themes](https://www.onemap.gov.sg/docs/#themes)                                                      |
+--------------+-----------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------+
| Geospatial   | Foodcourt/Hawker                        |                                                                                                                                                                      | [onemap.sg Themes](https://www.onemap.gov.sg/docs/#themes)                                                      |
+--------------+-----------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------+
| Geospatial   | Supermarket                             |                                                                                                                                                                      | [onemap.sg](onemap.sg)                                                                                          |
+--------------+-----------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------+
| Geospatial   | Current and Future MRT/LRT Stations     | Excludes Cross Region Line Punggol Branch                                                                                                                            | [data.gov.sg](https://data.gov.sg/dataset/master-plan-2019-rail-line-layer)                                     |
+--------------+-----------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------+
| \-           | Future MRT Station (CRL Punggol Branch) | Manually merge into MRT/LRT Station Dataset                                                                                                                          | [wikipedia.org : Elias MRT Stn](https://en.wikipedia.org/wiki/Elias_MRT_station)\                               |
|              |                                         |                                                                                                                                                                      | [wikipedia.org : Riveria MRT Stn](https://en.wikipedia.org/wiki/Riviera_MRT/LRT_station)                        |
+--------------+-----------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------+
| Geospatial   | MRT/LRT Railway Line                    | Filter elevated sections of MRT line                                                                                                                                 | [data.gov.sg](https://data.gov.sg/dataset/master-plan-2019-rail-line-layer)                                     |
+--------------+-----------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------+
| Geospatial   | Bus Stops                               |                                                                                                                                                                      | [datamall.lta.gov.sg](https://datamall.lta.gov.sg/content/dam/datamall/datasets/Geospatial/BusStopLocation.zip) |
+--------------+-----------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------+
| Geospatial   | Parks                                   | We consider the rail corridor, nature reserves and parks as parks as they are for leisure purposes.                                                                  | [data.gov.sg](https://data.gov.sg/dataset/nparks-parks-and-nature-reserves)                                     |
|              |                                         |                                                                                                                                                                      |                                                                                                                 |
|              |                                         | Also, we will prefer polygons of parks as we can calculate the actual proximity to the edges of the parks instead of to an arbitary point in the centre of the park. |                                                                                                                 |
+--------------+-----------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------+
| Geospatial   | Primary Schools                         | Requires special handling                                                                                                                                            | onemap.sg json                                                                                                  |
+--------------+-----------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------+
| Aspatial     | CHAS Clinics                            | Extracted using Excel from PDF                                                                                                                                       | [chas.sg](https://www.chas.sg/clinic-locator)                                                                   |
+--------------+-----------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------+

## Data Fields

The data fields we are looking to incorporate and work with in our predictive models includes:

::: panel-tabset
## Structural Factors

-   Area of the unit

-   Floor level

-   Remaining lease

-   Age of the unit

-   Main Upgrading Program (MUP) completed

    -   Extracted MUP and Home Improvment Programme (HIP) data from HDB website

    -   For HDB units that has received HIP, their home value may be affected positively than a similar aged flat that has not received it

-   Relative Age of Remaining Lead to Mean of Remaining Lease Left within 1km (+ if newer, - if older than area)

    -   If a HDB estate is relatively newer than HDBs in the area, homeowners might be enticed to buy newer HDB units in the area

-   Apartment Type (eg. DBSS/Standard/Premium)

    -   Design Build Sell Scheme (DBSS) flats may call for a higher value than regular HDB flats as they are designed, build and sold by 3rd party developers although they are still HDB Flats. They are supposed to be better than premium flats

    -   Premium flats which come with pre-installed fittings and furnishings over standard apartments which comes with none

    -   Reference: https://www.teoalida.com/singapore/hdbflattypes/

-   Apartment Multi-story (Maisonette or Loft)

    -   Some homeowners may prefer multi-story HDBs over single-story ones

## Vocational Factors

-   Proximity to CBD

-   Proximity to eldercare

-   Proximity to foodcourt/hawker centres

-   Proximity to MRT

-   Proximity to park

-   Proximity to good primary school

-   Proximity to shopping mall

-   Proximity to supermarket

-   Numbers of kindergartens within 350m

-   Numbers of childcare centres within 350m

-   Numbers of bus stop within 350m

-   Numbers of primary school within 1km

-   Proximity to Overhead MRT Line \[noise concern\] (if \<300m)

    -   The closer a HDB unit is to the MRT track, the home value might be affected due to noise concerns. We measure the proximity of HDB units using its euclidean distance to the closest part of the MRT track if it is less than 300metres away.

-   Number of Future MRT stops within 800m (10min walk)

    -   Here, I want to explore how the resale values of HDBs could be affected by future MRT stations that are announced but not yet built. Home owners may be enticed to buy houses near future MRT lines in hopes that the house values will increase and also due to increased connectivity

-   Number of LRT Stops within 350m

    -   The metric is necessary as LRT serves as a feeder within the town and is typically used short-haul vs MRT which is between various towns. The 350m metric is derived from Bus Stops differentiates the weight between a LRT stop and MRT stop especially if the LRT stop is far away from the MRT stop in towns such as Sengkang, Punggol and Pasir Ris
:::

# Data Wrangling: Geospatial Data

There are two categories of datasets we will need for our analysis, these includes:

-   Datasets that has been downloaded - These files are already downloaded into a local location

-   Datasets that are retrieved over API - We need to obtain the datasets using API Calls

## Retrieving Data from API Calls

There are some data that we need to retreive using API calls from [onemap.sg](onemap.sg). OneMap offers additional data from different government agencies through [Themes](https://www.onemap.gov.sg/docs/#themes). For R, the [onemapsgapi](https://cran.r-project.org/web/packages/onemapsgapi/onemapsgapi.pdf) package helps us with the API calls with onemap.sg servers to obtain the data we require.

Using onemapsgapi is pretty simple as shown below:

```{r eval=FALSE}
token <- "" # enter authentication token obtained from onemap
search_themes(token, "<searchterm>") %>% print(n=Inf)
tibble <- get_theme(token, "<queryname>")
sf <- st_as_sf(tibble, coords=c("Lng", "Lat"), crs=4326)
```

-   *search_themes()* - Search for various thematic layers provided by onemap (eg. Parks). A tibble dataframe will be provided with more details of the layer, such as the `THEMENAME`, `QUERYNAME`, `ICON`, `CATEGORY` and `THEME_OWNER`

-   *get_theme()* - Using the desired theme's `QUERYNAME` obtained from *search_themes()*, we can obtain the thematic data in a tibble dataframe. We will need to use st_as_sf to specify the `Lat`, `Lng` and crs to obtain it as a sf dataframe.

Listed below are a list of layers we need to obtain:

-   Childcare

-   Kindergartens

-   Eldercare

-   Foodcourt/Hawker Centres

In the code block below, we will assume to have used *search_themes()* to pick the specific themes we want, to load them. The justification will be listed below.

::: panel-tabset
## Obtain Data

Childcare

```{r eval=FALSE}
childcare_tibble <- get_theme(token, "childcare")
childcare_sf <- st_as_sf(childcare_tibble, coords=c("Lng", "Lat"), crs=4326)
```

Kindergartens

```{r eval=FALSE}
kindergartens_tibble <- get_theme(token, "kindergartens")
kindergartens_sf <- st_as_sf(kindergartens_tibble, coords=c("Lng", "Lat"), crs=4326)
```

Eldercare

```{r eval=FALSE}
eldercare_tibble <- get_theme(token, "eldercare")
eldercare_sf <- st_as_sf(eldercare_tibble, coords=c("Lng", "Lat"), crs=4326)
```

Foodcourt/Hawker Centre

```{r eval=FALSE}
hawker_tibble <- get_theme(token, "hawkercentre_new")
hawker_sf <- st_as_sf(hawker_tibble, coords=c("Lng", "Lat"), crs=4326)
```

## RDS Scripts (Save)

```{r eval=FALSE}
write_rds(childcare_sf, "Take-Home_Ex03/rds/childcare_sf.rds")
write_rds(kindergartens_sf, "Take-Home_Ex03/rds/kindergartens_sf.rds")
write_rds(eldercare_sf, "Take-Home_Ex03/rds/eldercare_sf.rds")
write_rds(hawker_sf, "Take-Home_Ex03/rds/hawker_sf.rds")
```
:::

## Obtaining Schools Data

Obtaining school data from OneMap is a bit tricky, it was not available through OneMap themes or a download link through the OneMap website. However, through clicking through the Query Schools function on the map using using 'Inspect Element', we could see that a GET request is called to obtain the map data as json (as seen in the screenshot below):

![](Take-Home_Ex03/geospatial/onemap-schools-1.png)

By opening the link, we could see that it is an undocumented public API that OneMap uses to retrieve map data regarding Primary Schools. The results are in json as shown below:

![](Take-Home_Ex03/geospatial/onemap-schools-2.png)

The data has been downloaded and will be processed into tibble format using *json_lite* *fromJSON()* which will import the JSON file and convert it into tibble dataframe.

```{r}
schools_tibble <- fromJSON("Take-Home_Ex03/geospatial/retrieveAllSchools.json")[["SearchResults"]]
glimpse(schools_tibble)
```

As we can see the want to exclude the column `PageCount` and the first row as it is not relavant to our dataset. The code chunk below will perform the above for us:

```{r}
schools_tibble <- select(schools_tibble,-"PageCount")
schools_tibble <- schools_tibble[-1,]
```

Next, we will convert the tibble dataframe to sf dataframe. Since X and Y coordinates are provided for us (SVY21) in the columns `SCH_Y_ADDR` and `SCH_X_ADDR`, we will use them instead of the `Lng` and `Lat` as SVY21 (Projected Coordinate System) will allow us to perform our analysis directly.

```{r}
schools_sf_3414 <- st_as_sf(schools_tibble, coords=c("SCH_X_ADDR", "SCH_Y_ADDR"), crs=3414)
```

Now, we will save the data imported as RDS file format (R Data Serialisation).

```{r eval=FALSE}
write_rds(schools_sf_3414, "Take-Home_Ex03/rds/schools_sf_3414.rds")
```

## Importing Geospatial Data

::: panel-tabset
## Downloaded

Master Plan Subzone 2019

```{r}
mpsz = st_read(dsn = "Take-Home_Ex03/geospatial", layer="MPSZ-2019")
```

Current and Future MRT/LRT Stations

```{r}
geo_mrt_lrt_stn = st_read(dsn = "Take-Home_Ex03/geospatial/master-plan-2019-rail-station-layer-kml.kml")
```

MRT/LRT Railway Line

```{r}
geo_railway_line = st_read(dsn = "Take-Home_Ex03/geospatial/rail-line.kml")
```

Bus Stops

```{r}
geo_bus_stop = st_read(dsn = "Take-Home_Ex03/geospatial", layer="BusStop")
```

Parks

```{r}
geo_parks = st_read(dsn = "Take-Home_Ex03/geospatial/nparks-parks-and-nature-reserves-kml.kml")
```

Supermarket

```{r}
geo_supermarkets = st_read(dsn = "Take-Home_Ex03/geospatial", layer="Supermarkets")
```

## Other Data (RDS)

```{r}
geo_schools <- read_rds("Take-Home_Ex03/rds/schools_sf_3414.rds")
geo_childcare <- read_rds("Take-Home_Ex03/rds/childcare_sf.rds")
geo_eldercare <- read_rds("Take-Home_Ex03/rds/eldercare_sf.rds")
geo_hawker <- read_rds("Take-Home_Ex03/rds/hawker_sf.rds")
geo_kindergartens <- read_rds("Take-Home_Ex03/rds/kindergartens_sf.rds")
```
:::

## Transforming Coordinate Systems

For datasets in `WGS84` Geodetic Coordinate System, we need to convert them to `SVY21` Projected Coordinate System to perform our analysis. Inferring form the information above, we will use the code chunk below to confirm all of them.

::: panel-tabset
## Transform

```{r}
mpsz <- st_transform(mpsz,3414)
geo_mrt_lrt_stn <- st_transform(geo_mrt_lrt_stn,3414)
geo_railway_line <- st_transform(geo_railway_line,3414)
geo_parks <- st_transform(geo_parks,3414)
geo_supermarkets <- st_transform(geo_supermarkets,3414)
geo_childcare <- st_transform(geo_childcare,3414)
geo_eldercare <- st_transform(geo_eldercare,3414)
geo_hawker <- st_transform(geo_hawker,3414)
geo_kindergartens <- st_transform(geo_kindergartens,3414)
```

## Check

Master Plan Subzone 2019

```{r}
mpsz
```

Current and Future MRT/LRT Stations

```{r}
geo_mrt_lrt_stn
```

MRT/LRT Railway Line

```{r}
geo_railway_line
```

Parks

```{r}
geo_parks
```

Supermarkets

```{r}
geo_supermarkets
```

Childcare

```{r}
geo_childcare
```

Eldercare

```{r}
geo_eldercare
```

Hawker

```{r}
geo_hawker
```

Kindergartens

```{r}
geo_kindergartens
```
:::

Great! Now everything is in `SVY21` Projected Coordinate System.

## Fixing KML Data

When we look at the MRT/LRT Station and Railway Line stations, we find that the labels are `KML_1`, `KML_2`, etc which are not useful for our analysis.

```{r}
glimpse(geo_mrt_lrt_stn)
```

```{r}
glimpse(geo_railway_line)
```

Here, we can see that many of the attributes are nested in a HTML format under the `description` column, We will now fix the `KML` imported data for MRT/LRT Station and Railway Line datasets so we can access the attributes to filter it effectively for our further analysis. The code referenced is from [StackOverflow](https://stackoverflow.com/questions/50775357/how-to-read-in-kml-file-properly-in-r-or-separate-out-lumped-variables-into-col):

```{r}
attributes <- lapply(X = 1:nrow(geo_mrt_lrt_stn), 
                     FUN = function(x) {

                       geo_mrt_lrt_stn %>% 
                         slice(x) %>%
                         pull(Description) %>%
                         read_html() %>%
                         html_node("table") %>%
                         html_table(header = TRUE, trim = TRUE, dec = ".", fill = TRUE) %>%
                         as_tibble(.name_repair = ~ make.names(c("Attribute", "Value"))) %>% 
                         pivot_wider(names_from = Attribute, values_from = Value)

                     })
geo_mrt_lrt_stn <- 
  geo_mrt_lrt_stn %>%
  bind_cols(bind_rows(attributes)) %>%
  select(-Description)

glimpse(geo_mrt_lrt_stn)
```

```{r}
attributes <- lapply(X = 1:nrow(geo_railway_line), 
                     FUN = function(x) {

                       geo_railway_line %>% 
                         slice(x) %>%
                         pull(Description) %>%
                         read_html() %>%
                         html_node("table") %>%
                         html_table(header = TRUE, trim = TRUE, dec = ".", fill = TRUE) %>%
                         as_tibble(.name_repair = ~ make.names(c("Attribute", "Value"))) %>% 
                         pivot_wider(names_from = Attribute, values_from = Value)

                     })
geo_railway_line <- 
  geo_railway_line %>%
  bind_cols(bind_rows(attributes)) %>%
  select(-Description)

glimpse(geo_railway_line)
```

Great now we have extracted the attributes into its own columns where we can use it for further analysis.

# Data Wrangling: Aspatial Data

We have three datasets that are Aspatial Data which only contains addresses of the locations. However, we cannot perform analysis without the coordinates of the datasets without its coordinates, hence, we need to geocode the data to retrieve its coordinates using onemap.

These are the datasets that require further processing:

-   CHAS Clinics

-   HDB HIP MUP

-   HDB Resale Flat Pricing

## Importing Aspatial Data

In the various tabs below, we will import each individual dataset from its respective folders, with a brief explanation of the use cases of each dataset.

::: panel-tabset
## CHAS Clinics

```{r}
CHAS_raw = read_xlsx("Take-Home_Ex03/aspatial/CHAS.xlsx") 
glimpse(CHAS_raw)
```

## HDB HIP MUP

```{r}
hdb_hip_mup_raw = read_xlsx("Take-Home_Ex03/aspatial/HDB_HIP-MUP-20230312.xlsx")
glimpse(hdb_hip_mup_raw)
```

## HDB Resale Flat Pricing

```{r}
hdb_resale_raw = read_csv("Take-Home_Ex03/aspatial/resale-flat-prices-based-on-registration-date-from-jan-2017-onwards.csv")
glimpse(hdb_resale_raw)
```
:::

## Filtering HDB Resale Flat Data

We will now filter the HDB Resale to focus on the target months, Jan 2020 to Feb 2023, and 5 Room HDBs to construct the predictive model. We will use:

-   *filter()* to filter out the desired room type and months

-   *unique()* to check if the desired room type and months has been filtered correctly

-   *glimpse()* to check the data structure of the filtered dataset

::: panel-tabset
## Filter Code

```{r}
hdb_resale <- filter(hdb_resale_raw, flat_type == "5 ROOM") %>%
              filter(month >= "2020-01" & month <= "2023-02")
```

## Glimpse Variables

```{r}
glimpse(hdb_resale)
```

## Unique Month and Flat_Type

```{r}
unique(hdb_resale$month)
```

```{r}
unique(hdb_resale$flat_type)
```
:::

From the code and results in the respective tabs (Glimpse Variables and Unique Month and Flat Type), we can see that:

-   There are **21,500 transactions** between Jan 2020 to Feb 2023.

-   The `month` and `flat_type` has been extracted correctly.

## Transforming Aspatial Data - Create New Columns with Values

Next, we transform the Aspatial Datasets into more meaningful values:

1.  CHAS Clinics - There is nothing to transform, since as noted earlier, there is already a `postal` column provided
2.  HDB HIP MUP - We need to obtain the address for geocoding (obtaining the SVY21 `X` and `Y` coordinates) by combining the `BLK` and `STREET` fields
3.  HDB Resale Flat Pricing - We need to obtain the address for geocoding (obtaining the SVY21 `X` and `Y` coordinates) by combining the `block` and `street_name` fields, and also convert the remaining lease from the form of `YY years MM months` to a more machine-readable format (ie. `MM` months)

The code chunks will assist with the transformation using *mutate()* further explained below:

::: panel-tabset
## HDB HIP MUP

We *mutate()* the `hdb_hip_mup_raw` dataset by pasting the `BLK` and `STREET` columns together into the `address` column to a new sf dataframe called `hdb_hip_mup_trans`

```{r}
hdb_hip_mup_trans <- hdb_hip_mup_raw %>%
  mutate(hdb_hip_mup_raw, address = paste(BLK, STREET))
```

## HDB Resale Flat Pricing

We *mutate()* the `hdb_resale` dataset by pasting the `block` and `street_name` columns together into the `address` column to a new variable called `hdb_hip_mup_trans`. We also used *mutate()* to modify the existing `remaining_lease` data to the form of `MM`.

The first section of the code `as.integer(str_sub(remaining_lease, 0, 2)) * 12` extracts the year numbers as `YY` and converts it into string and then multiplying it by 12 to convert it to number of months.

The next part of the code checks if there is any numerical `MM` (month) present, if there is no month present, the value will be `NA` and 0 will be assigned in place of `NA`. Else, if present, we take the `MM`.

The integer month is summed with the year in months to form this column `remaining_lease_mths` in the new sf dataframe `hdb_resale_trans`

```{r}
hdb_resale_trans <- hdb_resale %>%
  mutate(hdb_resale, address = paste(block, street_name)) %>%
  mutate(hdb_resale, remaining_lease_mths = (as.integer(str_sub(remaining_lease, 0, 2)) * 12 + ifelse(is.na(as.integer(str_sub(remaining_lease, 9, 11))), 0,  as.integer(str_sub(remaining_lease, 9, 11)))))
```

Next, let us left join the HDB HIP MUP data into HDB Resale Transactions so that we know which HDB units have already completed their upgrading.

```{r}
hdb_resale_trans <- left_join(hdb_resale_trans, hdb_hip_mup_trans)
glimpse(hdb_resale_trans)
```

Then we'll select only the unnecessary columns:

```{r}
hdb_resale_trans <- hdb_resale_trans %>% select(c(1:13, 16))
```
:::

## Retrieving SVY21 Coordinate of Addresses

This section will focus on retrieving relavant data such as coordinates of the address which we could use in further spatial analysis to obtain proximity to locational factors later.

We are interested in obtaining the `SVY21` `X` and `Y` coordinates as they are in the Projected Coordinate System, which allows us to perform measure directly without any additional transformations.

### Create a List Storing Unique Addresses/Postal Codes

Since some addresses/postal codes are duplicated, we store and check unique addresses to reduce the amount of `GET` requests sent to the OneMap API:

1.  Faster
2.  OneMap API has a rate limit of 250 API calls a minute
3.  It makes it easier for us to locate errors and correct it

Here, we will obtain a list of unique addresses/postal codes for each data set.

::: panel-tabset
## CHAS Clinics

```{r}
addr_lst.chas <- sort(unique(CHAS_raw$Postal))
glimpse(addr_lst.chas)
```

## HDB Resale Flat Pricing

```{r}
addr_lst.resale <- sort(unique(hdb_resale_trans$address))
glimpse(addr_lst.resale)
```
:::

### Create Function to Retrieve Coordinates from OneMap.sg API

The following function uses OneMap.sg Search API to obtain coordinates (SVY21 X, Y) using part of an address or postal code.

This is how the function `get_coordinates()` below will work:

1.  `new_coords` datafame is created to store all the new coordinate data and its original address that is input to the GET request API
2.  for each `addr` in `addr_lst` where `addr_lst` is the list passed into the function, we will query each record and append accordingly:
    1.  If there is 1 or more records, we append the top record's SVY21 X, Y coordinates and `addr` to a temporary dataframe called `new_row`,

    2.  Else, `NA` for it's `X` and `Y` columns and the `addr` is stored in `new_row`.
3.  The GET Request has various parameters:
    1.  `searchVal` - the value to pass to OneMap Search to obtain the Geocode (in this case we are interested in SVY21 X, Y coordinates)

    2.  `returnGeom` - return details about geometry (ie. SVY21 X, Y or Lat Lon), `Y` in this case as we want SVY21 X, Y coordinates

    3.  `getAddrDetails` - get more details about the address, `N` in this case as we don't require further information.
4.  fromJSON() helps us convert the JSON format to a list format for manipulation
    1.  the function rawToChar() was used as the received type for `reply$content` is RAW, which requires conversion before we can read the values
5.  Lastly, we will combine the `new_row` data into the main `new_coords` dataframe using *rbind()* as they are both dataframes.

<div>

```{r}
get_coordinates <- function(addr_lst){
  
  # Create a data frame to store all retrieved coordinates
  new_coords <- data.frame()
    
  for (addr in addr_lst){
    #print(i)

    reply <- GET('https://developers.onemap.sg/commonapi/search?',
           query = list(searchVal = addr,
                        returnGeom = 'Y',
                        getAddrDetails = 'N'))
    
    output <- fromJSON(rawToChar(reply$content))
    found <- output$found
    res <- output$results
    
    # Create a new data frame for each address
    new_row <- data.frame()
    
    # If single result, append 
    if (found >= 1){
      res_1 <- head(res, n = 1)
      x <- res_1$X
      y <- res_1$Y
      new_row <- data.frame(address = addr, x = x, y = y)
    }

    else {
      new_row <- data.frame(address = addr, x = NA, y = NA)
    }
    
    # Add the row
    new_coords <- rbind(new_coords, new_row)
  }
  return(new_coords)
}
```

</div>

### Call get_coordinates() Function to Obtain Coordinates

We use *get_coordinates()* function created earlier to obtain the coordinates of the address. *glimpse()* allows us to view and check if the data has been properly created.

RDS Scripts contains scripts to import/export the coordinates R objects to RDS file format (R Data Serialisation) prevent having to call the API each time on every render.

::: panel-tabset
## get_coordinates() Function

CHAS Clinics

```{r eval=FALSE}
coords_chas <- get_coordinates(addr_lst.chas)
```

HDB Resale Flat Pricing

```{r eval=FALSE}
coords_resale <- get_coordinates(addr_lst.resale)
```

## RDS Scripts

Writing RDS

```{r eval=FALSE}
write_rds(coords_chas, "Take-Home_Ex03/rds/coords_chas.rds")
write_rds(coords_resale, "Take-Home_Ex03/rds/coords_resale.rds")
```

Reading RDS

```{r}
coords_chas <- read_rds("Take-Home_Ex03/rds/coords_chas.rds")
coords_resale <- read_rds("Take-Home_Ex03/rds/coords_resale.rds")
```

## Glimpse Records

CHAS Clinics

```{r}
glimpse(coords_chas)
```

HDB Resale Flat Pricing

```{r}
glimpse(coords_resale)
```
:::

## Data Verification for Coordinate Data

With the retrieved data, we need to inspect and verify the data received and correct any errors made along the way. We will do all the steps in parallel for each dataset, outlined in step format below:

1.  Merge coordinate data and original dataframe
    -   We do this as the CHAS Clinics coordinates are derived from Postal Code and it might be hard to figure out which place are we looking at by looking at just the postal code
2.  Check for `NA` X/Y values and manually amend if required
3.  Convert DataFrame into a sf Object
4.  Plot a tmap and check if points are plotted in the correct regions

At any step if there are issues, we will detail steps to fix or recover from it.

### CHAS Clinics

1.  Merge Coordinate Data and Original Dataframe

    ```{r}
    temp_chas <- left_join(CHAS_raw, coords_chas, by=c("Postal" = "address"))
    ```

2.  Check for `NA` X/Y values and manually amend if required

    ```{r}
    filter(temp_chas, is.na(x) == TRUE)
    ```

    Here, using *filter()* and *is.na()*, we find out which records do not have a valid location assigned to it. Now, let us manually check through the records and fix the issue.

    +-------------------------------------------------------------------------+------------------------------------------------------------------------------+
    | CHAS Clinic Address                                                     | Issue                                                                        |
    +=========================================================================+==============================================================================+
    | 189, Selegie Road, Selegie Centre, #01- 05, Singapore 188332            | No longer exists based on Onemap and Google Map, we will remove it           |
    +-------------------------------------------------------------------------+------------------------------------------------------------------------------+
    | 140, Corporation Drive, #01- 03                                         | Postal Code number **610140** according to OneMap, we will amend accordingly |
    +-------------------------------------------------------------------------+------------------------------------------------------------------------------+
    | 6, Gemmill Lane                                                         | Postal Code number **069249** according to OneMap, we will amend accordingly |
    +-------------------------------------------------------------------------+------------------------------------------------------------------------------+
    | 102, Yishun Avenue 5, #01- 133, Singapore\\r\\n760102                   | No longer exists based on Onemap and Google Map, we will remove it           |
    +-------------------------------------------------------------------------+------------------------------------------------------------------------------+
    | 34, Craig Road, Chinatown Plaza, #01- 04,\\r\\nSingapore 089673         | No longer exists based on Onemap and Google Map, we will remove it           |
    +-------------------------------------------------------------------------+------------------------------------------------------------------------------+
    | 1, Rochor Road, Rochor Centre, #03- 516,\\r\\nSingapore 180001          | No longer exists based on Onemap and Google Map, we will remove it           |
    +-------------------------------------------------------------------------+------------------------------------------------------------------------------+
    | 51, TAMPINES AVENUE 4, OUR TAMPINES\\r\\nHUB, #B1- 04/05                | Records are appended as **528523** on OneMap, we will amend accordingly      |
    +-------------------------------------------------------------------------+------------------------------------------------------------------------------+
    | 50, Market Street, Golden Shoe Car Park,\\r\\n#01- 30, Singapore 048940 | No longer exists based on OneMap and Google Map, we will remove it           |
    +-------------------------------------------------------------------------+------------------------------------------------------------------------------+

    Now, let us update:

    #### Fixing Data

    ::: panel-tabset
    ## 1. Update Records

    We remove the clinics that are non-existent using *filter()*

    ```{r}
    chas_updated <- filter(CHAS_raw, !Address %in%
      c("189, Selegie Road, Selegie Centre, #01- 05,\r\nSingapore 188332",
        "102, Yishun Avenue 5, #01- 133, Singapore\r\n760102",
        "34, Craig Road, Chinatown Plaza, #01- 04,\r\nSingapore 089673",
        "1, Rochor Road, Rochor Centre, #03- 516,\r\nSingapore 180001",
        "50, Market Street, Golden Shoe Car Park,\r\n#01- 30, Singapore 048940"))
    ```

    Next, we use *mutate()* and *ifelse()* condition to update the Postal Codes of the clinics at the relavant addresses.

    ```{r}
    chas_updated <- chas_updated %>% 
      mutate(Postal = ifelse(Address == "140, Corporation Drive, #01- 03", "610140", Postal)) %>%
      mutate(Postal = ifelse(Address == "6, Gemmill Lane", "069249", Postal)) %>%
      mutate(Postal = ifelse(Address == "51, TAMPINES AVENUE 4, OUR TAMPINES\r\nHUB, #B1- 04/05", "528523", Postal))
    ```

    Lastly, we regenerate the list of unique Postal Codes to be geocoded.

    ```{r}
    addr_lst.chas_upd <- sort(unique(chas_updated$Postal))
    glimpse(addr_lst.chas_upd)
    ```

    ## 2. Rerun get_coordinates()

    We get the SVY21 X,Y coordinates using our *get_coordinates()* function

    ```{r eval=FALSE}
    coords_chas_upd <- get_coordinates(addr_lst.chas_upd)
    ```

    Saving the DataFrame as .rds for future use to prevent rerunning *get_coordinates()* GET API everytime a render is run

    ```{r eval=FALSE}
    write_rds(coords_chas_upd, "Take-Home_Ex03/rds/coords_chas_upd.rds")

    ```

    Load the DataFrame from .rds

    ```{r}
    coords_chas_upd <- read_rds("Take-Home_Ex03/rds/coords_chas_upd.rds")

    ```

    ## 3. Combine DataFrame and verify

    We left join the `chas_updated` main table and coordinates and filter the `x` column for any null values

    ```{r}
    temp_chas <- left_join(chas_updated, coords_chas_upd, by=c("Postal" = "address"))
    filter(temp_chas, is.na(x) == TRUE)
    ```

    No null values found, we have completed this step!
    :::

3.  Convert a DataFrame into a sf Object

    We specify the SVY21 X and Y coordinates to be used as the coordinate geometry. The `crs` specified is `3414` which refers to `SVY21`.

    ```{r}
    chas_sf <- st_as_sf(temp_chas,
                            coords = c("x", "y"),
                            crs = 3414)
    ```

4.  Plot a tmap and check if points are plotted in the correct regions

    Now, we will plot an interactive tmap to check if our points are correct.

    ```{r}
    tmap_mode("view")
    tm_shape(chas_sf) +
      tm_dots("Type",
              popup.vars=c("Name"="Name", "Address"="Address", "Type" = "Type", "Telephone" = "Telephone"))
    ```

    From our analysis, the points looks to be correctly located.

### HDB Resale Flat Pricing

1.  Merge Coordinate Data and Original Dataframe

    ```{r}
    temp_hdb_resale_trans <- left_join(hdb_resale_trans, coords_resale, by=c("address" = "address"))
    ```

2.  Check for `NA` X/Y values and manually amend if required

    ```{r}
    filter(temp_hdb_resale_trans, is.na(x) == TRUE)
    ```

    No `NA` values, great!

3.  Convert a DataFrame into a sf Object

    We specify the SVY21 X and Y coordinates to be used as the coordinate geometry. The `crs` specified is `3414` which refers to `SVY21`.

    ```{r}
    hdb_resale_sf <- st_as_sf(temp_hdb_resale_trans,
                            coords = c("x", "y"),
                            crs = 3414)
    ```

4.  Plot a tmap and check if points are plotted in the correct regions

    Now, we will plot an interactive tmap to check if our points are correct. We overlay the URA Master Plan Regions for a quick overlay to roughly check if the HDBs are located in the correct areas. Do note that HDB Towns differ from URA Planning Areas.

    ```{r}
    tmap_mode("view")
    tmap_options(check.and.fix = TRUE)
    tm_shape(mpsz) +
      tm_polygons("REGION_N",
                  alpha = 0.5) +
    tm_shape(hdb_resale_sf) +
      tm_dots("town",
              popup.vars=c("block"="block", "street_name"="street_name", "flat_model" = "flat_model", "town" = "town", "resale_price" = "resale_price", "remaining_lease_mths", "remaining_lease_mths"))
    ```

    Oddly, 27 Marine Cres appeared as a point on Sembcorp Marine Tuas Crescent and 54 Kent Rd somehow appeared as a point on 54J SOUTH BUONA VISTA ROAD KENT RIDGE HILL RESIDENCES. There are also some other differences, so let us now recode some of the addresses to get them to the right locations:

    #### Fixing Data

    ::: {.panel-tabset .column-screen-inset-left}
    ## 1. Update Records

    We use *mutate()* to replace the existing addresses with more specific ones that we found on OneMap.

    ```{r}
    mod_hdb_resale_trans <- hdb_resale_trans %>% 
      mutate(address = ifelse(address == "10 JLN BATU", "10 JALAN BATU DI TANJONG RHU", address)) %>%
      mutate(address = ifelse(address == "11 JLN BATU", "11 JALAN BATU DI TANJONG RHU", address)) %>%     
      mutate(address = ifelse(address == "54 KENT RD", "54 KENT ROAD KENT VILLE", address)) %>%    
      mutate(address = ifelse(address == "27 MARINE CRES", "27 MARINE CRESCENT MARINE CRESCENT VILLE", address))
    ```

    ```{r}
    temp_hdb_resale_trans <- left_join(mod_hdb_resale_trans, coords_resale, by=c("address" = "address"))
    ```

    Lastly, we regenerate the list of unique Postal Codes to be geocoded.

    ```{r}
    addr_lst.resale_upd <- sort(unique(mod_hdb_resale_trans$address))
    glimpse(addr_lst.resale_upd)
    ```

    ## 2. Rerun get_coordinates()

    We get the SVY21 X,Y coordinates using our *get_coordinates()* function

    ```{r eval=FALSE}
    coords_resale_upd <- get_coordinates(addr_lst.resale_upd)
    ```

    Saving the DataFrame as .rds for future use to prevent rerunning *get_coordinates()* GET API everytime a render is run

    ```{r eval=FALSE}
    write_rds(coords_resale_upd, "Take-Home_Ex03/rds/coords_resale_upd.rds")

    ```

    Load the DataFrame from .rds

    ```{r}
    coords_resale_upd <- read_rds("Take-Home_Ex03/rds/coords_resale_upd.rds")

    ```

    ## 3. Combine DataFrame and verify

    We left join the `hdb_hip_mup_trans_upd` main table and coordinates and filter the `x` column for any null values

    ```{r}
    temp_hdb_resale_trans <- left_join(mod_hdb_resale_trans, coords_resale_upd, by=c("address" = "address"))
    filter(temp_hdb_resale_trans, is.na(x) == TRUE)
    ```

    No null values found, we have completed this step!

    ## 4. Convert a DataFrame into a sf Object

    ```{r}
    hdb_resale_sf <- st_as_sf(temp_hdb_resale_trans,
                            coords = c("x", "y"),
                            crs = 3414)
    ```

    ## 5. Plot a tmap and check if points are plotted in the correct regions

    ```{r}
    tmap_mode("view")
    tmap_options(check.and.fix = TRUE)
    tm_shape(mpsz) +
      tm_polygons("REGION_N",
                  alpha = 0.5) +
    tm_shape(hdb_resale_sf) +
      tm_dots("town",
              popup.vars=c("block"="block", "street_name"="street_name", "flat_model" = "flat_model", "town" = "town", "resale_price" = "resale_price", "remaining_lease_mths", "remaining_lease_mths"))
    ```
    :::

```{r}
#tmap_mode("view")
#tm_shape(hdb_resale) +
#  tm_dots("resale_price",
#          popup.vars=c("month"="month", "town"="town", "block" = "block", "street_name" = "street_name"))
```

# Credits

https://stackoverflow.com/questions/50775357/how-to-read-in-kml-file-properly-in-r-or-separate-out-lumped-variables-into-col
