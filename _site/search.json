[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Teo Ren Jie",
    "section": "",
    "text": "About Me\n\n\nI’m Ren Jie, a Year 2 Information Systems Undergraduate student at the Singapore Management University, majoring in Digitalisation & Cloud Solutions (SCIS) and Urban Science (CIS).\nMy interests are in urban science and urban planning. I am excited to learn more about geospatial analytics from this course which will value-add to my individualised second major in Urban Science at the College of Integrative Studies, where I aim to utilise, integrate and interpret data from the city into innovative solutions for cities of the future.\n\n\n\nMore About This Site\n\nThis site documents my journey on learning and applying Geospatial Analytics\n\n\nFind Me\n\nConnect with me on LinkedIn or contact me through email!"
  },
  {
    "objectID": "exercises/hoex1.html",
    "href": "exercises/hoex1.html",
    "title": "Hands-on Exercise 1: Geospatial Data Handling and Wrangling",
    "section": "",
    "text": "Firstly, the code below will check if pacman has been installed. If it has not been installed, R will download and install it, before activating it for use during this session.\n\nif (!require('pacman', character.only = T)){\n  install.packages('pacman')\n}\n\nLoading required package: pacman\n\nlibrary('pacman')\n\nNext, pacman assists us by helping us load R packages that we require, sf and tidyverse.\n\npacman::p_load(sf, tidyverse)\n\n\n\n\nFor the purpose of this exercise, the following public datasets are used:\n\n\n\nDataset Name\nSource\n\n\n\n\nMaster Plan 2014 Subzone Boundary (Web) (MP14_SUBZONE_WEB_PL.shp)\ndata.gov.sg\n\n\nPre-Schools Location (preschools-location.kml)\ndata.gov.sg\n\n\nCycling Path (CyclingPathGazette.shp)\nLTA Datamall\n\n\nLatest version of Singapore Airbnb listing data (listings.csv)\nInside Airbnb\n\n\n\nThe data has been extracted to Hands-on_Ex01/data/geospatial.\nMaster Plan and Cycling Path layers are provided in ES\nRI shapefile format, Pre-Schools Location provided in kml and Airbnb listings in csv format.\n\n\n\nThere are two shapefile (.shp) datasets, Master Plan 2014 Subzone Boundary (Web) and Cycling Path.\n\n\nFirstly, we will import Master Plan 2014 Subzone Boundary (Web). In the code below, dsn specifies the filepath where the dataset is located and layer provides the filename of the dataset excluding the file extension.\n\nmpsz = st_read(dsn = \"Hands-on_Ex01/data/geospatial\", layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\renjie-teo\\IS415-GAA\\exercises\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nFrom the above message, it tells us that the dataset contains multipolygon features, containing 323 multipolygon features and 15 fields in the mpsz simple feature data frame and is in the svy21 projected coordinates system. The bounding box provides us the x and y extents (x min, x max, y min, y max) of the data.\n\n\n\nNext, we will import Cycling Path.\n\ncyclingpath = st_read(dsn = \"Hands-on_Ex01/data/geospatial\", layer = \"CyclingPathGazette\")\n\nReading layer `CyclingPathGazette' from data source \n  `C:\\renjie-teo\\IS415-GAA\\exercises\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 2248 features and 2 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11854.32 ymin: 28347.98 xmax: 42626.09 ymax: 48948.15\nProjected CRS: SVY21\n\n\nFrom the above message, it tells us that the dataset contains mutlilinestring features, containing 2248 multilinestring features and 2 fields in the cyclingpath simple feature data frame and is in the svy21 projected coordinates system. Similarly, the bounding box provides us the x and y extents (x min, x max, y min, y max) of the data.\n\n\n\n\nThere is one kml dataset, Pre-Schools Location, that we have to import.\n\n\nIn the code below, we do not specify dsn and layer. Just the filepath and filename will suffice.\n\npreschools = st_read(\"Hands-on_Ex01/data/geospatial/preschools-location.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `C:\\renjie-teo\\IS415-GAA\\exercises\\Hands-on_Ex01\\data\\geospatial\\preschools-location.kml' \n  using driver `KML'\nSimple feature collection with 1925 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nFrom the above message, it tells us that the dataset contains point features, containing 1359 features and 2 fields and is in the wgs84 projected coordinates system. Similarly, the bounding box provides us the x and y extents (x min, x max, y min, y max) of the data.\n\n\n\n\n\n\n\n\n\n\nDo recall that there are 2 different coordinate systems in use for the datasets here. Master Plan and Cycling Path utilises svy21 and Pre-Schools utilises wgs84."
  },
  {
    "objectID": "exercises/hoex1.html#st_geometry",
    "href": "exercises/hoex1.html#st_geometry",
    "title": "Hands-on Exercise 1: Geospatial Data Handling and Wrangling",
    "section": "2.1 st_geometry()",
    "text": "2.1 st_geometry()\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\nMULTIPOLYGON (((31495.56 30140.01, 31980.96 296...\n\n\nMULTIPOLYGON (((29092.28 30021.89, 29119.64 300...\n\n\nMULTIPOLYGON (((29932.33 29879.12, 29947.32 298...\n\n\nMULTIPOLYGON (((27131.28 30059.73, 27088.33 297...\n\n\nMULTIPOLYGON (((26451.03 30396.46, 26440.47 303...\n\n\nst_geometry() can help us obtain summarised details about a dataset about the geometry. In the case on The information provided is the same as what we have seen while importing the datasets earlier on."
  },
  {
    "objectID": "exercises/hoex1.html#glimpse",
    "href": "exercises/hoex1.html#glimpse",
    "title": "Hands-on Exercise 1: Geospatial Data Handling and Wrangling",
    "section": "2.2 glimpse()",
    "text": "2.2 glimpse()\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO <int> 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  <chr> \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  <chr> \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     <chr> \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N <chr> \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C <chr> \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   <chr> \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   <chr> \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    <chr> \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D <date> 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     <dbl> 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     <dbl> 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng <dbl> 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area <dbl> 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   <MULTIPOLYGON [m]> MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\n\nglimpse() can help us investigate what are the specific fields, its associated field data type and some sample data from the dataset to help us visualize the structure of the data."
  },
  {
    "objectID": "exercises/hoex1.html#head",
    "href": "exercises/hoex1.html#head",
    "title": "Hands-on Exercise 1: Geospatial Data Handling and Wrangling",
    "section": "2.3 head()",
    "text": "2.3 head()\n\nhead(mpsz, n=5)\n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n\n\nhead() can also help us obtain summarised details about a dataset as with glimpse(). Using the n=5 parameter inside function head, we are able to limit the amount of features to be shown to 5."
  },
  {
    "objectID": "exercises/hoex1.html#multi-plot-attributes",
    "href": "exercises/hoex1.html#multi-plot-attributes",
    "title": "Hands-on Exercise 1: Geospatial Data Handling and Wrangling",
    "section": "3.1 Multi-plot Attributes",
    "text": "3.1 Multi-plot Attributes\nThe following code will plot multiple attributes within the dataframe up to a reasonable limit.\n\nplot(mpsz)\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall"
  },
  {
    "objectID": "exercises/hoex1.html#geometry-plot",
    "href": "exercises/hoex1.html#geometry-plot",
    "title": "Hands-on Exercise 1: Geospatial Data Handling and Wrangling",
    "section": "3.2 Geometry Plot",
    "text": "3.2 Geometry Plot\nRecall st_geometry from Checking Content of a Simple Data Frame from earlier? st_geometry provides the geometry of the map, where we could use plot to plot just the geomtry of the data frame.\n\nplot(st_geometry(mpsz))"
  },
  {
    "objectID": "exercises/hoex1.html#specific-attributes",
    "href": "exercises/hoex1.html#specific-attributes",
    "title": "Hands-on Exercise 1: Geospatial Data Handling and Wrangling",
    "section": "3.3 Specific Attributes",
    "text": "3.3 Specific Attributes\nWe could also choose to plot a specific attribute of the data frame. The following code below will plot the PLN_AREA_N attribute.\n\nplot(mpsz[\"PLN_AREA_N\"])"
  },
  {
    "objectID": "exercises/hoex1.html#assigning-epsg-code-to-a-simple-feature-data-frame",
    "href": "exercises/hoex1.html#assigning-epsg-code-to-a-simple-feature-data-frame",
    "title": "Hands-on Exercise 1: Geospatial Data Handling and Wrangling",
    "section": "4.1 Assigning EPSG Code to a Simple Feature Data Frame",
    "text": "4.1 Assigning EPSG Code to a Simple Feature Data Frame\nThe coordinate system in the dataset could be wrongly assigned during the importing process or missing (missing .proj file for ESRI shapefile) when importing geospatial data into R.\n\n4.1.1 Checking the Coordinate System of the Data Frame\nTo check the coordinate system of a dataset, the st_crs() function of sf package could be used. Here, we check the coordinate system of mpsz simple feature data frame.\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nAlthough the data frame has been projected in SVY21, if we look at the end of the output, it indicates that the EPSG is 9001 which is incorrect. The correct EPSG code for SVY21 should be 3414.\nIn the code chunk below, we will correct the crs to EPSG 3414.\n\nmpsz3414 <- st_set_crs(mpsz,3414)\n\nWarning: st_crs<- : replacing crs does not reproject data; use st_transform for\nthat\n\n\nNow, let us check the crs if it has been updated.\n\nst_crs(mpsz3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nNow, the EPSG has been updated to 3414.\n\n\n4.1.2 Transforming from wgs84 to svy21\nIt is important in geospatial analytics to ensure that datasets are converted to projected coordinate system from the geographic coordinate system. Geographic coordinate system is not appropriate if analysis requires distance and/or area measurements.\n\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"geodetic latitude (Lat)\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"geodetic longitude (Lon)\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\n\nIn the preschools data frame, it is in the wgs84 coordinate system.\nSince reprojection is necessary from wgs84 to svy21 mathematically, st_set_crs() would not be appropriate. We will utilise st_transform().\nIn the example below, we reproject the preschools dataframe to svy21 (EPSG 3414).\n\npreschools3414 <- st_transform(preschools, crs = 3414)\n\nLet’s see the content of the reprojected preschools3414 dataframe.\n\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nNow, the data frame is in svy21 coordinate system.\n\n\n\n\n\n\nIf the bounding box values are greater than the 0-360 decimal degree used by most geographic coordinate system, it means it is likely to be in a projected coordinate system."
  },
  {
    "objectID": "exercises/hoex1.html#importing-aspatial-data",
    "href": "exercises/hoex1.html#importing-aspatial-data",
    "title": "Hands-on Exercise 1: Geospatial Data Handling and Wrangling",
    "section": "5.1 Importing Aspatial Data",
    "text": "5.1 Importing Aspatial Data\nSince listings data set is in csv format, we will used read_csv() of readr package to import listing.csv and output it to an R object called listings, which is a tibble data frame.\n\nlistings <- read_csv(\"Hands-on_Ex01/data/aspatial/listings.csv\")\n\nRows: 4161 Columns: 18\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (6): name, host_name, neighbourhood_group, neighbourhood, room_type, l...\ndbl  (11): id, host_id, latitude, longitude, price, minimum_nights, number_o...\ndate  (1): last_review\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nInstead of using glimpse() as shown earlier, list() could also do the job.\n\nlist(listings)\n\n[[1]]\n# A tibble: 4,161 × 18\n       id name     host_id host_…¹ neigh…² neigh…³ latit…⁴ longi…⁵ room_…⁶ price\n    <dbl> <chr>      <dbl> <chr>   <chr>   <chr>     <dbl>   <dbl> <chr>   <dbl>\n 1  50646 Pleasan…  227796 Sujatha Centra… Bukit …    1.33    104. Privat…    80\n 2  71609 Ensuite…  367042 Belinda East R… Tampin…    1.35    104. Privat…   145\n 3  71896 B&B  Ro…  367042 Belinda East R… Tampin…    1.35    104. Privat…    85\n 4  71903 Room 2-…  367042 Belinda East R… Tampin…    1.35    104. Privat…    85\n 5 275344 15 mins… 1439258 Kay     Centra… Bukit …    1.29    104. Privat…    49\n 6 289234 Booking…  367042 Belinda East R… Tampin…    1.34    104. Privat…   184\n 7 294281 5 mins … 1521514 Elizab… Centra… Newton     1.31    104. Privat…    79\n 8 324945 Cozy Bl… 1439258 Kay     Centra… Bukit …    1.29    104. Privat…    49\n 9 330089 Cozy Bl… 1439258 Kay     Centra… Bukit …    1.29    104. Privat…    55\n10 330095 10 mins… 1439258 Kay     Centra… Bukit …    1.29    104. Privat…    55\n# … with 4,151 more rows, 8 more variables: minimum_nights <dbl>,\n#   number_of_reviews <dbl>, last_review <date>, reviews_per_month <dbl>,\n#   calculated_host_listings_count <dbl>, availability_365 <dbl>,\n#   number_of_reviews_ltm <dbl>, license <chr>, and abbreviated variable names\n#   ¹​host_name, ²​neighbourhood_group, ³​neighbourhood, ⁴​latitude, ⁵​longitude,\n#   ⁶​room_type\n\n\nOur output shows our listing tibble data frame consists of 4161 rows and 18 columns. The useful fields we would be paying attention to is the latitude and longitude columns, which are in the decimal degree format. By assumption, we assume the data is in wgs84 Geographic Coordinate System."
  },
  {
    "objectID": "exercises/hoex1.html#creating-a-simple-feature-data-frame-from-an-aspatial-data-frame",
    "href": "exercises/hoex1.html#creating-a-simple-feature-data-frame-from-an-aspatial-data-frame",
    "title": "Hands-on Exercise 1: Geospatial Data Handling and Wrangling",
    "section": "5.2 Creating a Simple Feature Data Frame from an Aspatial Data Frame",
    "text": "5.2 Creating a Simple Feature Data Frame from an Aspatial Data Frame\nThe code below converts the listings tibble data fame into a simple feature data frame by using st_as_sf() from sf packages, which converts foreign data formats to an sf object.\n\nlistings_sf <- st_as_sf(listings,\n                        coords = c(\"longitude\", \"latitude\"),\n                        crs = 4326) %>%\n  st_transform(crs = 3414)\n\nThe arguments for\n\nlistings could be any other foreign data frame to be converted\ncoords requires to provide column name of x-coordinates followed by y-coordinates. The coordinates system also needs to be provided in terms of EPSG format. EPSG:4326 is the wgs84 Geographic Coordinate System whereas EPSG:3414 is Singapore’s svy21 Projected Coordinate System.\n%>% nest st_transform() into the st_as_sf() function to convert into svy21 coordinates"
  },
  {
    "objectID": "exercises/hoex1.html#examining-simple-feature-data-frame",
    "href": "exercises/hoex1.html#examining-simple-feature-data-frame",
    "title": "Hands-on Exercise 1: Geospatial Data Handling and Wrangling",
    "section": "5.3 Examining Simple Feature Data Frame",
    "text": "5.3 Examining Simple Feature Data Frame\n\nglimpse(listings_sf)\n\nRows: 4,161\nColumns: 17\n$ id                             <dbl> 50646, 71609, 71896, 71903, 275344, 289…\n$ name                           <chr> \"Pleasant Room along Bukit Timah\", \"Ens…\n$ host_id                        <dbl> 227796, 367042, 367042, 367042, 1439258…\n$ host_name                      <chr> \"Sujatha\", \"Belinda\", \"Belinda\", \"Belin…\n$ neighbourhood_group            <chr> \"Central Region\", \"East Region\", \"East …\n$ neighbourhood                  <chr> \"Bukit Timah\", \"Tampines\", \"Tampines\", …\n$ room_type                      <chr> \"Private room\", \"Private room\", \"Privat…\n$ price                          <dbl> 80, 145, 85, 85, 49, 184, 79, 49, 55, 5…\n$ minimum_nights                 <dbl> 92, 92, 92, 92, 60, 92, 92, 60, 60, 60,…\n$ number_of_reviews              <dbl> 18, 20, 24, 47, 14, 12, 133, 17, 12, 3,…\n$ last_review                    <date> 2014-12-26, 2020-01-17, 2019-10-13, 20…\n$ reviews_per_month              <dbl> 0.18, 0.15, 0.18, 0.34, 0.11, 0.10, 1.0…\n$ calculated_host_listings_count <dbl> 1, 6, 6, 6, 44, 6, 7, 44, 44, 44, 6, 7,…\n$ availability_365               <dbl> 365, 340, 265, 365, 296, 285, 365, 181,…\n$ number_of_reviews_ltm          <dbl> 0, 0, 0, 0, 1, 0, 0, 3, 2, 0, 1, 0, 0, …\n$ license                        <chr> NA, NA, NA, NA, \"S0399\", NA, NA, \"S0399…\n$ geometry                       <POINT [m]> POINT (22646.02 35167.9), POINT (…\n\n\nPreviously, there were 18 columns in the aspatial data, only 17 columns exists now. Longitude and Latitude columns were dropped and a new column has been created for geometry."
  },
  {
    "objectID": "exercises/hoex1.html#buffering",
    "href": "exercises/hoex1.html#buffering",
    "title": "Hands-on Exercise 1: Geospatial Data Handling and Wrangling",
    "section": "6.1 Buffering",
    "text": "6.1 Buffering\n\n\n\n\n\n\nScenario:\nThe authority is planning to upgrade the existing cycling path. To do so, they need to acquire 5 metres of reserved land on both sides of the current cycling path. You are tasked to determine the extent of land needed to be acquired and their total area.\n\n\n\nFirstly, we utilise st_buffer() of sf package to compute the 5-metre buffers around cycling paths.\n\nbuffer_cycling <- st_buffer(cyclingpath,\n                            dist = 5,\n                            nQuadSegs = 30)\n\nWhat nQuadSegs alters is the generalisation of points to create the buffer. More segments means it is less generalised and less segments means more generalised buffers.\nNext, we calculate the area of the buffers.\n\nbuffer_cycling$AREA <- st_area(buffer_cycling)\n\nNow, we can sum the area to get total land required for the buffer.\n\nsum(buffer_cycling$AREA)\n\n1556978 [m^2]"
  },
  {
    "objectID": "exercises/hoex1.html#point-in-polygon-count",
    "href": "exercises/hoex1.html#point-in-polygon-count",
    "title": "Hands-on Exercise 1: Geospatial Data Handling and Wrangling",
    "section": "6.2 Point-in-polygon Count",
    "text": "6.2 Point-in-polygon Count\n\n\n\n\n\n\nScenario:\nA pre-school service group wants to find the number of pre-schools in each Planning Subzone.\n\n\n\nFirstly, we utilise st_intersects() of sf package to find which pre-schools falls under which planning subzone. Then, using lengths, we calculate the number of pre-schools within each planning subzone.\n\nmpsz3414$`PreSch Count` <- lengths(st_intersects(mpsz3414, preschools3414))\n\nWe could use summary() to viewsummary statistics of the newly derived PreSch Count field.\n\nsummary(mpsz3414$`PreSch Count`)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    3.00    5.96    9.00   58.00 \n\n\nWow! Here, we can see that there is at least one planning subzone with 58 pre-schools, with a mean of 5.96 pre-schools in each subzone.\nNow, let’s look at the top sub-zone with the most pre-schools.\nThe code below utilises top_n of dplyr package to look in the mpsz3414 dataframe, under the field PreSch Count for the top record\n\ntop_n(mpsz3414, 1, `PreSch Count`)\n\nSimple feature collection with 1 feature and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 39655.33 ymin: 35966 xmax: 42940.57 ymax: 38622.37\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO     SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N PLN_AREA_C\n1      189          2 TAMPINES EAST    TMSZ02      N   TAMPINES         TM\n     REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR SHAPE_Leng\n1 EAST REGION       ER 21658EAAF84F4D8D 2014-12-05 41122.55 37392.39   10180.62\n  SHAPE_Area                       geometry PreSch Count\n1    4339824 MULTIPOLYGON (((42196.76 38...           58\n\n\nHere, we can see that the top planning subzone with the most preschools is Tampines East.\n\n\n\n\n\n\nScenario:\nCalculate the density of pre-school by planning subzone\n\n\n\nFirst, the formula for density is density = count / area\nWe will first calculate the area of each subzone below:\n\nmpsz3414$Area <- mpsz3414 %>%\n  st_area()\n\nNext, we will use mutate() of dplyr package to compute density. We multiply it by 1000000 to reduce the amount of decimal points by converting it to km2 for easier handling.\n\nmpsz3414 <- mpsz3414 %>%\n  mutate(`PreSch Density` = `PreSch Count`/Area * 1000000)\n\nNow, we can view the density of preschools.\n\nlist(mpsz3414$`PreSch Density`)\n\n[[1]]\nUnits: [1/m^2]\n  [1]  0.00000000  8.93150215  0.00000000  6.71784674  5.16223032  9.70516876\n  [7]  7.24989604  6.89216325  5.53101261  1.58316954  3.28434449  6.80952137\n [13]  0.00000000  2.54735962 11.84392175  0.00000000  0.00000000  0.00000000\n [19]  0.00000000  0.40657576  0.00000000  9.68631056  0.00000000  1.48058527\n [25] 10.83710054 15.70722567 35.60169297  5.47445116  6.18629982  8.20434375\n [31]  0.00000000  0.00000000  9.03949026  0.00000000  7.28645544 17.02931505\n [37] 25.35629701 15.89256712  0.00000000 11.15753677  0.00000000  8.55218466\n [43]  3.81906935  0.00000000  3.38235947  0.00000000 14.99604968  1.40732345\n [49]  8.01406205  0.00000000  0.56949216  5.86952041  3.03547315 11.71891220\n [55]  8.14148847  0.00000000  4.50504548  3.56920079  9.33487616  0.00000000\n [61]  5.62143826  0.00000000  3.14611804  9.93599725 17.95935646  0.00000000\n [67]  5.36153142  1.23223830  5.83558926  3.22047037  1.44233198  3.07398190\n [73]  2.21008233  5.73475293  0.00000000  0.00000000  1.82176954  9.49222530\n [79]  0.00000000  0.00000000  2.97422984  0.00000000  8.68525951  1.83998165\n [85]  7.18639790  0.00000000  0.00000000  5.36902632  0.00000000  2.38539919\n [91]  4.15173953  1.17625763  0.00000000  0.00000000  3.71428866  0.00000000\n [97]  0.00000000 10.30968514  0.00000000  3.52586966  6.81950547  0.00000000\n[103] 11.20672769  0.00000000  4.07884557  2.10935105  1.51390154  7.67355379\n[109] 10.89459084  9.34277714  0.00000000  0.00000000  5.19103594 10.30880422\n[115]  0.00000000  4.91199399  8.37774399 13.90186364 13.05635620  4.03408588\n[121]  4.68205034  0.00000000  0.00000000  0.00000000 10.30828105  6.59711016\n[127]  8.54111363  0.00000000  0.00000000  9.35774736  3.91277524  9.73248928\n[133]  9.52960696  4.07004471  9.01512182  0.88420004  5.85700658  9.21924053\n[139]  9.38756233  0.00000000  7.29210328 14.33152883  0.95320866  0.00000000\n[145]  1.22943315 14.14811689  0.00000000  4.82029416  4.96423679 10.81358754\n[151]  3.87478236 16.37550727  4.20286113  1.92511630  0.00000000  2.27575881\n[157]  3.78370366  0.00000000  4.54910663  9.37229330 11.20468789  0.00000000\n[163] 10.13730087  1.38998948 11.13208882  0.00000000  6.28324782 12.10849477\n[169]  1.46373505  5.42827717  2.50973772 11.03366227 10.52072865  9.49878064\n[175] 11.24580300 11.12890128 13.93950764  0.00000000  0.00000000 10.35889471\n[181]  6.12997351  8.63257212  6.52702292  0.00000000  6.45113675  8.65521161\n[187]  2.02537466  0.96587505 13.36459686  4.45419682  0.00000000  3.86526962\n[193] 12.69090170  5.93156946  1.62615585  2.07322060  7.12358161  8.11313906\n[199]  9.67642203 12.64374315  0.00000000 13.05378261  0.00000000 10.91908952\n[205]  4.47169158 10.97443928 15.73682882 10.53521767  0.00000000  7.86180592\n[211]  7.94696181  4.61489164  1.02119062  6.11811051 15.06832167 11.36765405\n[217]  7.09104861 10.31880873 11.98092893  5.46797281  0.00000000 16.45587097\n[223]  6.40125464 14.81499038  4.29058729  6.40314089  2.68546919  8.79682941\n[229]  0.47286030  2.09945890 11.21716914  3.17460839  4.01850845  0.00000000\n[235]  0.00000000  4.14472875 11.63901574 16.47133302  7.18459670  6.48975999\n[241] 10.17545246  4.63093287  9.05523476  1.03085549  2.42737742 11.58770447\n[247]  0.78643969 10.46342303 15.77874328  8.60077770  3.25580555  0.00000000\n[253] 21.90726711  5.95439968  1.62661251  0.00000000  0.00000000  4.07046653\n[259] 11.94152678 16.57069701  0.00000000  5.43686743 13.78099282 15.16440245\n[265]  0.00000000  8.46092732 14.10108710  0.00000000  0.05698650  0.00000000\n[271]  0.00000000 20.61136242 11.34007216  0.00000000 14.17732715  0.70978094\n[277]  4.41176266 34.93133940 11.45820473  0.00000000  0.00000000  7.61420607\n[283] 10.20733340 10.18622170  0.01433727  0.00000000 10.54179983  1.67883220\n[289]  0.00000000 18.40637075 23.89765810  0.78045947  9.23332461  0.00000000\n[295]  0.00000000  7.13352271  0.00000000  0.00000000  0.00000000  7.16914906\n[301]  0.00000000  0.00000000  0.13820154  0.00000000 11.25082456 17.08643178\n[307]  4.85251417  9.09591416  0.90530070 10.28168016  0.00000000  0.00000000\n[313]  0.00000000  0.25535809  0.00000000  0.00000000  1.39575809  0.00000000\n[319]  0.00000000  1.22409828  0.00000000  0.00000000  0.00000000"
  },
  {
    "objectID": "exercises/hoex1.html#investigating-pre-school-density",
    "href": "exercises/hoex1.html#investigating-pre-school-density",
    "title": "Hands-on Exercise 1: Geospatial Data Handling and Wrangling",
    "section": "7.1 Investigating Pre School Density",
    "text": "7.1 Investigating Pre School Density\nWe can plot a histogram to investigate the distrubtion of PreSch Density.\n\n7.1.1 Histogram (hist) of mpsz3414$PreSch Density\n\nhist(mpsz3414$`PreSch Density`)\n\n\n\n\nhist plots a histogram quickly from the data provided in PreSch Density. However it lacks customisation capabilities. We can customise it further to add appropriate labels using ggplot2.\n\n\n7.1.2 Histogram (ggplot2) of mpsz3414$PreSch Density\n\nggplot(data=mpsz3414,\n       aes(x= as.numeric(`PreSch Density`))) +\n  geom_histogram(bins=20,\n                 color=\"black\",\n                 fill=\"light blue\") +\n  labs(title = \"Are pre-schools even distributed in Singapore?\",\n       subtitle = \"There are many planning sub-zones with a single pre-school on the other hand, \\n there are six planning-subzones with at least 20 pre-schools\",\n       x = \"Pre-school density (per km sq)\",\n       y = \"Frequency\")\n\n\n\n\n\n\n\n\n\n\nScenario:\nUsing ggplot2, plot a scatterplot showing the relationship between Pre-school Density and Pre-school Count\n\n\n\n\nggplot(data=mpsz3414,\n       aes(x= as.numeric(`PreSch Density`), y = as.numeric(`PreSch Count`))) +\n  geom_point(color=\"black\",\n            fill=\"light blue\") +\n  xlim(0, 60) + \n  ylim(0, 60) +\n  labs(x = \"Pre-school density (per km sq)\",\n       y = \"Pre-school count\")\n\n\n\n\nHere, while the graph works without specifying xlim and ylim, we want to standardise the scales on x and y axes, hence, we specified the limits to be from 0 to 60 on both axes."
  },
  {
    "objectID": "exercises/hoex2.html",
    "href": "exercises/hoex2.html",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "",
    "text": "Firstly, the code below will check if pacman has been installed. If it has not been installed, R will download and install it, before activating it for use during this session.\n\nif (!require('pacman', character.only = T)){\n  install.packages('pacman')\n}\n\nLoading required package: pacman\n\nlibrary('pacman')\n\nNext, pacman assists us by helping us load R packages that we require, sf, tmap and tidyverse. terra is included as it is a dependency of tmap which may not install/load if terra has not been installed prior.\n\npacman::p_load(sf, tidyverse, tmap, terra)\n\n\n\n\nThe following public datasets are used:\n\n\n\nDataset Name\nSource\n\n\n\n\nMaster Plan 2014 Subzone Boundary (Web) (MP14_SUBZONE_WEB_PL.shp)\ndata.gov.sg\n\n\nSingapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling, June 2011-2020 (respopagesextod2011to2020.csv)\nDepartment of Statistics, Singapore\n\n\n\nThe Master Plan 2014 Subzone Boundary (Web) has been extracted to Hands-on_Ex02/data/geospatial whereas the Department of Statistics Singapore Resident dataset has been extracted to Hands-on_Ex02/data/aspatial.\n\n\n\nFirstly, we will import Master Plan 2014 Subzone Boundary (Web).\n\nmpsz = st_read(dsn = \"Hands-on_Ex02/data/geospatial\", layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\renjie-teo\\IS415-GAA\\exercises\\Hands-on_Ex02\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nFrom the above message, it tells us that the dataset contains multipolygon features, containing 323 multipolygon features and 15 fields in the mpsz simple feature data frame and is in the svy21 projected coordinates system. The bounding box provides us the x and y extents (x min, x max, y min, y max) of the data.\nWe can use mpsz to examine the contents.\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\nBy default, only the top 10 records are shown. To show more than 10 records, we can use a workaround below to print n = 15 records:\n\nmpsz %>% print(n = 15)\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 15 features:\n   OBJECTID SUBZONE_NO        SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1     MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1     PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3        BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8   HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3          REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7   ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9    BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2      CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13  PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7        QUEENSWAY    QTSZ07      N      QUEENSTOWN\n11       11         12       KENT RIDGE    QTSZ12      N      QUEENSTOWN\n12       12          6  ALEXANDRA NORTH    BMSZ06      N     BUKIT MERAH\n13       13          1      MARINA EAST    MESZ01      Y     MARINA EAST\n14       14          5 INSTITUTION HILL    RVSZ05      Y    RIVER VALLEY\n15       15          1   ROBERTSON QUAY    SRSZ01      Y SINGAPORE RIVER\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n11         QT CENTRAL REGION       CR 601BA309A1AAC731 2014-12-05 23464.84\n12         BM CENTRAL REGION       CR 4DC4BF8D86594CBF 2014-12-05 26548.25\n13         ME CENTRAL REGION       CR 782A2FAF53029A34 2014-12-05 32344.05\n14         RV CENTRAL REGION       CR C3C22D1EE31757BD 2014-12-05 28465.40\n15         SR CENTRAL REGION       CR DF71BB5EC3C9FFD1 2014-12-05 28416.85\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n11 29725.37   7439.548  1826848.6 MULTIPOLYGON (((23332.77 30...\n12 30519.39   2907.051   293706.4 MULTIPOLYGON (((26231.96 30...\n13 30103.25   6470.950  1844060.7 MULTIPOLYGON (((33214.62 29...\n14 30711.22   2842.526   392563.3 MULTIPOLYGON (((28481.45 30...\n15 30409.36   4995.758   506589.0 MULTIPOLYGON (((28087.34 30...\n\n\n\n\n\n\n\nTo check the coordinate system of a dataset, the st_crs() function of sf package could be used. Here, we check the coordinate system of mpsz simple feature data frame.\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nAlthough the data frame has been projected in SVY21, if we look at the end of the output, it indicates that the EPSG is 9001 which is incorrect. The correct EPSG code for SVY21 should be 3414.\nIn the code chunk below, we will correct the crs to EPSG 3414.\n\nmpsz3414 <- st_set_crs(mpsz,3414)\n\nWarning: st_crs<- : replacing crs does not reproject data; use st_transform for\nthat\n\n\nNow, let us check the crs if it has been updated.\n\nst_crs(mpsz3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nNow, the EPSG has been updated to 3414.\n\n\n\n\nSince population data set is in csv format, we will used read_csv() of readr package to import respopagesextod2011to2020.csv and output it to an R object called listings, which is a tibble data frame.\n\npopulation <- read_csv(\"Hands-on_Ex02/data/aspatial/respopagesextod2011to2020.csv\")\n\nRows: 984656 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): PA, SZ, AG, Sex, TOD\ndbl (2): Pop, Time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nlist(population)\n\n[[1]]\n# A tibble: 984,656 × 7\n   PA         SZ                     AG     Sex     TOD                Pop  Time\n   <chr>      <chr>                  <chr>  <chr>   <chr>            <dbl> <dbl>\n 1 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   HDB 1- and 2-Ro…     0  2011\n 2 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   HDB 3-Room Flats    10  2011\n 3 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   HDB 4-Room Flats    30  2011\n 4 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   HDB 5-Room and …    50  2011\n 5 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   HUDC Flats (exc…     0  2011\n 6 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   Landed Properti…     0  2011\n 7 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   Condominiums an…    40  2011\n 8 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   Others               0  2011\n 9 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Females HDB 1- and 2-Ro…     0  2011\n10 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Females HDB 3-Room Flats    10  2011\n# … with 984,646 more rows\n\n\nOur output shows our population tibble data frame consists of 984656 rows and 7 columns. The useful fields we would be paying attention to is the PA and SZ columns, which we will use to match to the geocodes with the Master plan dataset ."
  },
  {
    "objectID": "exercises/hoex2.html#data-wrangling",
    "href": "exercises/hoex2.html#data-wrangling",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "2.1 Data Wrangling",
    "text": "2.1 Data Wrangling\nWe need to perform some data wrangling and transformation to obtain the data in a format that we want to visualise it in.\nThe specific transformation we have to perform is to group various age groups into categories as mentioned above.\nWe could use the following functions to help us:\n\npivot_wider() of tidyr package, and\nmutate(), filter(), group_by() and select() of dplyr package\n\n\npopdata2020 <- population %>%\n  filter(Time == 2020) %>%\n  group_by(PA, SZ, AG) %>%\n  summarise(`POP` = sum(`Pop`)) %>%\n  ungroup()%>%\n  pivot_wider(names_from=AG, \n              values_from=POP) %>%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %>%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%>%\nmutate(`AGED`=rowSums(.[16:21])) %>%\nmutate(`TOTAL`=rowSums(.[3:21])) %>%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %>%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\n`summarise()` has grouped output by 'PA', 'SZ'. You can override using the\n`.groups` argument.\n\n\nFrom the code above, as the original table groups data into more specific breakdowns such as Sex and TOD which is not required for our analysis, we use group_by to regroup the data by PA, SZ and AG.\nThe summarise function sums the various pop values under the grouped rows together.\nAfter performing the calculations, we ungroup the data. Then, by utilising pivot_wider, we specify to shift the AG labels in many rows to become a column label. This will result in PA, SZ having a singular row, with the various AG as their individual column within the row.\nmutate is used to sum various values together to obtain the desired categories that was specified earlier. select statement writes the specific column values to the new dataframe."
  },
  {
    "objectID": "exercises/hoex2.html#joining-aspatial-and-geospatial-data",
    "href": "exercises/hoex2.html#joining-aspatial-and-geospatial-data",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "2.2 Joining Aspatial and Geospatial Data",
    "text": "2.2 Joining Aspatial and Geospatial Data\n\n2.2.1 Standardising Fields\nThe SZ and PA columns of the aspatial dataset maps directly to the SUBZONE_N and PLN_AREA_N columns of the master plan geospatial dataset.\nHowever, while the SUBZONE_N and PLN_AREA_N values are provided in all caps, SZ and PA comes in a mixture of upper and lowercase. We have to standardise the case.\n\npopdata2020 <- popdata2020 %>%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = funs(toupper)) %>%\n  filter(`ECONOMY ACTIVE` > 0)\n\nWarning: `funs()` was deprecated in dplyr 0.8.0.\nℹ Please use a list of either functions or lambdas:\n\n# Simple named list: list(mean = mean, median = median)\n\n# Auto named with `tibble::lst()`: tibble::lst(mean, median)\n\n# Using lambdas list(~ mean(., trim = .2), ~ median(., na.rm = TRUE))\n\n\nThe mutate_at function used above allows specific columns to be specified to perform specified functions, in this case, to convert to uppercase.\n\n\n2.2.2 Merge Geospatial and Apastial Data\nSimilar to SQL, we can left_join data from popdata2020 to mpsz. They will be merged based on the common identifier if SUBZONE_N and SZ matches.\n\nmpsz_pop2020 <- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\nWe will save the manipulated data into a rds file as a backup.\n\nwrite_rds(mpsz_pop2020, \"Hands-on_Ex02/data/rds/mpszpop2020.rds\")"
  },
  {
    "objectID": "exercises/hoex2.html#quick-start",
    "href": "exercises/hoex2.html#quick-start",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "3.1 Quick Start",
    "text": "3.1 Quick Start\nThe easiest method to plot a choropleth map using tmap is using qtm().\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")\n\n\n\n\nFrom the code above, we can understand that:\n\ntmap_mode() toggles between static (“plot”) or interactive modes (“view)\nfill argument is used to map the attribute (ie. DEPENDENCY in this case)"
  },
  {
    "objectID": "exercises/hoex2.html#creating-a-choropleth-map-by-using-tmaps-elements",
    "href": "exercises/hoex2.html#creating-a-choropleth-map-by-using-tmaps-elements",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "3.2 Creating a choropleth map by using tmap’s elements",
    "text": "3.2 Creating a choropleth map by using tmap’s elements\nWhile qtm() allows one to quickly plot a choropleth map, it is rigid and does not offer much flexibility and control over the map’s elements. Hence, tmap’s drawing elements should be used instead.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n3.2.1 Drawing a Base Map\nThe basic elements to creating a tmap includes, tm_shape(), followed by other layer elements such as tm_fill() and/or tm_polygons().\nIn the code below, tm_shape() defines the input data and tm_polygons() tells\nIn the code chunk below, tm_shape() is used to define the input data (i.e mpsz_pop2020) and tm_polygons() is used to draw the planning subzone polygons\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\n3.2.2 Drawing a Choropleth Map with tm_polygons()\nDrawing a choropleth map with tmap is rather simple. Simply specify the column name under tm_polygons.\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\nFrom the code above, we can understand from tm_polygons that:\n\nThe default interval binning used to draw the choropleth map is “pretty” which will be elaborated further in XX.XX.XX\nThe default colour scheme used is YlOrRd from ColorBrewer. This will be elaborated more in XX.XX.XX\nBy default, missing values are shaded in grey.\n\n\n\n3.2.3 Drawing a Choropleth Map with tm_fill() and tm_borders()\nWe can also use tm_fill() to draw a choropleth map.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\nFrom the map above, we can see that the map is coloured, without any lines.\nTo introduce light borders, we can use tm_borders().\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(lwd = 0.1,  alpha = 1)\n\n\n\n\nFor tm_borders(), there are four arguments that are accepted:\n\nalpha = transparency, 0 = transparent, 1 = opaque\ncol = border color\nlwd = border line width, default is 1\nlty = border line type, default is “solid”"
  },
  {
    "objectID": "exercises/hoex2.html#data-classification-methods",
    "href": "exercises/hoex2.html#data-classification-methods",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "3.3 Data Classification Methods",
    "text": "3.3 Data Classification Methods\nMost choropleth maps use some form of data classification, to group large numbers of observations into classes or n number of data ranges for classification.\ntmap provides a total ten data classification methods: fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks.\nThe style argument of tm_fill() or tm_polygons() can be used to define a data classification method.\n\n3.3.1 Plotting Chloropleth Maps with Built-in Classification Methods\nThe code below uses a quantile classification method. Jenks classifies data according to the natural breaks within the data.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nThe code below uses equal style, which creates n = 5 ranges which are equal in range.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n3.3.1.1 Differences between Classification Methods\nfixed:\nSpecify each range using the breaks argument manually. Does not require the use of n intervals.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"fixed\",\n          breaks = c(-Inf, seq(0, 10, by = 2.5), Inf) ) +\n  tm_borders(alpha = 0.5)\n\n\n\n\nsd:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"sd\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\npretty:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"pretty\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nkmeans:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"kmeans\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nhclust:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"hclust\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nbclust:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"bclust\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nCommittee Member: 1(1) 2(1) 3(1) 4(1) 5(1) 6(1) 7(1) 8(1) 9(1) 10(1)\nComputing Hierarchical Clustering\n\n\nfisher:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"fisher\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nquantile:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\nClassification Name\nDescription\n\n\n\n\nfixed\nBased on breaks specified\n\n\nsd\nn number of ranges, must ensure distribution is approx. normal. Measure of dispersion/dispersion (z scores)\n\n\nequal\nn number of ranges (excluding missing values), equal widths for each range, avoid if data is skewed or large outlier values (as in example above)\n\n\npretty (default)\nn number of ranges (including missing values), equal widths for each range, avoid if data is skewed or large outlier values (as in example above)\n\n\nquantile\nn number of ranges, equal number of observations in each range\n\n\nkmeans\nn number of ranges, runs euclidean distance computation between centroids and points and reassigns each points to closest cluster centroid until no change in cluster points or threshold is reached\n\n\nhclust\nn number of ranges, using divisive hierarchical clustering, splits until n number of clusters are obtained based on similarities with other points\n\n\nbclust\nn number of ranges, using bagged clustering\n\n\nfisher\nn number of ranges, using fisher clustering\n\n\njenks\nn number of ranges, based on natural breaks\n\n\n\n\n\n3.3.1.1 Differences between n ranges (using quantile)\nn = 2:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 2,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nn = 5:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nn = 10:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 10,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nn = 20:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 20,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nAs n amount of ranges increase, the colour differences between each subzone is more distinct. However, the amount of ranges depends on how fine grained the analysis has to be. Too many ranges could make it hard to pinpoint the exact colour and confuse users. Additionally, using quantile method, the outlier range (0.879 to 19.000) may mislead users as it is very similar in colour to the previous range (0.847 to 0.879)\n\n\n\n3.3.2 Plotting with Custom Breaks\nWe can specify breaks manually (as in the fixed style) instead of being automatically computed.\nFirst, we need to know our min and max ranges of the data\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.1111  0.7147  0.7866  0.8585  0.8763 19.0000      92 \n\n\nTo create custom breaks, we need to specify n+1 values to obtain n ranges as the values includes a min and max.\nThe code below creates breaks at 0.60, 0.70, 0.80, 0.90 with a min of 0 and max of 1.00.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(alpha = 0.5)\n\nWarning: Values have found that are higher than the highest break"
  },
  {
    "objectID": "exercises/hoex2.html#section",
    "href": "exercises/hoex2.html#section",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "",
    "text": "3.4 Colour Scheme\n\n3.4.1 Using ColorBrewer Palettes\nTo change the colour, we can use the palette argument. Here, we will change it to the blues colour scheme.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nWe can also reverse the colours using the - symbol infront of the desired color. In the below example, we use Greens.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "exercises/hoex2.html#map-layouts",
    "href": "exercises/hoex2.html#map-layouts",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "3.5 Map Layouts",
    "text": "3.5 Map Layouts\nA map layout contains different elements that adds up into a single map.\nOther than the objects to be mapped, map elements could include, title, scale bar, compass, margins, aspect ratios, colour settings and data classification methods.\n\n3.5.1 Map Legend\nThere are several legend options to change the placement, format and appearance of the legend.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n3.5.2 Map Style\nMap styles could be changed using the tmap_style() function from tmap. In the example below, the classic style is used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\ntmap style set to \"classic\"\n\n\nother available styles are: \"white\", \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"watercolor\" \n\n\n\n\n\n\n\n3.5.2 Cartographic Furniture\nWe can also draw various cartographic furniture onto the map, such as the scale bar, grid and compass.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\nTo reset the map to the default style, we can use the code below:\n\ntmap_style(\"white\")\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\""
  },
  {
    "objectID": "exercises/hoex2.html#drawing-small-choropleth-maps",
    "href": "exercises/hoex2.html#drawing-small-choropleth-maps",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "3.6 Drawing Small Choropleth Maps",
    "text": "3.6 Drawing Small Choropleth Maps\nWe can draw multiple small maps, also known as facet maps, arranged horizontally or stacked vertically to allow us to visualise how spatial relationships change with respect to another variable, such as time.\nUsing tmap, we can plot multiple small maps in three ways:\n\nassigning multiple values to at least one of the aesthetic arguments (eg. tmap_fill() or tmap_polygons())\ndefining a group-by variable in tm_facets()\ncreating multiple stand-alone maps with tmap_arrange()\n\n\n3.6.1 Assigning multiple values to at least one of the aesthetic arguments\nIn the example below, we specify multiple values using the c()\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\n\n\n\nWe can also specifically specify style and palette arguments for each map as shown below:\n\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n3.6.2 Defining a group-by variable in tm_facets()\nIn the example below, we create multiple maps using tm_facets(). The map is generated based on different values under the REGION_N column.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE, \n            drop.shapes=TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\nWarning: The argument drop.shapes has been renamed to drop.units, and is\ntherefore deprecated\n\n\n\n\n\n\n\n3.6.3 Creating Multiple Maps using tmap_arrange()\nIn the example below, we create multiple maps specified individually using tmap_arrange()\n\nyoungmap <- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap <- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)"
  },
  {
    "objectID": "exercises/hoex2.html#mapping-spatial-objects-meeting-a-selection-criterion",
    "href": "exercises/hoex2.html#mapping-spatial-objects-meeting-a-selection-criterion",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "3.6 Mapping Spatial Objects Meeting a Selection Criterion",
    "text": "3.6 Mapping Spatial Objects Meeting a Selection Criterion\nInstead of creating multiple choropleth maps, we can also use the selection function to map spatial objects meeting a certain criterion. In the example below, we only map objects that are in the CENTRAL REGION.\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\nWarning in pre_process_gt(x, interactive = interactive, orig_crs =\ngm$shape.orig_crs): legend.width controls the width of the legend within a map.\nPlease use legend.outside.size to control the width of the outside legend"
  },
  {
    "objectID": "exercises/hoex3.html",
    "href": "exercises/hoex3.html",
    "title": "Hands-on Exercise 3: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "",
    "text": "Spatial Point Pattern Analysis is the evaluation of the pattern or distribution, of a set of points on a surface. The point can be location of:\n\nevents such as crime, traffic accident and disease onset, or\nbusiness services (coffee and fastfood outlets) or facilities such as childcare and eldercare.\n\nUsing appropriate functions of spatstat, this hands-on exercise aims to discover the spatial point processes of childecare centres in Singapore.\nThe specific questions we would like to answer are as follows:\n\nare the childcare centres in Singapore randomly distributed throughout the country?\nif the answer is not, then the next logical question is where are the locations with higher concentration of childcare centres?\n\n\n\n\nFirstly, the code below will check if pacman has been installed. If it has not been installed, R will download and install it, before activating it for use during this session.\n\nif (!require('pacman', character.only = T)){\n  install.packages('pacman')\n}\nlibrary('pacman')\n\nNext, pacman assists us by helping us load R packages that we require, sf, tmap and maptools, spatstat, raster.\n\npacman::p_load(sf, tmap, maptools, spatstat, raster)\n\nThe following packages assists us to accomplish the following:\n\nsf helps to import, manage and process vector-based geospatial data in R\ntmap provides functions to allow us to plot high quality static or interactive maps using leaflet API\nmaptoolsI provides us a set of tools for manipulating geographic data\nspatstat has a wide range of functions for point pattern analysis\nraster reads, writes, manipulates, analyses and model of gridded spatial data (raster)\n\n\n\n\nThe following public datasets are used:\n\n\n\nDataset Name\nSource\n\n\n\n\nMaster Plan 2014 Subzone Boundary (Web) (MP14_SUBZONE_WEB_PL.shp)\ndata.gov.sg\n\n\nPre-Schools Location (preschools-location.geojson)\ndata.gov.sg\n\n\nCoastal Outline (CostalOutline.shp)\nProf Kam - SLA"
  },
  {
    "objectID": "exercises/hoex3.html#importing-spatial-data",
    "href": "exercises/hoex3.html#importing-spatial-data",
    "title": "Hands-on Exercise 3: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "Importing Spatial Data",
    "text": "Importing Spatial Data\nWe will use st_read() of sf package to import the three geospatial datasets.\n\nchildcare_sf <- st_read(dsn = \"Hands-on_Ex03/data/geospatial/child-care-services-geojson.geojson\")\n\nReading layer `child-care-services-geojson' from data source \n  `C:\\renjie-teo\\IS415-GAA\\exercises\\Hands-on_Ex03\\data\\geospatial\\child-care-services-geojson.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1545 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nsg_sf <- st_read(dsn = \"Hands-on_Ex03/data/geospatial\", layer = \"CostalOutline\")\n\nReading layer `CostalOutline' from data source \n  `C:\\renjie-teo\\IS415-GAA\\exercises\\Hands-on_Ex03\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21\n\n\n\nmpsz_sf <- st_read(dsn = \"Hands-on_Ex03/data/geospatial\", layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\renjie-teo\\IS415-GAA\\exercises\\Hands-on_Ex03\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21"
  },
  {
    "objectID": "exercises/hoex3.html#inspect-and-reproject-coordinate-system",
    "href": "exercises/hoex3.html#inspect-and-reproject-coordinate-system",
    "title": "Hands-on Exercise 3: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "Inspect and Reproject Coordinate System",
    "text": "Inspect and Reproject Coordinate System\n\nChildcare Dataset\nFirst, we inspect the crs of the sf dataframe.\n\nst_crs(childcare_sf)\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"geodetic latitude (Lat)\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"geodetic longitude (Lon)\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\n\nThe ID provided is EPSG:4326 which matches the intended WGS84 Coordinate reference. We will now convert the CRS from WGS84 Geographic Coordinate System to SVY21 Projected Coordinate System for further analysis.\n\nchildcare_sf <- st_transform(childcare_sf , crs = 3414)\n\n\n\nCoastal Outline Dataset\nFirst, we inspect the crs of the sf dataframe.\n\nst_crs(sg_sf)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nThe ID provided is EPSG:9001 which does not match the intended Projected CRS input of SVY21. Now, we correct the CRS ID using the code below.\n\nsg_sf <- st_set_crs(sg_sf,3414)\n\nNow, let us check if the CRS ID has been set correctly:\n\nst_crs(sg_sf)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\nMaster Plan Subzone Dataset\nFirst, we inspect the crs of the sf dataframe.\n\nst_crs(mpsz_sf)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nThe ID provided is EPSG:9001 which does not match the intended Projected CRS input of SVY21. Now, we correct the CRS ID using the code below.\n\nmpsz_sf <- st_set_crs(mpsz_sf,3414)\n\nNow, let us check if the CRS ID has been set correctly:\n\nst_crs(mpsz_sf)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]"
  },
  {
    "objectID": "exercises/hoex3.html#mapping-the-geospatial-datasets",
    "href": "exercises/hoex3.html#mapping-the-geospatial-datasets",
    "title": "Hands-on Exercise 3: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "Mapping the Geospatial Datasets",
    "text": "Mapping the Geospatial Datasets\nAfter checking the CRS of each geospatial data frame, we can plot a map to see their spatial patterns.\n\nStatic Map\nFirst, we will create a static map to get a general feel of the dataset.\n\nchildcare_sf\n\nSimple feature collection with 1545 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 11203.01 ymin: 25667.6 xmax: 45404.24 ymax: 49300.88\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n     Name\n1   kml_1\n2   kml_2\n3   kml_3\n4   kml_4\n5   kml_5\n6   kml_6\n7   kml_7\n8   kml_8\n9   kml_9\n10 kml_10\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Description\n1                     <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSBLOCKHOUSENUMBER</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSBUILDINGNAME</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSPOSTALCODE</th> <td>760742</td> </tr><tr bgcolor=\"\"> <th>ADDRESSSTREETNAME</th> <td>742, YISHUN AVENUE 5, #01 - 470, SINGAPORE 760742</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSTYPE</th> <td></td> </tr><tr bgcolor=\"\"> <th>DESCRIPTION</th> <td>Child Care Services</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>HYPERLINK</th> <td></td> </tr><tr bgcolor=\"\"> <th>LANDXADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>LANDYADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"\"> <th>NAME</th> <td>AVERBEL CHILD DEVELOPMENT CENTRE PTE LTD</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>PHOTOURL</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSFLOORNUMBER</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>AEA27114446235CE</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20200826094036</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSUNITNUMBER</th> <td></td> </tr></table></center>\n2                                                        <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSBLOCKHOUSENUMBER</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSBUILDINGNAME</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSPOSTALCODE</th> <td>159053</td> </tr><tr bgcolor=\"\"> <th>ADDRESSSTREETNAME</th> <td>20, LENGKOK BAHRU, #02 - 05, SINGAPORE 159053</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSTYPE</th> <td></td> </tr><tr bgcolor=\"\"> <th>DESCRIPTION</th> <td>Child Care Services</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>HYPERLINK</th> <td></td> </tr><tr bgcolor=\"\"> <th>LANDXADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>LANDYADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"\"> <th>NAME</th> <td>AWWA LTD.</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>PHOTOURL</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSFLOORNUMBER</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>86B24416FB1663C6</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20200826094036</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSUNITNUMBER</th> <td></td> </tr></table></center>\n3                            <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSBLOCKHOUSENUMBER</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSBUILDINGNAME</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSPOSTALCODE</th> <td>556912</td> </tr><tr bgcolor=\"\"> <th>ADDRESSSTREETNAME</th> <td>22, LI HWAN VIEW, GOLDEN HILL ESTATE, SINGAPORE 556912</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSTYPE</th> <td></td> </tr><tr bgcolor=\"\"> <th>DESCRIPTION</th> <td>Child Care Services</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>HYPERLINK</th> <td></td> </tr><tr bgcolor=\"\"> <th>LANDXADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>LANDYADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"\"> <th>NAME</th> <td>BABIES BY-THE-PARK PTE. LTD.</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>PHOTOURL</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSFLOORNUMBER</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>F971CBBA973E1AE5</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20200826094036</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSUNITNUMBER</th> <td></td> </tr></table></center>\n4                     <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSBLOCKHOUSENUMBER</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSBUILDINGNAME</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSPOSTALCODE</th> <td>569139</td> </tr><tr bgcolor=\"\"> <th>ADDRESSSTREETNAME</th> <td>3, ANG MO KIO STREET 62, #01 - 36, LINK@AMK, SINGAPORE 569139</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSTYPE</th> <td></td> </tr><tr bgcolor=\"\"> <th>DESCRIPTION</th> <td>Child Care Services</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>HYPERLINK</th> <td></td> </tr><tr bgcolor=\"\"> <th>LANDXADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>LANDYADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"\"> <th>NAME</th> <td>Baby Elk Infant Care Pte Ltd</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>PHOTOURL</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSFLOORNUMBER</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>86A4F25D1C7C9D85</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20200826094036</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSUNITNUMBER</th> <td></td> </tr></table></center>\n5                                               <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSBLOCKHOUSENUMBER</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSBUILDINGNAME</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSPOSTALCODE</th> <td>467961</td> </tr><tr bgcolor=\"\"> <th>ADDRESSSTREETNAME</th> <td>22A, KEW DRIVE, SINGAPORE 467961</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSTYPE</th> <td></td> </tr><tr bgcolor=\"\"> <th>DESCRIPTION</th> <td>Child Care Services</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>HYPERLINK</th> <td></td> </tr><tr bgcolor=\"\"> <th>LANDXADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>LANDYADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"\"> <th>NAME</th> <td>BABYPLANET MONTESSORI PTE. LTD.</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>PHOTOURL</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSFLOORNUMBER</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>CFE3F056F8171C7B</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20200826094036</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSUNITNUMBER</th> <td></td> </tr></table></center>\n6                                           <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSBLOCKHOUSENUMBER</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSBUILDINGNAME</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSPOSTALCODE</th> <td>598523</td> </tr><tr bgcolor=\"\"> <th>ADDRESSSTREETNAME</th> <td>3 Jalan Kakatua, JURONG PARK, SINGAPORE 598523</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSTYPE</th> <td></td> </tr><tr bgcolor=\"\"> <th>DESCRIPTION</th> <td>Child Care Services</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>HYPERLINK</th> <td></td> </tr><tr bgcolor=\"\"> <th>LANDXADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>LANDYADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"\"> <th>NAME</th> <td>BAMBINI CHILDCARE LLP</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>PHOTOURL</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSFLOORNUMBER</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>2B4F0B285ED28C4A</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20200826094036</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSUNITNUMBER</th> <td></td> </tr></table></center>\n7                              <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSBLOCKHOUSENUMBER</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSBUILDINGNAME</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSPOSTALCODE</th> <td>160131</td> </tr><tr bgcolor=\"\"> <th>ADDRESSSTREETNAME</th> <td>131, JALAN BUKIT MERAH, #01 - 1591, SINGAPORE 160131</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSTYPE</th> <td></td> </tr><tr bgcolor=\"\"> <th>DESCRIPTION</th> <td>Child Care Services</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>HYPERLINK</th> <td></td> </tr><tr bgcolor=\"\"> <th>LANDXADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>LANDYADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"\"> <th>NAME</th> <td>BAMBINI MONTESSORI PTE. LTD.</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>PHOTOURL</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSFLOORNUMBER</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>F62A225197813BBD</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20200826094036</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSUNITNUMBER</th> <td></td> </tr></table></center>\n8                        <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSBLOCKHOUSENUMBER</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSBUILDINGNAME</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSPOSTALCODE</th> <td>543319</td> </tr><tr bgcolor=\"\"> <th>ADDRESSSTREETNAME</th> <td>319C, ANCHORVALE DRIVE, #01 - 66, SINGAPORE 543319</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSTYPE</th> <td></td> </tr><tr bgcolor=\"\"> <th>DESCRIPTION</th> <td>Child Care Services</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>HYPERLINK</th> <td></td> </tr><tr bgcolor=\"\"> <th>LANDXADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>LANDYADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"\"> <th>NAME</th> <td>BERRY TREE PRESCHOOL PRIVATE LIMITED</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>PHOTOURL</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSFLOORNUMBER</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>AE242159867D5EB2</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20200826094036</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSUNITNUMBER</th> <td></td> </tr></table></center>\n9  <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSBLOCKHOUSENUMBER</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSBUILDINGNAME</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSPOSTALCODE</th> <td>750511</td> </tr><tr bgcolor=\"\"> <th>ADDRESSSTREETNAME</th> <td>511, CANBERRA ROAD, #03 - 02, SEMBAWANG MART, SINGAPORE 750511</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSTYPE</th> <td></td> </tr><tr bgcolor=\"\"> <th>DESCRIPTION</th> <td>Child Care Services</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>HYPERLINK</th> <td></td> </tr><tr bgcolor=\"\"> <th>LANDXADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>LANDYADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"\"> <th>NAME</th> <td>BERRY TREE PRESCHOOL@SEMBAWANG PRIVATE LIMITED</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>PHOTOURL</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSFLOORNUMBER</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>C1456F97A17ED64A</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20200826094036</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSUNITNUMBER</th> <td></td> </tr></table></center>\n10                    <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSBLOCKHOUSENUMBER</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSBUILDINGNAME</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSPOSTALCODE</th> <td>823195</td> </tr><tr bgcolor=\"\"> <th>ADDRESSSTREETNAME</th> <td>195C, PUNGGOL ROAD, #01 - 532, THE PERIWINKLE, SINGAPORE 823195</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSTYPE</th> <td></td> </tr><tr bgcolor=\"\"> <th>DESCRIPTION</th> <td>Child Care Services</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>HYPERLINK</th> <td></td> </tr><tr bgcolor=\"\"> <th>LANDXADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>LANDYADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"\"> <th>NAME</th> <td>BERRY TREE@PUNGGOL PTE LTD</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>PHOTOURL</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSFLOORNUMBER</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>4F6A8FCA467C3437</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20200826094036</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSUNITNUMBER</th> <td></td> </tr></table></center>\n                        geometry\n1   POINT Z (27976.73 45716.7 0)\n2     POINT Z (25824 29900.09 0)\n3  POINT Z (31399.04 37416.36 0)\n4   POINT Z (29268.43 40942.1 0)\n5  POINT Z (41217.74 33554.94 0)\n6  POINT Z (20644.07 36118.78 0)\n7  POINT Z (27427.95 29182.36 0)\n8  POINT Z (34378.47 41423.03 0)\n9  POINT Z (26467.04 48384.34 0)\n10 POINT Z (36173.81 42550.33 0)\n\n\n\ntm_shape(sg_sf)+\n  tm_polygons() +\ntm_shape(mpsz_sf) +\n  tm_polygons() +\ntm_shape(childcare_sf) +\n  tm_dots()\n\n\n\n\nHere, we do not see any anomalies, all the geospatial points are within the map’s context, which means that the reference system and coordinate values are referred to the similar spatial context.\nWe can also prepare a pin map (interactive) by using the code below\n\ntmap_mode('view') +\ntm_shape(childcare_sf) +\n  tm_dots()\n\n\n\n\n\n\nFrom the interactive map above, we can see that tmap is ustilising the leaflet for R API, which allows us to interact, navigate, zoom and query each simple feature. Changing the background of the map is also possible.\nAfter setting the tmap_mode() to view we need to remember to switch it back to plot."
  },
  {
    "objectID": "exercises/hoex3.html#converting-sf-dataframes-to-sps-spatial-class",
    "href": "exercises/hoex3.html#converting-sf-dataframes-to-sps-spatial-class",
    "title": "Hands-on Exercise 3: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "Converting sf Dataframes to sp’s Spatial* Class",
    "text": "Converting sf Dataframes to sp’s Spatial* Class\nWhile simple feature data frame is gaining in popularity, many geospatial analysis packages still require the input geospatial data in sp’s Spatial* classes. We will convert the sf data frames to sp’s Spatial* Class below.\n\nchildcare <- as_Spatial(childcare_sf)\nmpsz <- as_Spatial(mpsz_sf)\nsg <- as_Spatial(sg_sf)\n\nNow, let’s view the information of the Spatial* classes below:\n\nchildcare\n\nclass       : SpatialPointsDataFrame \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 2\nnames       :    Name,                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Description \nmin values  :   kml_1, <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSBLOCKHOUSENUMBER</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSBUILDINGNAME</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSPOSTALCODE</th> <td>018989</td> </tr><tr bgcolor=\"\"> <th>ADDRESSSTREETNAME</th> <td>1, MARINA BOULEVARD, #B1 - 01, ONE MARINA BOULEVARD, SINGAPORE 018989</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSTYPE</th> <td></td> </tr><tr bgcolor=\"\"> <th>DESCRIPTION</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>HYPERLINK</th> <td></td> </tr><tr bgcolor=\"\"> <th>LANDXADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>LANDYADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"\"> <th>NAME</th> <td>THE LITTLE SKOOL-HOUSE INTERNATIONAL PTE. LTD.</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>PHOTOURL</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSFLOORNUMBER</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>08F73931F4A691F4</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20200826094036</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSUNITNUMBER</th> <td></td> </tr></table></center> \nmax values  : kml_999,                  <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSBLOCKHOUSENUMBER</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSBUILDINGNAME</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSPOSTALCODE</th> <td>829646</td> </tr><tr bgcolor=\"\"> <th>ADDRESSSTREETNAME</th> <td>200, PONGGOL SEVENTEENTH AVENUE, SINGAPORE 829646</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSTYPE</th> <td></td> </tr><tr bgcolor=\"\"> <th>DESCRIPTION</th> <td>Child Care Services</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>HYPERLINK</th> <td></td> </tr><tr bgcolor=\"\"> <th>LANDXADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>LANDYADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"\"> <th>NAME</th> <td>RAFFLES KIDZ @ PUNGGOL PTE LTD</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>PHOTOURL</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSFLOORNUMBER</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>379D017BF244B0FA</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20200826094036</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSUNITNUMBER</th> <td></td> </tr></table></center> \n\n\n\nmpsz\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 323 \nextent      : 2667.538, 56396.44, 15748.72, 50256.33  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 15\nnames       : OBJECTID, SUBZONE_NO, SUBZONE_N, SUBZONE_C, CA_IND, PLN_AREA_N, PLN_AREA_C,       REGION_N, REGION_C,          INC_CRC, FMEL_UPD_D,     X_ADDR,     Y_ADDR,    SHAPE_Leng,    SHAPE_Area \nmin values  :        1,          1, ADMIRALTY,    AMSZ01,      N, ANG MO KIO,         AM, CENTRAL REGION,       CR, 00F5E30B5C9B7AD8,      16409,  5092.8949,  19579.069, 871.554887798, 39437.9352703 \nmax values  :      323,         17,    YUNNAN,    YSSZ09,      Y,     YISHUN,         YS,    WEST REGION,       WR, FFCCF172717C2EAF,      16409, 50424.7923, 49552.7904, 68083.9364708,  69748298.792 \n\n\n\nsg\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 4\nnames       : GDO_GID, MSLINK, MAPID,              COSTAL_NAM \nmin values  :       1,      1,     0,             ISLAND LINK \nmax values  :      60,     67,     0, SINGAPORE - MAIN ISLAND \n\n\nNow, they have been correctly converted into sp’s Spatial* classes."
  },
  {
    "objectID": "exercises/hoex3.html#converting-the-spatial-class-into-generic-sp-format",
    "href": "exercises/hoex3.html#converting-the-spatial-class-into-generic-sp-format",
    "title": "Hands-on Exercise 3: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "Converting the Spatial* Class into Generic sp Format",
    "text": "Converting the Spatial* Class into Generic sp Format\nspstat requires the analytical data to be in ppp object form. As there is no direct method to convert Spatial* classes to ppp object, we need to convert the Spatial* classes into an intermediate Spatial object first.\nThecode below converts Spatial* Classes into generic sp objects\n\nchildcare_sp <- as(childcare, \"SpatialPoints\")\nsg_sp <- as(sg, \"SpatialPolygons\")\n\nNext, we can check the sp object properties.\n\nchildcare_sp\n\nclass       : SpatialPoints \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \n\n\n\nsg_sp\n\nclass       : SpatialPolygons \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \n\n\nComparing the sp object and Spatial* Classes, the variables, names, min and max values are omitted from the sp object but present in Spatial* Classes."
  },
  {
    "objectID": "exercises/hoex3.html#converting-the-generic-sp-format-into-spatstats-ppp-format",
    "href": "exercises/hoex3.html#converting-the-generic-sp-format-into-spatstats-ppp-format",
    "title": "Hands-on Exercise 3: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "Converting the Generic sp Format into spatstat’s ppp Format",
    "text": "Converting the Generic sp Format into spatstat’s ppp Format\nNow, we will use as.ppp() function of spatstat to convert the spatial data into spatstat’s ppp object format.\n\nchildcare_ppp <- as(childcare_sp, \"ppp\")\nchildcare_ppp\n\nPlanar point pattern: 1545 points\nwindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n\n\nNow, let us plot childcare_ppp and examine the difference\n\nplot(childcare_ppp)\n\n\n\n\nWe can take a quick look at the summary statistics of the newly created ppp object by using the code below:\n\nsummary(childcare_ppp)\n\nPlanar point pattern:  1545 points\nAverage intensity 1.91145e-06 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 3 decimal places\ni.e. rounded to the nearest multiple of 0.001 units\n\nWindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n                    (34200 x 23630 units)\nWindow area = 808287000 square units\n\n\nNote the warning message about duplicates. The statistical methodology used for spatial points pattern processes is based largely on the assumption that processes are simple, that means that the points cannot be coincident."
  },
  {
    "objectID": "exercises/hoex3.html#handling-duplicated-points",
    "href": "exercises/hoex3.html#handling-duplicated-points",
    "title": "Hands-on Exercise 3: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "Handling duplicated points",
    "text": "Handling duplicated points\nWe can check the duplication in a ppp object using the code below\n\nany(duplicated(childcare_ppp))\n\n[1] TRUE\n\n\nTo count the number of coincident points, we can use the multiplicity() function as shown in the code chunk below.\n\nmultiplicity(childcare_ppp)\n\n   1    2    3    4    5    6    7    8    9   10   11   12   13   14   15   16 \n   1    1    1    3    1    1    1    1    2    1    1    1    1    1    1    1 \n  17   18   19   20   21   22   23   24   25   26   27   28   29   30   31   32 \n   1    1    1    1    1    1    1    1    1    1    9    1    1    1    1    1 \n  33   34   35   36   37   38   39   40   41   42   43   44   45   46   47   48 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n  49   50   51   52   53   54   55   56   57   58   59   60   61   62   63   64 \n   1    1    1    1    1    1    2    1    1    3    1    1    1    1    1    1 \n  65   66   67   68   69   70   71   72   73   74   75   76   77   78   79   80 \n   1    1    1    1    1    2    1    1    1    1    1    2    1    1    1    1 \n  81   82   83   84   85   86   87   88   89   90   91   92   93   94   95   96 \n   1    1    1    3    1    1    1    1    1    1    1    1    1    1    1    1 \n  97   98   99  100  101  102  103  104  105  106  107  108  109  110  111  112 \n   1    1    1    1    1    1    1    1    2    1    1    1    1    1    1    1 \n 113  114  115  116  117  118  119  120  121  122  123  124  125  126  127  128 \n   1    1    1    1    1    1    2    1    1    1    3    1    1    1    2    1 \n 129  130  131  132  133  134  135  136  137  138  139  140  141  142  143  144 \n   1    1    1    1    1    2    1    1    1    1    1    1    1    1    3    2 \n 145  146  147  148  149  150  151  152  153  154  155  156  157  158  159  160 \n   1    2    1    1    1    2    2    3    1    5    1    5    1    1    1    2 \n 161  162  163  164  165  166  167  168  169  170  171  172  173  174  175  176 \n   1    1    1    1    2    1    1    1    1    1    1    2    1    1    1    1 \n 177  178  179  180  181  182  183  184  185  186  187  188  189  190  191  192 \n   1    4    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 193  194  195  196  197  198  199  200  201  202  203  204  205  206  207  208 \n   1    1    1    1    1    2    2    1    1    1    1    2    1    4    1    1 \n 209  210  211  212  213  214  215  216  217  218  219  220  221  222  223  224 \n   2    1    1    1    1    1    1    1    1    1    1    1    2    1    1    1 \n 225  226  227  228  229  230  231  232  233  234  235  236  237  238  239  240 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 241  242  243  244  245  246  247  248  249  250  251  252  253  254  255  256 \n   1    1    1    1    2    1    1    1    1    1    1    1    1    1    1    1 \n 257  258  259  260  261  262  263  264  265  266  267  268  269  270  271  272 \n   1    1    1    1    1    1    1    1    1    1    2    1    1    1    1    3 \n 273  274  275  276  277  278  279  280  281  282  283  284  285  286  287  288 \n   1    1    1    1    1    1    3    1    1    1    1    1    1    1    1    1 \n 289  290  291  292  293  294  295  296  297  298  299  300  301  302  303  304 \n   1    1    1    1    1    1    1    9    1    1    2    1    1    1    1    1 \n 305  306  307  308  309  310  311  312  313  314  315  316  317  318  319  320 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 321  322  323  324  325  326  327  328  329  330  331  332  333  334  335  336 \n   1    1    1    5    1    1    1    1    1    2    1    1    2    2    1    1 \n 337  338  339  340  341  342  343  344  345  346  347  348  349  350  351  352 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    2    2    1 \n 353  354  355  356  357  358  359  360  361  362  363  364  365  366  367  368 \n   1    1    1    1    9    1    1    1    1    1    1    1    1    1    1    1 \n 369  370  371  372  373  374  375  376  377  378  379  380  381  382  383  384 \n   1    3    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 385  386  387  388  389  390  391  392  393  394  395  396  397  398  399  400 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 401  402  403  404  405  406  407  408  409  410  411  412  413  414  415  416 \n   1    1    2    1    1    1    1    1    1    1    2    1    1    1    1    1 \n 417  418  419  420  421  422  423  424  425  426  427  428  429  430  431  432 \n   1    1    1    1    1    1    1    2    1    1    2    1    1    1    1    1 \n 433  434  435  436  437  438  439  440  441  442  443  444  445  446  447  448 \n   1    1    1    1    2    1    1    1    1    1    1    1    1    1    1    1 \n 449  450  451  452  453  454  455  456  457  458  459  460  461  462  463  464 \n   1    1    9    9    1    1    1    1    1    1    1    1    1    1    2    1 \n 465  466  467  468  469  470  471  472  473  474  475  476  477  478  479  480 \n   2    1    1    1    1    1    1    1    1    1    1    1    2    2    1    1 \n 481  482  483  484  485  486  487  488  489  490  491  492  493  494  495  496 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 497  498  499  500  501  502  503  504  505  506  507  508  509  510  511  512 \n   1    1    1    1    1    1    2    1    1    1    1    1    1    1    1    2 \n 513  514  515  516  517  518  519  520  521  522  523  524  525  526  527  528 \n   1    1    1    1    1    1    1    1    1    1    1    2    1    1    3    1 \n 529  530  531  532  533  534  535  536  537  538  539  540  541  542  543  544 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 545  546  547  548  549  550  551  552  553  554  555  556  557  558  559  560 \n   1    1    1    1    1    1    1    1    1    3    1    1    1    1    1    1 \n 561  562  563  564  565  566  567  568  569  570  571  572  573  574  575  576 \n   2    2    2    1    1    1    1    2    1    1    2    1    1    1    2    1 \n 577  578  579  580  581  582  583  584  585  586  587  588  589  590  591  592 \n   1    2    1    1    1    1    1    9    1    4    1    2    1    1    1    1 \n 593  594  595  596  597  598  599  600  601  602  603  604  605  606  607  608 \n   2    1    1    1    1    1    1    1    2    1    2    1    1    1    1    1 \n 609  610  611  612  613  614  615  616  617  618  619  620  621  622  623  624 \n   1    1    1    1    1    1    1    1    1    2    1    2    1    1    1    1 \n 625  626  627  628  629  630  631  632  633  634  635  636  637  638  639  640 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 641  642  643  644  645  646  647  648  649  650  651  652  653  654  655  656 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    4 \n 657  658  659  660  661  662  663  664  665  666  667  668  669  670  671  672 \n   1    1    1    1    1    1    1    3    1    1    1    1    1    1    1    1 \n 673  674  675  676  677  678  679  680  681  682  683  684  685  686  687  688 \n   1    1    1    1    1    4    1    1    1    1    1    4    1    1    1    1 \n 689  690  691  692  693  694  695  696  697  698  699  700  701  702  703  704 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 705  706  707  708  709  710  711  712  713  714  715  716  717  718  719  720 \n   1    1    2    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 721  722  723  724  725  726  727  728  729  730  731  732  733  734  735  736 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 737  738  739  740  741  742  743  744  745  746  747  748  749  750  751  752 \n   1    2    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 753  754  755  756  757  758  759  760  761  762  763  764  765  766  767  768 \n   1    1    1    1    1    2    1    1    1    1    1    1    1    1    1    1 \n 769  770  771  772  773  774  775  776  777  778  779  780  781  782  783  784 \n   1    1    1    1    1    1    1    1    1    4    1    1    1    1    1    1 \n 785  786  787  788  789  790  791  792  793  794  795  796  797  798  799  800 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 801  802  803  804  805  806  807  808  809  810  811  812  813  814  815  816 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 817  818  819  820  821  822  823  824  825  826  827  828  829  830  831  832 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 833  834  835  836  837  838  839  840  841  842  843  844  845  846  847  848 \n   1    1    1    1    1    1    1    2    1    1    1    1    1    1    1    1 \n 849  850  851  852  853  854  855  856  857  858  859  860  861  862  863  864 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 865  866  867  868  869  870  871  872  873  874  875  876  877  878  879  880 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    2 \n 881  882  883  884  885  886  887  888  889  890  891  892  893  894  895  896 \n   3    1    1    1    2    1    1    1    3    1    1    3    1    1    1    1 \n 897  898  899  900  901  902  903  904  905  906  907  908  909  910  911  912 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 913  914  915  916  917  918  919  920  921  922  923  924  925  926  927  928 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 929  930  931  932  933  934  935  936  937  938  939  940  941  942  943  944 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 945  946  947  948  949  950  951  952  953  954  955  956  957  958  959  960 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    2 \n 961  962  963  964  965  966  967  968  969  970  971  972  973  974  975  976 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 977  978  979  980  981  982  983  984  985  986  987  988  989  990  991  992 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 993  994  995  996  997  998  999 1000 1001 1002 1003 1004 1005 1006 1007 1008 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 \n   1    1    1    1    1    1    1    1    1    2    2    1    1    1    1    1 \n1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 \n   1    1    1    1    1    2    1    1    1    1    1    1    1    1    1    1 \n1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 \n   1    1    1    1    1    1    1    1    2    2    1    1    1    5    1    1 \n1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 \n   1    1    1    1    1    1    1    1    1    2    1    1    1    1    1    1 \n1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 \n   1    1    1    1    1    1    1    1    1    1    2    1    1    1    1    1 \n1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 \n   1    9    1    2    2    1    1    1    2    1    1    1    1    1    1    1 \n1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 \n   1    1    1    1    2    1    1    1    3    1    1    1    1    1    1    1 \n1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 \n   9    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 \n   1    1    1    2    1    1    1    1    1    1    1    1    1    1    1    1 \n1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    2 \n1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 \n   1    1    1    2    1    2    1    1    1    2    2    2    1    1    1    1 \n1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 \n   1    1    2    1    1    1    1    1    1    1    1    1    2    1    1    1 \n1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 \n   1    1    1    1    3    1    1    1    1    1    1    1    1    1    1    1 \n1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 \n   1    1    1    1    1    1    1    1    4    1    1    1    1    1    2    1 \n1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 \n   1    1    1    1    1    1    1    1    1    9    1    1    1    1    1    1 \n1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 1424 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1425 1426 1427 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    2    1 \n1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 \n   1    2    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1457 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 1471 1472 \n   1    1    1    1    1    1    1    1    1    1    2    1    1    1    1    1 \n1473 1474 1475 1476 1477 1478 1479 1480 1481 1482 1483 1484 1485 1486 1487 1488 \n   1    1    1    1    1    1    2    1    1    1    1    1    1    1    1    1 \n1489 1490 1491 1492 1493 1494 1495 1496 1497 1498 1499 1500 1501 1502 1503 1504 \n   1    1    1    1    1    1    1    1    1    1    5    1    1    1    1    1 \n1505 1506 1507 1508 1509 1510 1511 1512 1513 1514 1515 1516 1517 1518 1519 1520 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1521 1522 1523 1524 1525 1526 1527 1528 1529 1530 1531 1532 1533 1534 1535 1536 \n   1    1    1    1    1    2    1    1    1    1    2    1    1    1    1    3 \n1537 1538 1539 1540 1541 1542 1543 1544 1545 \n   1    1    1    1    1    1    2    1    1 \n\n\nIf we want to know how many locations have more than one point event, we can use the code chunk below.\n\nsum(multiplicity(childcare_ppp) > 1)\n\n[1] 128\n\n\nThe output shows that there are 128 duplicated point events.\nTo view the locations of the duplicated point events, we can plot the childcare dataset by using the code chunk below.\n\ntmap_mode('view')\ntm_shape(childcare) +\n  tm_dots(alpha = 0.4,\n          size = 0.05)\n\n\n\n\n\n\n\ntmap_mode('plot')\n\nFrom the interactive map above, you can see that the duplicated points have points that are darker in color, as the transparency of 1 point has been set to an alpha of 0.4, two overlapping points will make it more opaque.\nThere are a few ways to overcome this problem:\n\nDelete the duplicates. However, some useful point events will be lost\njittering. Adds small perturrbations to duplicate points so that they do not occupy the same exact space\nMake each point “unique” and then attach duplicates of points to the patterns as marks, as attributes of the points. Then we can use analytical techniques that take into account the marks.\n\nWe use the second approach, jittering to manipulate the points below\n\nchildcare_ppp_jit <- rjitter(childcare_ppp,\n                             retry = TRUE,\n                             nsim = 1,\n                             drop = TRUE)\n\nNow, let’s check the if there are still any duplicated points below\n\nany(duplicated(childcare_ppp_jit))\n\n[1] FALSE"
  },
  {
    "objectID": "exercises/hoex3.html#creating-owin-object",
    "href": "exercises/hoex3.html#creating-owin-object",
    "title": "Hands-on Exercise 3: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "Creating owin object",
    "text": "Creating owin object\nWhen analysing spatial point patterns, it is good practice to confine the analysis with a geographical area like Singapore boundary. In spatstat, an object called owin is specially designed to represent this polygonal region.\nThe code cunk below is used to convert the sg SpatialPolygon object into owin object of spatstat.\n\nsg_owin <- as(sg_sp, \"owin\")\n\nThe output object can be displayed by using plot() function.\n\nplot(sg_owin)\n\n\n\n\nand summary() function of Base R.\n\nsummary(sg_owin)\n\nWindow: polygonal boundary\n60 separate polygons (no holes)\n            vertices        area relative.area\npolygon 1         38 1.56140e+04      2.09e-05\npolygon 2        735 4.69093e+06      6.27e-03\npolygon 3         49 1.66986e+04      2.23e-05\npolygon 4         76 3.12332e+05      4.17e-04\npolygon 5       5141 6.36179e+08      8.50e-01\npolygon 6         42 5.58317e+04      7.46e-05\npolygon 7         67 1.31354e+06      1.75e-03\npolygon 8         15 4.46420e+03      5.96e-06\npolygon 9         14 5.46674e+03      7.30e-06\npolygon 10        37 5.26194e+03      7.03e-06\npolygon 11        53 3.44003e+04      4.59e-05\npolygon 12        74 5.82234e+04      7.78e-05\npolygon 13        69 5.63134e+04      7.52e-05\npolygon 14       143 1.45139e+05      1.94e-04\npolygon 15       165 3.38736e+05      4.52e-04\npolygon 16       130 9.40465e+04      1.26e-04\npolygon 17        19 1.80977e+03      2.42e-06\npolygon 18        16 2.01046e+03      2.69e-06\npolygon 19        93 4.30642e+05      5.75e-04\npolygon 20        90 4.15092e+05      5.54e-04\npolygon 21       721 1.92795e+06      2.57e-03\npolygon 22       330 1.11896e+06      1.49e-03\npolygon 23       115 9.28394e+05      1.24e-03\npolygon 24        37 1.01705e+04      1.36e-05\npolygon 25        25 1.66227e+04      2.22e-05\npolygon 26        10 2.14507e+03      2.86e-06\npolygon 27       190 2.02489e+05      2.70e-04\npolygon 28       175 9.25904e+05      1.24e-03\npolygon 29      1993 9.99217e+06      1.33e-02\npolygon 30        38 2.42492e+04      3.24e-05\npolygon 31        24 6.35239e+03      8.48e-06\npolygon 32        53 6.35791e+05      8.49e-04\npolygon 33        41 1.60161e+04      2.14e-05\npolygon 34        22 2.54368e+03      3.40e-06\npolygon 35        30 1.08382e+04      1.45e-05\npolygon 36       327 2.16921e+06      2.90e-03\npolygon 37       111 6.62927e+05      8.85e-04\npolygon 38        90 1.15991e+05      1.55e-04\npolygon 39        98 6.26829e+04      8.37e-05\npolygon 40       415 3.25384e+06      4.35e-03\npolygon 41       222 1.51142e+06      2.02e-03\npolygon 42       107 6.33039e+05      8.45e-04\npolygon 43         7 2.48299e+03      3.32e-06\npolygon 44        17 3.28303e+04      4.38e-05\npolygon 45        26 8.34758e+03      1.11e-05\npolygon 46       177 4.67446e+05      6.24e-04\npolygon 47        16 3.19460e+03      4.27e-06\npolygon 48        15 4.87296e+03      6.51e-06\npolygon 49        66 1.61841e+04      2.16e-05\npolygon 50       149 5.63430e+06      7.53e-03\npolygon 51       609 2.62570e+07      3.51e-02\npolygon 52         8 7.82256e+03      1.04e-05\npolygon 53       976 2.33447e+07      3.12e-02\npolygon 54        55 8.25379e+04      1.10e-04\npolygon 55       976 2.33447e+07      3.12e-02\npolygon 56        61 3.33449e+05      4.45e-04\npolygon 57         6 1.68410e+04      2.25e-05\npolygon 58         4 9.45963e+03      1.26e-05\npolygon 59        46 6.99702e+05      9.35e-04\npolygon 60        13 7.00873e+04      9.36e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 748741000 square units\nFraction of frame area: 0.414"
  },
  {
    "objectID": "exercises/hoex3.html#combining-point-events-object-and-owin-object",
    "href": "exercises/hoex3.html#combining-point-events-object-and-owin-object",
    "title": "Hands-on Exercise 3: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "Combining Point Events Object and owin Object",
    "text": "Combining Point Events Object and owin Object\nIn this last step of geospatial data wrangling, we will extract childcare events that are located within Singapore using the code below\n\nchildcareSG_ppp = childcare_ppp[sg_owin]\n\nThe output object combined both the point and polygon feature in one ppp object class as shown below.\n\nsummary(childcareSG_ppp)\n\nPlanar point pattern:  1545 points\nAverage intensity 2.063463e-06 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 3 decimal places\ni.e. rounded to the nearest multiple of 0.001 units\n\nWindow: polygonal boundary\n60 separate polygons (no holes)\n            vertices        area relative.area\npolygon 1         38 1.56140e+04      2.09e-05\npolygon 2        735 4.69093e+06      6.27e-03\npolygon 3         49 1.66986e+04      2.23e-05\npolygon 4         76 3.12332e+05      4.17e-04\npolygon 5       5141 6.36179e+08      8.50e-01\npolygon 6         42 5.58317e+04      7.46e-05\npolygon 7         67 1.31354e+06      1.75e-03\npolygon 8         15 4.46420e+03      5.96e-06\npolygon 9         14 5.46674e+03      7.30e-06\npolygon 10        37 5.26194e+03      7.03e-06\npolygon 11        53 3.44003e+04      4.59e-05\npolygon 12        74 5.82234e+04      7.78e-05\npolygon 13        69 5.63134e+04      7.52e-05\npolygon 14       143 1.45139e+05      1.94e-04\npolygon 15       165 3.38736e+05      4.52e-04\npolygon 16       130 9.40465e+04      1.26e-04\npolygon 17        19 1.80977e+03      2.42e-06\npolygon 18        16 2.01046e+03      2.69e-06\npolygon 19        93 4.30642e+05      5.75e-04\npolygon 20        90 4.15092e+05      5.54e-04\npolygon 21       721 1.92795e+06      2.57e-03\npolygon 22       330 1.11896e+06      1.49e-03\npolygon 23       115 9.28394e+05      1.24e-03\npolygon 24        37 1.01705e+04      1.36e-05\npolygon 25        25 1.66227e+04      2.22e-05\npolygon 26        10 2.14507e+03      2.86e-06\npolygon 27       190 2.02489e+05      2.70e-04\npolygon 28       175 9.25904e+05      1.24e-03\npolygon 29      1993 9.99217e+06      1.33e-02\npolygon 30        38 2.42492e+04      3.24e-05\npolygon 31        24 6.35239e+03      8.48e-06\npolygon 32        53 6.35791e+05      8.49e-04\npolygon 33        41 1.60161e+04      2.14e-05\npolygon 34        22 2.54368e+03      3.40e-06\npolygon 35        30 1.08382e+04      1.45e-05\npolygon 36       327 2.16921e+06      2.90e-03\npolygon 37       111 6.62927e+05      8.85e-04\npolygon 38        90 1.15991e+05      1.55e-04\npolygon 39        98 6.26829e+04      8.37e-05\npolygon 40       415 3.25384e+06      4.35e-03\npolygon 41       222 1.51142e+06      2.02e-03\npolygon 42       107 6.33039e+05      8.45e-04\npolygon 43         7 2.48299e+03      3.32e-06\npolygon 44        17 3.28303e+04      4.38e-05\npolygon 45        26 8.34758e+03      1.11e-05\npolygon 46       177 4.67446e+05      6.24e-04\npolygon 47        16 3.19460e+03      4.27e-06\npolygon 48        15 4.87296e+03      6.51e-06\npolygon 49        66 1.61841e+04      2.16e-05\npolygon 50       149 5.63430e+06      7.53e-03\npolygon 51       609 2.62570e+07      3.51e-02\npolygon 52         8 7.82256e+03      1.04e-05\npolygon 53       976 2.33447e+07      3.12e-02\npolygon 54        55 8.25379e+04      1.10e-04\npolygon 55       976 2.33447e+07      3.12e-02\npolygon 56        61 3.33449e+05      4.45e-04\npolygon 57         6 1.68410e+04      2.25e-05\npolygon 58         4 9.45963e+03      1.26e-05\npolygon 59        46 6.99702e+05      9.35e-04\npolygon 60        13 7.00873e+04      9.36e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 748741000 square units\nFraction of frame area: 0.414\n\n\n\nplot(childcareSG_ppp)"
  },
  {
    "objectID": "exercises/hoex3.html#kernel-density-estimation",
    "href": "exercises/hoex3.html#kernel-density-estimation",
    "title": "Hands-on Exercise 3: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "Kernel Density Estimation",
    "text": "Kernel Density Estimation\n\nComputing Kernel Density Estimation using Automatic Bandwidth Selection Method\nThe code below computes a kernel density by using the following configurations of density() of spatstat:\n\nbw.diggle() automatic bandwidth selection method. Other recommended methods include: bw.CvL(), bw.scott() or bw.ppl()\nThe smoothing kernel used by default is gaussian. Other smoothing methods include: epanechnikov, quartic or disc\nThe intensity estimate is corrected for edge effect bias by using the method described by Jones and Diggel, default is FALSE.\n\n\nkde_childcareSG_bw <- density(childcareSG_ppp,\n                              sigma = bw.diggle,\n                              edge = TRUE,\n                              kernel = \"gaussian\")\n\nThe plot() function is then used to display the kernel density derived.\n\nplot(kde_childcareSG_bw)\n\n\n\n\nThe density values of the output range from 0 to 0.0000035 which is too small to comprehend as the default unit of measure of svy21 is in metres. As a result, the density values computed is in number of points per square meter.\nWe can check the bandwidth used to compute the kde layer using the code below.\n\nbw <- bw.diggle(childcareSG_ppp)\nbw\n\n   sigma \n298.4095 \n\n\n\n\nRescaling KDE Values\nUsing the rescale() function, we can convert the unit of measurement from metres to kilometres\n\nchildcareSG_ppp.km <- rescale(childcareSG_ppp, 1000, \"km\")\n\nNow, we can re-run density() using the rescaled data set and plot the output kde map\n\nkde_childcareSG_bw <- density(childcareSG_ppp.km,\n                              sigma = bw.diggle,\n                              edge = TRUE,\n                              kernel = \"gaussian\")\nplot(kde_childcareSG_bw)\n\n\n\n\nThe kde output image looks identical to the previous version, only the data values in the legend has changed.\n\n\nWorking with Different Automatic Bandwidth Methods\nBesides bw.diggle(), there are three other spatstat functions that can be used to determine bandwidth. They are bw.CvL(), bw.scott(), and bw.ppl()\nLet us look at the bandwidth returned by the different automatic bandwidth calculation methods below.\n\nbw.CvL(childcareSG_ppp.km)\n\n   sigma \n4.543278 \n\n\n\nbw.scott(childcareSG_ppp.km)\n\n sigma.x  sigma.y \n2.224898 1.450966 \n\n\n\nbw.ppl(childcareSG_ppp.km)\n\n    sigma \n0.3897114 \n\n\n\nbw.diggle(childcareSG_ppp.km)\n\n    sigma \n0.2984095 \n\n\nBaddeley et al. suggested the use of bw.ppl() algorithm due to their experience of producing more appropraiate values when pattern consists predominantly of tight clusters. However, if the purpose of one’s study is to detect a single tight cluster in the midst of random noise, bw.diggle() method will be more appropriate.\nThe code below compares the output of using bw.diggle() and bw.ppl() methods\n\nkde_childcareSG.ppl <- density(childcareSG_ppp.km,\n                               sigma = bw.ppl,\n                               edge = TRUE,\n                               kernel = \"gaussian\")\npar(mfrow = c(1,2))\nplot(kde_childcareSG_bw, main = \"bw.diggle\")\nplot(kde_childcareSG.ppl, main = \"bw.ppl\")\n\n\n\n\n\n\nWorking with Different Kernel Methods\nBy default, the kernel method used in density.ppp() is gaussian. However, there are epanechnikov, quartic and dics.\nHere, we will use the code to compute three more KDE using the kernel functions\n\npar(mfrow=c(2,2))\nplot(density(childcareSG_ppp.km, \n             sigma = bw.ppl, \n             edge = TRUE, \n             kernel = \"gaussian\"), \n             main = \"Gaussian\")\nplot(density(childcareSG_ppp.km, \n             sigma = bw.ppl, \n             edge = TRUE, \n             kernel = \"epanechnikov\"), \n             main = \"Epanechnikov\")\nplot(density(childcareSG_ppp.km, \n             sigma = bw.ppl, \n             edge = TRUE, \n             kernel = \"quartic\"), \n             main = \"Quartic\")\nplot(density(childcareSG_ppp.km, \n             sigma = bw.ppl, \n             edge = TRUE, \n             kernel = \"disc\"), \n             main = \"Disc\")"
  },
  {
    "objectID": "exercises/hoex3.html#fixed-and-adaptive-kde",
    "href": "exercises/hoex3.html#fixed-and-adaptive-kde",
    "title": "Hands-on Exercise 3: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "Fixed and Adaptive KDE",
    "text": "Fixed and Adaptive KDE\n\nComputing KDE by using Fixed Bandwidth\nNext, we can compute a KDE layer by defining a bandwidth of 600 metres. As the unit of measurement of childcareSG_ppp.km object is in kilometres, we use a sigma value of 0.6.\n\nkde_childcareSG_600 <- density(childcareSG_ppp.km, sigma = 0.6, edge = TRUE, kernel = \"gaussian\")\nplot(kde_childcareSG_600)\n\n\n\n\n\n\nComputing KDE by using Adaptive Bandwidth\nThe fixed bandwidth method is very sensitive to highly skewed distribution of spatial point patterns over geographical units (eg. urban vs rural). One way to overcome the problem is to use adaptive bandwidth.\nWe can use density.adaptive() to derive adaptive kernel density estimation\n\nkde_childcareSG_adaptive <- adaptive.density(childcareSG_ppp.km, method = \"kernel\")\nplot(kde_childcareSG_adaptive)\n\n\n\n\nWe can compare the fixed and adaptive KDE outputs using the code below\n\npar(mfrow=c(1,2))\nplot(kde_childcareSG_bw, main = \"Fixed bandwidth\")\nplot(kde_childcareSG_adaptive, main = \"Adaptive bandwidth\")\n\n\n\n\n\n\nConverting KDE Output into Grid Object\nThe results are the same, but the conversion allows us to use it for mapping purposes.\n\ngridded_kde_childcareSG_bw <- as.SpatialGridDataFrame.im(kde_childcareSG_bw)\nspplot(gridded_kde_childcareSG_bw)\n\n\n\n\n\nConverting Gridded Output into Raster\nNext, we will convert gridded kernel density objects into RasterLayer object using raster() of the raster object.\n\nkde_childcareSG_bw_raster <- raster(gridded_kde_childcareSG_bw)\n\nWe can view the properties of kde_childcareSG_bw_raster RasterLayer\n\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : v \nvalues     : -8.476185e-15, 28.51831  (min, max)\n\n\nNote that the CRS property is NA.\n\n\nAssigning Projection Systems\nThe code below will be used to include CRS information.\n\nprojection(kde_childcareSG_bw_raster) <- CRS(\"+init=EPSG:3414\")\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +units=m +no_defs \nsource     : memory\nnames      : v \nvalues     : -8.476185e-15, 28.51831  (min, max)\n\n\nNote that the CRS property has been included."
  },
  {
    "objectID": "exercises/hoex3.html#visualising-output-in-tmap",
    "href": "exercises/hoex3.html#visualising-output-in-tmap",
    "title": "Hands-on Exercise 3: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "Visualising Output in tmap",
    "text": "Visualising Output in tmap\nWe can finally display the raster using tmap\n\ntm_shape(kde_childcareSG_bw_raster) + \n  tm_raster(\"v\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\"), frame = FALSE)\n\n\n\n\nNote that the raster values are encoded explicitly onto the raster pixel using the values in the “v” field."
  },
  {
    "objectID": "exercises/hoex3.html#comparing-spatial-point-patterns-using-kde",
    "href": "exercises/hoex3.html#comparing-spatial-point-patterns-using-kde",
    "title": "Hands-on Exercise 3: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "Comparing Spatial Point Patterns Using KDE",
    "text": "Comparing Spatial Point Patterns Using KDE\nHere, we will look at how to compare KDE of childcare at Punggol, Tampines, Chua Chu Kang and Jurong West Planning Areas\n\nExtracting Study Areas\nThe code below will help us to extract the target planning areas\n\npg = mpsz[mpsz@data$PLN_AREA_N == \"PUNGGOL\",]\ntm = mpsz[mpsz@data$PLN_AREA_N == \"TAMPINES\",]\nck = mpsz[mpsz@data$PLN_AREA_N == \"CHOA CHU KANG\",]\njw = mpsz[mpsz@data$PLN_AREA_N == \"JURONG WEST\",]\n\nPlotting target planning areas\n\npar(mfrow=c(2,2))\nplot(pg, main = \"Punggol\")\nplot(tm, main = \"Tampines\")\nplot(ck, main = \"Choa Chu Kang\")\nplot(jw, main = \"Jurong West\")\n\n\n\n\n\n\nConverting the Spatial Point Data Frame into Generic sp Format\n\npg_sp = as(pg, \"SpatialPolygons\")\ntm_sp = as(tm, \"SpatialPolygons\")\nck_sp = as(ck, \"SpatialPolygons\")\njw_sp = as(jw, \"SpatialPolygons\")\n\n\n\nCreating owin Object\n\npg_owin = as(pg_sp, \"owin\")\ntm_owin = as(tm_sp, \"owin\")\nck_owin = as(ck_sp, \"owin\")\njw_owin = as(jw_sp, \"owin\")\n\n\n\nCombining Childcare Points and the Study Area\nBy using the code chunk below, we are able to extract childcare that is within the specific region to do our analysis later on.\n\nchildcare_pg_ppp = childcare_ppp_jit[pg_owin]\nchildcare_tm_ppp = childcare_ppp_jit[tm_owin]\nchildcare_ck_ppp = childcare_ppp_jit[ck_owin]\nchildcare_jw_ppp = childcare_ppp_jit[jw_owin]\n\nWe use rescale() to transform the units of measurement from metre to kilometre\n\nchildcare_pg_ppp.km = rescale(childcare_pg_ppp, 1000, \"km\")\nchildcare_tm_ppp.km = rescale(childcare_tm_ppp, 1000, \"km\")\nchildcare_ck_ppp.km = rescale(childcare_ck_ppp, 1000, \"km\")\nchildcare_jw_ppp.km = rescale(childcare_jw_ppp, 1000, \"km\")\n\nNow, we will plot the four study areas and locations of childcare centres\n\npar(mfrow=c(2,2))\nplot(childcare_pg_ppp.km, main=\"Punggol\")\nplot(childcare_tm_ppp.km, main=\"Tampines\")\nplot(childcare_ck_ppp.km, main=\"Choa Chu Kang\")\nplot(childcare_jw_ppp.km, main=\"Jurong West\")\n\n\n\n\n\n\nComputing KDE\nThe code chunk below will be used to compute the KDE of these four planning area. bw.diggle method is used to derive each bandwidth\n\npar(mfrow=c(2,2))\nplot(density(childcare_pg_ppp.km, \n             sigma = bw.diggle, \n             edge = TRUE, \n             kernel = \"gaussian\"),\n             main = \"Punggol\")\nplot(density(childcare_tm_ppp.km, \n             sigma = bw.diggle, \n             edge = TRUE, \n             kernel = \"gaussian\"),\n             main = \"Tampines\")\nplot(density(childcare_ck_ppp.km, \n             sigma = bw.diggle, \n             edge = TRUE, \n             kernel = \"gaussian\"),\n             main = \"Choa Chu Kang\")\nplot(density(childcare_jw_ppp.km, \n             sigma = bw.diggle, \n             edge = TRUE, \n             kernel = \"gaussian\"),\n             main = \"Jurong West\")\n\n\n\n\n\n\nComputing Fixed Bandwidth KDE\nFor comparison purposes, we will use 250m as the bandwidth.\n\npar(mfrow=c(2,2))\nplot(density(childcare_ck_ppp.km, \n             sigma = 0.25, \n             edge = TRUE, \n             kernel = \"gaussian\"),\n             main = \"Chou Chu Kang\")\nplot(density(childcare_jw_ppp.km, \n             sigma = 0.25, \n             edge = TRUE, \n             kernel = \"gaussian\"),\n             main = \"Jurong West\")\nplot(density(childcare_pg_ppp.km, \n             sigma = 0.25, \n             edge = TRUE, \n             kernel = \"gaussian\"),\n             main = \"Punggol\")\nplot(density(childcare_tm_ppp.km, \n             sigma = 0.25, \n             edge = TRUE, \n             kernel = \"gaussian\"),\n             main = \"Tampines\")"
  },
  {
    "objectID": "exercises/hoex3.html#nearest-neighbour-analysis",
    "href": "exercises/hoex3.html#nearest-neighbour-analysis",
    "title": "Hands-on Exercise 3: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "Nearest Neighbour Analysis",
    "text": "Nearest Neighbour Analysis\nIn this section, we will perform the Clark-Evans test of aggregation for a spatial point pattern by using clarkevans.test() of statspat at 95% confidence interval.\nThe test hypotheses are:\n\nHo = The distribution of childcare services are randomly distributed.\nH1 = The distribution of childcare services are not randomly distributed.\n\n\nTesting Spatial Point Patterns using Clark and Evans Test\n\nclarkevans.test(childcareSG_ppp,\n                correction=\"none\",\n                clipregion=\"sg_owin\",\n                alternative=c(\"clustered\"),\n                nsim=99)\n\n\n    Clark-Evans test\n    No edge correction\n    Monte Carlo test based on 99 simulations of CSR with fixed n\n\ndata:  childcareSG_ppp\nR = 0.54756, p-value = 0.01\nalternative hypothesis: clustered (R < 1)\n\n\nAs P is 0.01 < 0.05, we reject the null hypothesis that the childcare services are randomly distributed. We can infer from the R value (Nearest Neighbour Index) that since R = 0.54756 < 1, the pattern exhibits clustering in Tampines.\n\n\nClark and Evans Test: Choa Chu Kang Planning Area\n\nclarkevans.test(childcare_ck_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Monte Carlo test based on 999 simulations of CSR with fixed n\n\ndata:  childcare_ck_ppp\nR = 0.94048, p-value = 0.124\nalternative hypothesis: two-sided\n\n\nAs P is 0.204 > 0.05, we cannot reject the null hypothesis that the childcare services are randomly distributed in Choa Chu Kang.\n\n\nClark and Evans Test: Tampines Planning Area\n\nclarkevans.test(childcare_tm_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Monte Carlo test based on 999 simulations of CSR with fixed n\n\ndata:  childcare_tm_ppp\nR = 0.78263, p-value = 0.002\nalternative hypothesis: two-sided\n\n\nAs P is 0.002 < 0.05, we reject the null hypothesis that the childcare services are randomly distributed.\nWe can infer from the R value (Nearest Neighbour Index) that since R = 0.79654 < 1, the patten exhibits clustering in Tampines."
  },
  {
    "objectID": "exercises/hoex5.html",
    "href": "exercises/hoex5.html",
    "title": "Hands-on Exercise 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "",
    "text": "In this hands-on exercise, you will learn how to compute Global and Local Measure of Spatial Autocorrelation (GLSA) by using spdep package. By the end to this hands-on exercise, you will be able to:\n\nimport geospatial data using appropriate function(s) of sf package,\nimport csv file using appropriate function of readr package,\nperform relational join using appropriate join function of dplyr package,\ncompute Global Spatial Autocorrelation (GSA) statistics by using appropriate functions of spdep package,\n\nplot Moran scatterplot,\ncompute and plot spatial correlogram using appropriate function of spdep package.\n\ncompute Local Indicator of Spatial Association (LISA) statistics for detecting clusters and outliers by using appropriate functions spdep package;\ncompute Getis-Ord’s Gi-statistics for detecting hot spot or/and cold spot area by using appropriate functions of spdep package; and\nto visualise the analysis output by using tmap package.\n\n\n\n\nIn spatial policy, one of the main development objective of the local government and planners is to ensure equal distribution of development in the province. Our task in this study, hence, is to apply appropriate spatial statistical methods to discover if development are even distributed geographically. If the answer is No. Then, our next question will be “is there sign of spatial clustering?”. And, if the answer for this question is yes, then our next question will be “where are these clusters?”\nIn this case study, we are interested to examine the spatial pattern of a selected development indicator (i.e. GDP per capita) of Hunan Provice, People Republic of China.(https://en.wikipedia.org/wiki/Hunan)\n\n\n\nPacman assists us by helping us load R packages that we require, sf, sfdep, tmap and tidyverse.\n\npacman::p_load(sf, sfdep, tmap, tidyverse, spdep)\n\nThe following packages assists us to accomplish the following:\n\nsfdep helps to compute spatial weights, global and local spatial autocorrelation statistics\ntmap provides functions to allow us to plot high quality static or interactive maps using leaflet API\n\n\n\n\nThe following datasets are used:\n\n\n\nDataset Name\nSource\n\n\n\n\nHunan (Hunan.shp)\nProf Kam\n\n\nHunan 2021 (Hunan-2021.csv)\nProf Kam"
  },
  {
    "objectID": "exercises/hoex5.html#importing-geospatial-data",
    "href": "exercises/hoex5.html#importing-geospatial-data",
    "title": "Hands-on Exercise 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "Importing Geospatial Data",
    "text": "Importing Geospatial Data\nUsing the code chunk below, we will import the Hunan shapefile into R as sf data frame.\n\nhunan <- st_read(dsn = \"Hands-on_Ex05/data/geospatial\",\n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\renjie-teo\\IS415-GAA\\exercises\\Hands-on_Ex05\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "exercises/hoex5.html#section",
    "href": "exercises/hoex5.html#section",
    "title": "Hands-on Exercise 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "",
    "text": "Importing Geospatial Data\nUsing the code chunk below, we will import Hunan_2012.csv into R, which reults in a R data frame.\n\nhunan2012 <- read_csv(\"Hands-on_Ex05/data/aspatial/Hunan_2012.csv\")"
  },
  {
    "objectID": "exercises/hoex5.html#perfoming-relational-join",
    "href": "exercises/hoex5.html#perfoming-relational-join",
    "title": "Hands-on Exercise 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "Perfoming Relational Join",
    "text": "Perfoming Relational Join\nThe hunan2012.csv provides attributes that we want to combine with our shapefile. To do this, we can do a left join as shown in the code chunk, before selecting the columns that we want to retain.\n\nhunan <- left_join(hunan, hunan2012) %>%\n  select(1:4, 7, 15)"
  },
  {
    "objectID": "exercises/hoex5.html#visualising-regional-development-indicator",
    "href": "exercises/hoex5.html#visualising-regional-development-indicator",
    "title": "Hands-on Exercise 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "Visualising Regional Development Indicator",
    "text": "Visualising Regional Development Indicator\nNext, we will prepare a chloropleth map to show the distribution of GDPPC in Hunan in 2012.\n\nequal <- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal interval classification\")\n\nquantile <- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal quantile classification\")\n\ntmap_arrange(equal, \n             quantile, \n             asp=1, \n             ncol=2)"
  },
  {
    "objectID": "exercises/hoex5.html#computing-contiguity-spatial-weights",
    "href": "exercises/hoex5.html#computing-contiguity-spatial-weights",
    "title": "Hands-on Exercise 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "Computing Contiguity Spatial Weights",
    "text": "Computing Contiguity Spatial Weights\nUsing the sfdep package with with mutate() and st_contiguity() and st_weights(), it performs the necessary tasks, to obtain the contiguity weights and then row-standardised weight matrix.\nBy default, the code chunk below will assign each neighbouring with equal weight (style=“W”)\n\nwm_q <- hunan %>%\n  mutate(nb = st_contiguity(geometry),\n         wt = st_weights(nb),\n         .before = 1)\n\n\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\n    nb       wt.Length  wt.Class  wt.Mode    NAME_2               ID_3      \n NULL:NULL    5       -none-   numeric    Length:88          Min.   :21098  \n              5       -none-   numeric    Class :character   1st Qu.:21125  \n              4       -none-   numeric    Mode  :character   Median :21150  \n              4       -none-   numeric                       Mean   :21150  \n              4       -none-   numeric                       3rd Qu.:21174  \n              5       -none-   numeric                       Max.   :21201  \n              4       -none-   numeric                                      \n              7       -none-   numeric                                      \n              6       -none-   numeric                                      \n              8       -none-   numeric                                      \n              3       -none-   numeric                                      \n              5       -none-   numeric                                      \n              4       -none-   numeric                                      \n              3       -none-   numeric                                      \n              4       -none-   numeric                                      \n              5       -none-   numeric                                      \n              7       -none-   numeric                                      \n              5       -none-   numeric                                      \n              6       -none-   numeric                                      \n              7       -none-   numeric                                      \n              5       -none-   numeric                                      \n              5       -none-   numeric                                      \n              7       -none-   numeric                                      \n              5       -none-   numeric                                      \n              5       -none-   numeric                                      \n              4       -none-   numeric                                      \n              3       -none-   numeric                                      \n              5       -none-   numeric                                      \n              3       -none-   numeric                                      \n              1       -none-   numeric                                      \n              8       -none-   numeric                                      \n              8       -none-   numeric                                      \n              5       -none-   numeric                                      \n              3       -none-   numeric                                      \n              6       -none-   numeric                                      \n              6       -none-   numeric                                      \n              4       -none-   numeric                                      \n              4       -none-   numeric                                      \n              5       -none-   numeric                                      \n              6       -none-   numeric                                      \n              6       -none-   numeric                                      \n              7       -none-   numeric                                      \n              6       -none-   numeric                                      \n              4       -none-   numeric                                      \n              6       -none-   numeric                                      \n              3       -none-   numeric                                      \n              5       -none-   numeric                                      \n              5       -none-   numeric                                      \n              4       -none-   numeric                                      \n              5       -none-   numeric                                      \n              3       -none-   numeric                                      \n              5       -none-   numeric                                      \n              3       -none-   numeric                                      \n              6       -none-   numeric                                      \n              5       -none-   numeric                                      \n              7       -none-   numeric                                      \n              6       -none-   numeric                                      \n              5       -none-   numeric                                      \n              4       -none-   numeric                                      \n              4       -none-   numeric                                      \n              7       -none-   numeric                                      \n              3       -none-   numeric                                      \n              4       -none-   numeric                                      \n              2       -none-   numeric                                      \n              1       -none-   numeric                                      \n              5       -none-   numeric                                      \n              4       -none-   numeric                                      \n              5       -none-   numeric                                      \n              3       -none-   numeric                                      \n              3       -none-   numeric                                      \n              3       -none-   numeric                                      \n              5       -none-   numeric                                      \n              5       -none-   numeric                                      \n              6       -none-   numeric                                      \n              6       -none-   numeric                                      \n              7       -none-   numeric                                      \n              7       -none-   numeric                                      \n              7       -none-   numeric                                      \n              7       -none-   numeric                                      \n              8       -none-   numeric                                      \n              6       -none-   numeric                                      \n              5       -none-   numeric                                      \n              9       -none-   numeric                                      \n              6       -none-   numeric                                      \n             11       -none-   numeric                                      \n              9       -none-   numeric                                      \n              4       -none-   numeric                                      \n              2       -none-   numeric                                      \n    NAME_3           ENGTYPE_3            County              GDPPC      \n Length:88          Length:88          Length:88          Min.   : 8497  \n Class :character   Class :character   Class :character   1st Qu.:14566  \n Mode  :character   Mode  :character   Mode  :character   Median :20433  \n                                                          Mean   :24405  \n                                                          3rd Qu.:27224  \n                                                          Max.   :88656  \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n          geometry \n POLYGON      :88  \n epsg:4326    : 0  \n +proj=long...: 0  \n                   \n                   \n                   \n                   \n                   \n                   \n                   \n                   \n                   \n                   \n                   \n                   \n                   \n                   \n                   \n                   \n                   \n                   \n                   \n                   \n                   \n                   \n                   \n                   \n                   \n                   \n                   \n                   \n                   \n                   \n                   \n                   \n                   \n                   \n                   \n                   \n                   \n                   \n                   \n                   \n                   \n                   \n                   \n                   \n                   \n                   \n                   \n                   \n                   \n                   \n                   \n                   \n                   \n                   \n                   \n                   \n                   \n                   \n                   \n                   \n                   \n                   \n                   \n                   \n                   \n                   \n                   \n                   \n                   \n                   \n                   \n                   \n                   \n                   \n                   \n                   \n                   \n                   \n                   \n                   \n                   \n                   \n                   \n                   \n                   \n\n\nFrom the summary report, we can see that there are 88 area units, with the most connected area unit having 11 neighbours."
  },
  {
    "objectID": "exercises/hoex5.html#section-1",
    "href": "exercises/hoex5.html#section-1",
    "title": "Hands-on Exercise 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "",
    "text": "Global Spatial Correlation\n\nMoran’s I Test\nThe code chunk below performs Moran’s I statistical testing using global_moran_test() of sfdep.\nOur hypothesis formulated is as follows:\nHo = The observations of spatial pattern of GDPPC values in Hunan are randomly distributed.\nH1= The observations of spatial pattern of GDPPC values in Hunan are not randomly distributed.\nThe null hypothesis will be rejected is p-value is smaller than alpha value of 0.001.\n\nglobal_moran_test(hunan$GDPPC,\n                  wm_q$nb,\n                  wm_q$wt)\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\nFrom the code, since the p-value is < 0.001, we reject the null hypothesis\n\nComputing Monte Carlo Moran’s I\n\nset.seed(1234)\nbperm = global_moran_perm(hunan$GDPPC,\n                          wm_q$nb,\n                          wm_q$wt,\n                          nsim = 999,\n                          zero.policy = TRUE,\n                          na.action = na.omit)\nbperm\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.30075, observed rank = 1000, p-value < 2.2e-16\nalternative hypothesis: two.sided\n\n\nSince I (0.300749970) > 0, there appears to be clustering in Hunan, China and observations tend to be similar.\n\n\nVisualising Monte Carlo Moran’s I\nWe can better visualise Moran’s I test statistics in greater detail by plotting the distrubtion of statistical values as a histogram using the code chunk below.\n\nmean(bperm$res[1:999])\n\n[1] -0.01504572\n\n\n\nvar(bperm$res[1:999])\n\n[1] 0.004371574\n\n\n\nsummary(bperm$res[1:999])\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-0.18339 -0.06168 -0.02125 -0.01505  0.02611  0.27593 \n\n\n\nhist(bperm$res,\n     freq = TRUE,\n     breaks = 20,\n     xlab = \"Simulated Moran's I\")\nabline(v = 0,\n       col = \"red\")\n\n\n\n\n\n\n\nGlobal Spatial Autocorreclation: Geary’s\n\nGeary’s C Test\nIn this section, we will use global_c_test() from sfdep to conudct Geary’s C Test\nOur hypothesis formulated is as follows:\nHo = The observations of spatial pattern of GDPPC values in Hunan are randomly distributed.\nH1= The observations of spatial pattern of GDPPC values in Hunan are not randomly distributed.\nThe null hypothesis will be rejected is p-value is smaller than alpha value of 0.001.\n\nglobal_c_test(hunan$GDPPC,\n                  wm_q$nb,\n                  wm_q$wt)\n\n\n    Geary C test under randomisation\n\ndata:  x \nweights: listw \n\nGeary C statistic standard deviate = 3.6108, p-value = 0.0001526\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n        0.6907223         1.0000000         0.0073364 \n\n\nFrom the code, since the p-value is < 0.001, we reject the null hypothesis\n\n\nComputing Monte Carlo Geary’s C\n\nset.seed(1234)\nbperm = global_c_perm(hunan$GDPPC,\n                      wm_q$nb,\n                      wm_q$wt,\n                      nsim = 999)\nbperm\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  x \nweights: listw \nnumber of simulations + 1: 1000 \n\nstatistic = 0.69072, observed rank = 1, p-value = 0.001\nalternative hypothesis: greater\n\n\nSince C (0.69072) < 1, there appears to be clustering in Hunan, China and observations tend to be similar.\n\n\nVisualising the Monte Carlo Gerary’s C\n\nmean(bperm$res[1:999])\n\n[1] 1.004402\n\n\n\nvar(bperm$res[1:999])\n\n[1] 0.007436493\n\n\n\nsummary(bperm$res[1:999])\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.7142  0.9502  1.0052  1.0044  1.0595  1.2722 \n\n\n\nhist(bperm$res, freq = TRUE, breaks = 20, xlab = \"Simulated Geary C\")\nabline(v = 1, col = \"red\")"
  },
  {
    "objectID": "exercises/hoex5.html#spatial-correlogram",
    "href": "exercises/hoex5.html#spatial-correlogram",
    "title": "Hands-on Exercise 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "Spatial Correlogram",
    "text": "Spatial Correlogram\nSpatial correlograms are great to examine patterns of spatial autocorrelation in your data or model residuals. They show how correlated are pairs of spatial observations when you increase the distance (lag) between them - they are plots of some index of autocorrelation (Moran’s I or Geary’s c) against distance.Although correlograms are not as fundamental as variograms (a keystone concept of geostatistics), they are very useful as an exploratory and descriptive tool. For this purpose they actually provide richer information than variograms.\n\nCompute Moran’s I Correlogram\nAs sfdep does not offer a method to plot the correlogram, we will be using sp.correlogram() of spdep package. Thereafter, we use plot to plot the output of the graph\n\nMI_corr <- sp.correlogram(wm_q$nb, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"I\", \n                          style=\"W\")\nplot(MI_corr)\n\n\n\n\nThe plot does not allow us to fully interpret the autocorrelation values as some of the values might not be statistically significant. Hence, we should print the analysis results using the code below.\n\nprint(MI_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided    \n1 (88)  0.3007500  -0.0114943  0.0043484           4.7351       2.189e-06 ***\n2 (88)  0.2060084  -0.0114943  0.0020962           4.7505       2.029e-06 ***\n3 (88)  0.0668273  -0.0114943  0.0014602           2.0496        0.040400 *  \n4 (88)  0.0299470  -0.0114943  0.0011717           1.2107        0.226015    \n5 (88) -0.1530471  -0.0114943  0.0012440          -4.0134       5.984e-05 ***\n6 (88) -0.1187070  -0.0114943  0.0016791          -2.6164        0.008886 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n<analyse>\n\n\nPlot Geary’s C Correlogram and Plot\nAs sfdep does not offer a method to plot the correlogram, we will be using sp.correlogram() of spdep package. Thereafter, we use plot to plot the output of the graph\n\nGC_corr <- sp.correlogram(wm_q$nb, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"C\", \n                          style=\"W\")\nplot(GC_corr)\n\n\n\n\nThe plot does not allow us to fully interpret the autocorrelation values as some of the values might not be statistically significant. Hence, we should print the analysis results using the code below.\n\nprint(GC_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Geary's C\n        estimate expectation  variance standard deviate Pr(I) two sided    \n1 (88) 0.6907223   1.0000000 0.0073364          -3.6108       0.0003052 ***\n2 (88) 0.7630197   1.0000000 0.0049126          -3.3811       0.0007220 ***\n3 (88) 0.9397299   1.0000000 0.0049005          -0.8610       0.3892612    \n4 (88) 1.0098462   1.0000000 0.0039631           0.1564       0.8757128    \n5 (88) 1.2008204   1.0000000 0.0035568           3.3673       0.0007592 ***\n6 (88) 1.0773386   1.0000000 0.0058042           1.0151       0.3100407    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n<analyse>"
  },
  {
    "objectID": "exercises/hoex8.html",
    "href": "exercises/hoex8.html",
    "title": "Hands-on Exercise 8: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "",
    "text": "Geographically weighted regression (GWR) is a spatial statistical technique that takes non-stationary variables into consideration (e.g., climate; demographic factors; physical environment characteristics) and models the local relationships between these independent variables and an outcome of interest (also known as dependent variable). In this hands-on exercise, you will learn how to build hedonic pricing models by using GWR methods. The dependent variable is the resale prices of condominium in 2015. The independent variables are divided into either structural and locational.\n\n\n\nPacman assists us by helping us load R packages that we require, olsrr, GWModel, corrplot, sf, tmap and tidyverse.\n\npacman::p_load(olsrr, corrplot, ggpubr, sf, spdep, GWmodel, tmap, tidyverse, gtsummary)\n\n\n#update.packages()\n\nThe following packages assists us to accomplish the following:\n\nsfdep helps to compute spatial weights, global and local spatial autocorrelation statistics\ntmap provides functions to allow us to plot high quality static or interactive maps using leaflet API\nXXXX\n\n\n\n\nThe following datasets are used:\n\n\n\nDataset Name\nSource\n\n\n\n\nMaster Plan 2014 Subzone Boundary (Web) (MP14_SUBZONE_WEB_PL.shp)\ndata.gov.sg\n\n\ncondo_resale_2015 (condo_resale_2015.csv)\nProf Kam"
  },
  {
    "objectID": "exercises/hoex8.html#importing-geospatial-data",
    "href": "exercises/hoex8.html#importing-geospatial-data",
    "title": "Hands-on Exercise 8: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Importing Geospatial Data",
    "text": "Importing Geospatial Data\nUsing the code chunk below, we will import the MP14_SUBZONE_WEB_PL shapefile into R as sf data frame, which consists of the URA Master Plan 2014 Planning Boundary.\nAt the same time, we will correct the coordinate reference system to SVY21 which is EPSG:3414.\n\nmpsz <- st_read(dsn = \"Hands-on_Ex08/data/geospatial\",\n                 layer = \"MP14_SUBZONE_WEB_PL\") %>%\n  st_transform(3414)\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\renjie-teo\\IS415-GAA\\exercises\\Hands-on_Ex08\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nLet us verify if mpsz has been updated correctly:\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nNice, the EPSG has been updated to 3414.\nNow, let us inspect the bounding box extents of mpsz using st_bbox() of sf.\n\nst_bbox(mpsz) \n\n     xmin      ymin      xmax      ymax \n 2667.538 15748.721 56396.440 50256.334"
  },
  {
    "objectID": "exercises/hoex8.html#importing-aspatial-data",
    "href": "exercises/hoex8.html#importing-aspatial-data",
    "title": "Hands-on Exercise 8: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Importing Aspatial Data",
    "text": "Importing Aspatial Data\n\ncondo_resale = read_csv(\"Hands-on_Ex08/data/aspatial/Condo_resale_2015.csv\")\n\n\nglimpse(condo_resale)\n\nRows: 1,436\nColumns: 23\n$ LATITUDE             <dbl> 1.287145, 1.328698, 1.313727, 1.308563, 1.321437,…\n$ LONGITUDE            <dbl> 103.7802, 103.8123, 103.7971, 103.8247, 103.9505,…\n$ POSTCODE             <dbl> 118635, 288420, 267833, 258380, 467169, 466472, 3…\n$ SELLING_PRICE        <dbl> 3000000, 3880000, 3325000, 4250000, 1400000, 1320…\n$ AREA_SQM             <dbl> 309, 290, 248, 127, 145, 139, 218, 141, 165, 168,…\n$ AGE                  <dbl> 30, 32, 33, 7, 28, 22, 24, 24, 27, 31, 17, 22, 6,…\n$ PROX_CBD             <dbl> 7.941259, 6.609797, 6.898000, 4.038861, 11.783402…\n$ PROX_CHILDCARE       <dbl> 0.16597932, 0.28027246, 0.42922669, 0.39473543, 0…\n$ PROX_ELDERLYCARE     <dbl> 2.5198118, 1.9333338, 0.5021395, 1.9910316, 1.121…\n$ PROX_URA_GROWTH_AREA <dbl> 6.618741, 7.505109, 6.463887, 4.906512, 6.410632,…\n$ PROX_HAWKER_MARKET   <dbl> 1.76542207, 0.54507614, 0.37789301, 1.68259969, 0…\n$ PROX_KINDERGARTEN    <dbl> 0.05835552, 0.61592412, 0.14120309, 0.38200076, 0…\n$ PROX_MRT             <dbl> 0.5607188, 0.6584461, 0.3053433, 0.6910183, 0.528…\n$ PROX_PARK            <dbl> 1.1710446, 0.1992269, 0.2779886, 0.9832843, 0.116…\n$ PROX_PRIMARY_SCH     <dbl> 1.6340256, 0.9747834, 1.4715016, 1.4546324, 0.709…\n$ PROX_TOP_PRIMARY_SCH <dbl> 3.3273195, 0.9747834, 1.4715016, 2.3006394, 0.709…\n$ PROX_SHOPPING_MALL   <dbl> 2.2102717, 2.9374279, 1.2256850, 0.3525671, 1.307…\n$ PROX_SUPERMARKET     <dbl> 0.9103958, 0.5900617, 0.4135583, 0.4162219, 0.581…\n$ PROX_BUS_STOP        <dbl> 0.10336166, 0.28673408, 0.28504777, 0.29872340, 0…\n$ NO_Of_UNITS          <dbl> 18, 20, 27, 30, 30, 31, 32, 32, 32, 32, 34, 34, 3…\n$ FAMILY_FRIENDLY      <dbl> 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0…\n$ FREEHOLD             <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1…\n$ LEASEHOLD_99YR       <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n\n\n\nhead(condo_resale$LONGITUDE) #see the data in XCOORD column\n\n[1] 103.7802 103.8123 103.7971 103.8247 103.9505 103.9386\n\n\n\nhead(condo_resale$LATITUDE) #see the data in YCOORD column\n\n[1] 1.287145 1.328698 1.313727 1.308563 1.321437 1.314198\n\n\n\nsummary(condo_resale)\n\n    LATITUDE       LONGITUDE        POSTCODE      SELLING_PRICE     \n Min.   :1.240   Min.   :103.7   Min.   : 18965   Min.   :  540000  \n 1st Qu.:1.309   1st Qu.:103.8   1st Qu.:259849   1st Qu.: 1100000  \n Median :1.328   Median :103.8   Median :469298   Median : 1383222  \n Mean   :1.334   Mean   :103.8   Mean   :440439   Mean   : 1751211  \n 3rd Qu.:1.357   3rd Qu.:103.9   3rd Qu.:589486   3rd Qu.: 1950000  \n Max.   :1.454   Max.   :104.0   Max.   :828833   Max.   :18000000  \n    AREA_SQM          AGE           PROX_CBD       PROX_CHILDCARE    \n Min.   : 34.0   Min.   : 0.00   Min.   : 0.3869   Min.   :0.004927  \n 1st Qu.:103.0   1st Qu.: 5.00   1st Qu.: 5.5574   1st Qu.:0.174481  \n Median :121.0   Median :11.00   Median : 9.3567   Median :0.258135  \n Mean   :136.5   Mean   :12.14   Mean   : 9.3254   Mean   :0.326313  \n 3rd Qu.:156.0   3rd Qu.:18.00   3rd Qu.:12.6661   3rd Qu.:0.368293  \n Max.   :619.0   Max.   :37.00   Max.   :19.1804   Max.   :3.465726  \n PROX_ELDERLYCARE  PROX_URA_GROWTH_AREA PROX_HAWKER_MARKET PROX_KINDERGARTEN \n Min.   :0.05451   Min.   :0.2145       Min.   :0.05182    Min.   :0.004927  \n 1st Qu.:0.61254   1st Qu.:3.1643       1st Qu.:0.55245    1st Qu.:0.276345  \n Median :0.94179   Median :4.6186       Median :0.90842    Median :0.413385  \n Mean   :1.05351   Mean   :4.5981       Mean   :1.27987    Mean   :0.458903  \n 3rd Qu.:1.35122   3rd Qu.:5.7550       3rd Qu.:1.68578    3rd Qu.:0.578474  \n Max.   :3.94916   Max.   :9.1554       Max.   :5.37435    Max.   :2.229045  \n    PROX_MRT         PROX_PARK       PROX_PRIMARY_SCH  PROX_TOP_PRIMARY_SCH\n Min.   :0.05278   Min.   :0.02906   Min.   :0.07711   Min.   :0.07711     \n 1st Qu.:0.34646   1st Qu.:0.26211   1st Qu.:0.44024   1st Qu.:1.34451     \n Median :0.57430   Median :0.39926   Median :0.63505   Median :1.88213     \n Mean   :0.67316   Mean   :0.49802   Mean   :0.75471   Mean   :2.27347     \n 3rd Qu.:0.84844   3rd Qu.:0.65592   3rd Qu.:0.95104   3rd Qu.:2.90954     \n Max.   :3.48037   Max.   :2.16105   Max.   :3.92899   Max.   :6.74819     \n PROX_SHOPPING_MALL PROX_SUPERMARKET PROX_BUS_STOP       NO_Of_UNITS    \n Min.   :0.0000     Min.   :0.0000   Min.   :0.001595   Min.   :  18.0  \n 1st Qu.:0.5258     1st Qu.:0.3695   1st Qu.:0.098356   1st Qu.: 188.8  \n Median :0.9357     Median :0.5687   Median :0.151710   Median : 360.0  \n Mean   :1.0455     Mean   :0.6141   Mean   :0.193974   Mean   : 409.2  \n 3rd Qu.:1.3994     3rd Qu.:0.7862   3rd Qu.:0.220466   3rd Qu.: 590.0  \n Max.   :3.4774     Max.   :2.2441   Max.   :2.476639   Max.   :1703.0  \n FAMILY_FRIENDLY     FREEHOLD      LEASEHOLD_99YR  \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000  \n Median :0.0000   Median :0.0000   Median :0.0000  \n Mean   :0.4868   Mean   :0.4227   Mean   :0.4882  \n 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n\n\n\ncondo_resale.sf <- st_as_sf(condo_resale,\n                            coords = c(\"LONGITUDE\", \"LATITUDE\"),\n                            crs=4326) %>%\n  st_transform(crs=3414)\n\n\nhead(condo_resale.sf)\n\nSimple feature collection with 6 features and 21 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 22085.12 ymin: 29951.54 xmax: 41042.56 ymax: 34546.2\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 6 × 22\n  POSTCODE SELLI…¹ AREA_…²   AGE PROX_…³ PROX_…⁴ PROX_…⁵ PROX_…⁶ PROX_…⁷ PROX_…⁸\n     <dbl>   <dbl>   <dbl> <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n1   118635 3000000     309    30    7.94   0.166   2.52     6.62   1.77   0.0584\n2   288420 3880000     290    32    6.61   0.280   1.93     7.51   0.545  0.616 \n3   267833 3325000     248    33    6.90   0.429   0.502    6.46   0.378  0.141 \n4   258380 4250000     127     7    4.04   0.395   1.99     4.91   1.68   0.382 \n5   467169 1400000     145    28   11.8    0.119   1.12     6.41   0.565  0.461 \n6   466472 1320000     139    22   10.3    0.125   0.789    5.09   0.781  0.0994\n# … with 12 more variables: PROX_MRT <dbl>, PROX_PARK <dbl>,\n#   PROX_PRIMARY_SCH <dbl>, PROX_TOP_PRIMARY_SCH <dbl>,\n#   PROX_SHOPPING_MALL <dbl>, PROX_SUPERMARKET <dbl>, PROX_BUS_STOP <dbl>,\n#   NO_Of_UNITS <dbl>, FAMILY_FRIENDLY <dbl>, FREEHOLD <dbl>,\n#   LEASEHOLD_99YR <dbl>, geometry <POINT [m]>, and abbreviated variable names\n#   ¹​SELLING_PRICE, ²​AREA_SQM, ³​PROX_CBD, ⁴​PROX_CHILDCARE, ⁵​PROX_ELDERLYCARE,\n#   ⁶​PROX_URA_GROWTH_AREA, ⁷​PROX_HAWKER_MARKET, ⁸​PROX_KINDERGARTEN"
  },
  {
    "objectID": "exercises/hoex8.html#eda-using-statistical-graphics",
    "href": "exercises/hoex8.html#eda-using-statistical-graphics",
    "title": "Hands-on Exercise 8: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "EDA Using Statistical Graphics",
    "text": "EDA Using Statistical Graphics\n\nggplot(data=condo_resale.sf, aes(x=`SELLING_PRICE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\n\n\n\n\ncondo_resale.sf <- condo_resale.sf %>%\n  mutate(`LOG_SELLING_PRICE` = log(SELLING_PRICE))\n\n\nggplot(data=condo_resale.sf, aes(x=`LOG_SELLING_PRICE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")"
  },
  {
    "objectID": "exercises/hoex8.html#multiple-histogram-plots-distribution-of-variables",
    "href": "exercises/hoex8.html#multiple-histogram-plots-distribution-of-variables",
    "title": "Hands-on Exercise 8: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Multiple Histogram Plots Distribution of Variables",
    "text": "Multiple Histogram Plots Distribution of Variables\n\nAREA_SQM <- ggplot(data=condo_resale.sf, aes(x= `AREA_SQM`)) + \n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nAGE <- ggplot(data=condo_resale.sf, aes(x= `AGE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_CBD <- ggplot(data=condo_resale.sf, aes(x= `PROX_CBD`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_CHILDCARE <- ggplot(data=condo_resale.sf, aes(x= `PROX_CHILDCARE`)) + \n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_ELDERLYCARE <- ggplot(data=condo_resale.sf, aes(x= `PROX_ELDERLYCARE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_URA_GROWTH_AREA <- ggplot(data=condo_resale.sf, \n                               aes(x= `PROX_URA_GROWTH_AREA`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_HAWKER_MARKET <- ggplot(data=condo_resale.sf, aes(x= `PROX_HAWKER_MARKET`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_KINDERGARTEN <- ggplot(data=condo_resale.sf, aes(x= `PROX_KINDERGARTEN`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_MRT <- ggplot(data=condo_resale.sf, aes(x= `PROX_MRT`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_PARK <- ggplot(data=condo_resale.sf, aes(x= `PROX_PARK`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_PRIMARY_SCH <- ggplot(data=condo_resale.sf, aes(x= `PROX_PRIMARY_SCH`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_TOP_PRIMARY_SCH <- ggplot(data=condo_resale.sf, \n                               aes(x= `PROX_TOP_PRIMARY_SCH`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nggpubr::ggarrange(AREA_SQM, AGE, PROX_CBD, PROX_CHILDCARE, PROX_ELDERLYCARE, \n          PROX_URA_GROWTH_AREA, PROX_HAWKER_MARKET, PROX_KINDERGARTEN, PROX_MRT,\n          PROX_PARK, PROX_PRIMARY_SCH, PROX_TOP_PRIMARY_SCH,  \n          ncol = 3, nrow = 4)"
  },
  {
    "objectID": "exercises/hoex8.html#drawing-statistical-point-map",
    "href": "exercises/hoex8.html#drawing-statistical-point-map",
    "title": "Hands-on Exercise 8: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Drawing Statistical Point Map",
    "text": "Drawing Statistical Point Map\n\ntmap_mode(\"view\")\n\n\ntmap_options(check.and.fix = TRUE) \ntm_shape(mpsz)+\n  tm_polygons() +\ntm_shape(condo_resale.sf) +  \n  tm_dots(col = \"SELLING_PRICE\",\n          alpha = 0.6,\n          style=\"quantile\") +\n  tm_view(set.zoom.limits = c(11,14))\n\n\n\n\n\n\n\ntmap_mode(\"plot\")"
  },
  {
    "objectID": "exercises/hoex8.html#simple-linear-regression-method",
    "href": "exercises/hoex8.html#simple-linear-regression-method",
    "title": "Hands-on Exercise 8: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Simple Linear Regression Method",
    "text": "Simple Linear Regression Method\n\ncondo.slr <- lm(formula=SELLING_PRICE ~ AREA_SQM, data = condo_resale.sf)\n\n\nsummary(condo.slr)\n\n\nCall:\nlm(formula = SELLING_PRICE ~ AREA_SQM, data = condo_resale.sf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3695815  -391764   -87517   258900 13503875 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -258121.1    63517.2  -4.064 5.09e-05 ***\nAREA_SQM      14719.0      428.1  34.381  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 942700 on 1434 degrees of freedom\nMultiple R-squared:  0.4518,    Adjusted R-squared:  0.4515 \nF-statistic:  1182 on 1 and 1434 DF,  p-value: < 2.2e-16\n\n\n\nggplot(data=condo_resale.sf,  \n       aes(x=`AREA_SQM`, y=`SELLING_PRICE`)) +\n  geom_point() +\n  geom_smooth(method = lm)"
  },
  {
    "objectID": "exercises/hoex8.html#multiple-linear-regression-method",
    "href": "exercises/hoex8.html#multiple-linear-regression-method",
    "title": "Hands-on Exercise 8: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Multiple Linear Regression Method",
    "text": "Multiple Linear Regression Method\n\nVisualising the Relationships of the Independent Variables\n\ncorrplot::corrplot(cor(condo_resale[, 5:23]), diag = FALSE, order = \"AOE\",\n         tl.pos = \"td\", tl.cex = 0.5, method = \"number\", type = \"upper\")"
  },
  {
    "objectID": "exercises/hoex8.html#building-a-hedonic-pricing-model-using-multiple-linear-regression-method",
    "href": "exercises/hoex8.html#building-a-hedonic-pricing-model-using-multiple-linear-regression-method",
    "title": "Hands-on Exercise 8: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Building a Hedonic Pricing Model using Multiple Linear Regression Method",
    "text": "Building a Hedonic Pricing Model using Multiple Linear Regression Method\n\ncondo.mlr <- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE    + \n                  PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\n                  PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + PROX_KINDERGARTEN + \n                  PROX_MRT  + PROX_PARK + PROX_PRIMARY_SCH + \n                  PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + \n                  PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                data=condo_resale.sf)\nsummary(condo.mlr)\n\n\nCall:\nlm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + PROX_CHILDCARE + \n    PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + \n    PROX_KINDERGARTEN + PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + \n    PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3475964  -293923   -23069   241043 12260381 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(>|t|)    \n(Intercept)           481728.40  121441.01   3.967 7.65e-05 ***\nAREA_SQM               12708.32     369.59  34.385  < 2e-16 ***\nAGE                   -24440.82    2763.16  -8.845  < 2e-16 ***\nPROX_CBD              -78669.78    6768.97 -11.622  < 2e-16 ***\nPROX_CHILDCARE       -351617.91  109467.25  -3.212  0.00135 ** \nPROX_ELDERLYCARE      171029.42   42110.51   4.061 5.14e-05 ***\nPROX_URA_GROWTH_AREA   38474.53   12523.57   3.072  0.00217 ** \nPROX_HAWKER_MARKET     23746.10   29299.76   0.810  0.41782    \nPROX_KINDERGARTEN     147468.99   82668.87   1.784  0.07466 .  \nPROX_MRT             -314599.68   57947.44  -5.429 6.66e-08 ***\nPROX_PARK             563280.50   66551.68   8.464  < 2e-16 ***\nPROX_PRIMARY_SCH      180186.08   65237.95   2.762  0.00582 ** \nPROX_TOP_PRIMARY_SCH    2280.04   20410.43   0.112  0.91107    \nPROX_SHOPPING_MALL   -206604.06   42840.60  -4.823 1.57e-06 ***\nPROX_SUPERMARKET      -44991.80   77082.64  -0.584  0.55953    \nPROX_BUS_STOP         683121.35  138353.28   4.938 8.85e-07 ***\nNO_Of_UNITS             -231.18      89.03  -2.597  0.00951 ** \nFAMILY_FRIENDLY       140340.77   47020.55   2.985  0.00289 ** \nFREEHOLD              359913.01   49220.22   7.312 4.38e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 755800 on 1417 degrees of freedom\nMultiple R-squared:  0.6518,    Adjusted R-squared:  0.6474 \nF-statistic: 147.4 on 18 and 1417 DF,  p-value: < 2.2e-16"
  },
  {
    "objectID": "exercises/hoex8.html#preparing-publication-quality-table-olsrr-method",
    "href": "exercises/hoex8.html#preparing-publication-quality-table-olsrr-method",
    "title": "Hands-on Exercise 8: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Preparing Publication Quality Table: olsrr method",
    "text": "Preparing Publication Quality Table: olsrr method\n\ncondo.mlr1 <- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE + \n                   PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\n                   PROX_URA_GROWTH_AREA + PROX_MRT  + PROX_PARK + \n                   PROX_PRIMARY_SCH + PROX_SHOPPING_MALL    + PROX_BUS_STOP + \n                   NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD,\n                 data=condo_resale.sf)\nols_regress(condo.mlr1)\n\n                             Model Summary                               \n------------------------------------------------------------------------\nR                       0.807       RMSE                     755957.289 \nR-Squared               0.651       Coef. Var                    43.168 \nAdj. R-Squared          0.647       MSE                571471422208.591 \nPred R-Squared          0.638       MAE                      414819.628 \n------------------------------------------------------------------------\n RMSE: Root Mean Square Error \n MSE: Mean Square Error \n MAE: Mean Absolute Error \n\n                                     ANOVA                                       \n--------------------------------------------------------------------------------\n                    Sum of                                                      \n                   Squares          DF         Mean Square       F         Sig. \n--------------------------------------------------------------------------------\nRegression    1.512586e+15          14        1.080418e+14    189.059    0.0000 \nResidual      8.120609e+14        1421    571471422208.591                      \nTotal         2.324647e+15        1435                                          \n--------------------------------------------------------------------------------\n\n                                               Parameter Estimates                                                \n-----------------------------------------------------------------------------------------------------------------\n               model           Beta    Std. Error    Std. Beta       t        Sig           lower          upper \n-----------------------------------------------------------------------------------------------------------------\n         (Intercept)     527633.222    108183.223                   4.877    0.000     315417.244     739849.200 \n            AREA_SQM      12777.523       367.479        0.584     34.771    0.000      12056.663      13498.382 \n                 AGE     -24687.739      2754.845       -0.167     -8.962    0.000     -30091.739     -19283.740 \n            PROX_CBD     -77131.323      5763.125       -0.263    -13.384    0.000     -88436.469     -65826.176 \n      PROX_CHILDCARE    -318472.751    107959.512       -0.084     -2.950    0.003    -530249.889    -106695.613 \n    PROX_ELDERLYCARE     185575.623     39901.864        0.090      4.651    0.000     107302.737     263848.510 \nPROX_URA_GROWTH_AREA      39163.254     11754.829        0.060      3.332    0.001      16104.571      62221.936 \n            PROX_MRT    -294745.107     56916.367       -0.112     -5.179    0.000    -406394.234    -183095.980 \n           PROX_PARK     570504.807     65507.029        0.150      8.709    0.000     442003.938     699005.677 \n    PROX_PRIMARY_SCH     159856.136     60234.599        0.062      2.654    0.008      41697.849     278014.424 \n  PROX_SHOPPING_MALL    -220947.251     36561.832       -0.115     -6.043    0.000    -292668.213    -149226.288 \n       PROX_BUS_STOP     682482.221    134513.243        0.134      5.074    0.000     418616.359     946348.082 \n         NO_Of_UNITS       -245.480        87.947       -0.053     -2.791    0.005       -418.000        -72.961 \n     FAMILY_FRIENDLY     146307.576     46893.021        0.057      3.120    0.002      54320.593     238294.560 \n            FREEHOLD     350599.812     48506.485        0.136      7.228    0.000     255447.802     445751.821 \n-----------------------------------------------------------------------------------------------------------------\n\n\n\nPreparing Publication Quality Table: gtsummary method\n\ntbl_regression(condo.mlr1, intercept = TRUE)\n\n\n\n\n\n  \n  \n    \n      Characteristic\n      Beta\n      95% CI1\n      p-value\n    \n  \n  \n    (Intercept)\n527,633\n315,417, 739,849\n<0.001\n    AREA_SQM\n12,778\n12,057, 13,498\n<0.001\n    AGE\n-24,688\n-30,092, -19,284\n<0.001\n    PROX_CBD\n-77,131\n-88,436, -65,826\n<0.001\n    PROX_CHILDCARE\n-318,473\n-530,250, -106,696\n0.003\n    PROX_ELDERLYCARE\n185,576\n107,303, 263,849\n<0.001\n    PROX_URA_GROWTH_AREA\n39,163\n16,105, 62,222\n<0.001\n    PROX_MRT\n-294,745\n-406,394, -183,096\n<0.001\n    PROX_PARK\n570,505\n442,004, 699,006\n<0.001\n    PROX_PRIMARY_SCH\n159,856\n41,698, 278,014\n0.008\n    PROX_SHOPPING_MALL\n-220,947\n-292,668, -149,226\n<0.001\n    PROX_BUS_STOP\n682,482\n418,616, 946,348\n<0.001\n    NO_Of_UNITS\n-245\n-418, -73\n0.005\n    FAMILY_FRIENDLY\n146,308\n54,321, 238,295\n0.002\n    FREEHOLD\n350,600\n255,448, 445,752\n<0.001\n  \n  \n  \n    \n      1 CI = Confidence Interval\n    \n  \n\n\n\n\n\ntbl_regression(condo.mlr1, \n               intercept = TRUE) %>% \n  add_glance_source_note(\n    label = list(sigma ~ \"\\U03C3\"),\n    include = c(r.squared, adj.r.squared, \n                AIC, statistic,\n                p.value, sigma))\n\n\n\n\n\n  \n  \n    \n      Characteristic\n      Beta\n      95% CI1\n      p-value\n    \n  \n  \n    (Intercept)\n527,633\n315,417, 739,849\n<0.001\n    AREA_SQM\n12,778\n12,057, 13,498\n<0.001\n    AGE\n-24,688\n-30,092, -19,284\n<0.001\n    PROX_CBD\n-77,131\n-88,436, -65,826\n<0.001\n    PROX_CHILDCARE\n-318,473\n-530,250, -106,696\n0.003\n    PROX_ELDERLYCARE\n185,576\n107,303, 263,849\n<0.001\n    PROX_URA_GROWTH_AREA\n39,163\n16,105, 62,222\n<0.001\n    PROX_MRT\n-294,745\n-406,394, -183,096\n<0.001\n    PROX_PARK\n570,505\n442,004, 699,006\n<0.001\n    PROX_PRIMARY_SCH\n159,856\n41,698, 278,014\n0.008\n    PROX_SHOPPING_MALL\n-220,947\n-292,668, -149,226\n<0.001\n    PROX_BUS_STOP\n682,482\n418,616, 946,348\n<0.001\n    NO_Of_UNITS\n-245\n-418, -73\n0.005\n    FAMILY_FRIENDLY\n146,308\n54,321, 238,295\n0.002\n    FREEHOLD\n350,600\n255,448, 445,752\n<0.001\n  \n  \n    \n      R² = 0.651; Adjusted R² = 0.647; AIC = 42,967; Statistic = 189; p-value = <0.001; σ = 755,957\n    \n  \n  \n    \n      1 CI = Confidence Interval\n    \n  \n\n\n\n\n\n\nChecking for Multicolinearity\n\nols_vif_tol(condo.mlr1)\n\n              Variables Tolerance      VIF\n1              AREA_SQM 0.8728554 1.145665\n2                   AGE 0.7071275 1.414172\n3              PROX_CBD 0.6356147 1.573280\n4        PROX_CHILDCARE 0.3066019 3.261559\n5      PROX_ELDERLYCARE 0.6598479 1.515501\n6  PROX_URA_GROWTH_AREA 0.7510311 1.331503\n7              PROX_MRT 0.5236090 1.909822\n8             PROX_PARK 0.8279261 1.207837\n9      PROX_PRIMARY_SCH 0.4524628 2.210126\n10   PROX_SHOPPING_MALL 0.6738795 1.483945\n11        PROX_BUS_STOP 0.3514118 2.845664\n12          NO_Of_UNITS 0.6901036 1.449058\n13      FAMILY_FRIENDLY 0.7244157 1.380423\n14             FREEHOLD 0.6931163 1.442759\n\n\n\n\nTest for Non-linearity\n\nols_plot_resid_fit(condo.mlr1)\n\n\n\n\n\n\nTest for Normal Assumption\n\nols_plot_resid_hist(condo.mlr1)\n\n\n\n\n\nols_test_normality(condo.mlr1)\n\n-----------------------------------------------\n       Test             Statistic       pvalue  \n-----------------------------------------------\nShapiro-Wilk              0.6856         0.0000 \nKolmogorov-Smirnov        0.1366         0.0000 \nCramer-von Mises         121.0768        0.0000 \nAnderson-Darling         67.9551         0.0000 \n-----------------------------------------------\n\n\n\n\nTesting for Spatial Autocorrelation\n\nmlr.output <- as.data.frame(condo.mlr1$residuals)\n\n\ncondo_resale.res.sf <- cbind(condo_resale.sf, \n                        condo.mlr1$residuals) %>%\nrename(`MLR_RES` = `condo.mlr1.residuals`)\n\n\ncondo_resale.sp <- as_Spatial(condo_resale.res.sf)\ncondo_resale.sp\n\nclass       : SpatialPointsDataFrame \nfeatures    : 1436 \nextent      : 14940.85, 43352.45, 24765.67, 48382.81  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 23\nnames       : POSTCODE, SELLING_PRICE, AREA_SQM, AGE,    PROX_CBD, PROX_CHILDCARE, PROX_ELDERLYCARE, PROX_URA_GROWTH_AREA, PROX_HAWKER_MARKET, PROX_KINDERGARTEN,    PROX_MRT,   PROX_PARK, PROX_PRIMARY_SCH, PROX_TOP_PRIMARY_SCH, PROX_SHOPPING_MALL, ... \nmin values  :    18965,        540000,       34,   0, 0.386916393,    0.004927023,      0.054508623,          0.214539508,        0.051817113,       0.004927023, 0.052779424, 0.029064164,      0.077106132,          0.077106132,                  0, ... \nmax values  :   828833,       1.8e+07,      619,  37, 19.18042832,     3.46572633,      3.949157205,           9.15540001,        5.374348075,       2.229045366,  3.48037319,  2.16104919,      3.928989144,          6.748192062,        3.477433767, ... \n\n\n\ntmap_mode(\"view\")\n\n\ntm_shape(mpsz)+\n  tmap_options(check.and.fix = TRUE) +\n  tm_polygons(alpha = 0.4) +\ntm_shape(condo_resale.res.sf) +  \n  tm_dots(col = \"MLR_RES\",\n          alpha = 0.6,\n          style=\"quantile\") +\n  tm_view(set.zoom.limits = c(11,14))\n\n\n\n\n\n\n\ntmap_mode(\"plot\")\n\n\nnb <- dnearneigh(coordinates(condo_resale.sp), 0, 1500, longlat = FALSE)\nsummary(nb)\n\nNeighbour list object:\nNumber of regions: 1436 \nNumber of nonzero links: 66266 \nPercentage nonzero weights: 3.213526 \nAverage number of links: 46.14624 \nLink number distribution:\n\n  1   3   5   7   9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24 \n  3   3   9   4   3  15  10  19  17  45  19   5  14  29  19   6  35  45  18  47 \n 25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44 \n 16  43  22  26  21  11   9  23  22  13  16  25  21  37  16  18   8  21   4  12 \n 45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64 \n  8  36  18  14  14  43  11  12   8  13  12  13   4   5   6  12  11  20  29  33 \n 65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84 \n 15  20  10  14  15  15  11  16  12  10   8  19  12  14   9   8   4  13  11   6 \n 85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 \n  4   9   4   4   4   6   2  16   9   4   5   9   3   9   4   2   1   2   1   1 \n105 106 107 108 109 110 112 116 125 \n  1   5   9   2   1   3   1   1   1 \n3 least connected regions:\n193 194 277 with 1 link\n1 most connected region:\n285 with 125 links\n\n\n\nnb_lw <- nb2listw(nb, style = 'W')\nsummary(nb_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 1436 \nNumber of nonzero links: 66266 \nPercentage nonzero weights: 3.213526 \nAverage number of links: 46.14624 \nLink number distribution:\n\n  1   3   5   7   9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24 \n  3   3   9   4   3  15  10  19  17  45  19   5  14  29  19   6  35  45  18  47 \n 25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44 \n 16  43  22  26  21  11   9  23  22  13  16  25  21  37  16  18   8  21   4  12 \n 45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64 \n  8  36  18  14  14  43  11  12   8  13  12  13   4   5   6  12  11  20  29  33 \n 65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84 \n 15  20  10  14  15  15  11  16  12  10   8  19  12  14   9   8   4  13  11   6 \n 85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 \n  4   9   4   4   4   6   2  16   9   4   5   9   3   9   4   2   1   2   1   1 \n105 106 107 108 109 110 112 116 125 \n  1   5   9   2   1   3   1   1   1 \n3 least connected regions:\n193 194 277 with 1 link\n1 most connected region:\n285 with 125 links\n\nWeights style: W \nWeights constants summary:\n     n      nn   S0       S1       S2\nW 1436 2062096 1436 94.81916 5798.341\n\n\n\nlm.morantest(condo.mlr1, nb_lw)\n\n\n    Global Moran I for regression residuals\n\ndata:  \nmodel: lm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD +\nPROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_MRT +\nPROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP +\nNO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, data = condo_resale.sf)\nweights: nb_lw\n\nMoran I statistic standard deviate = 24.366, p-value < 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nObserved Moran I      Expectation         Variance \n    1.438876e-01    -5.487594e-03     3.758259e-05"
  },
  {
    "objectID": "exercises/hoex8.html#building-fixed-bandwidth-gwr-model",
    "href": "exercises/hoex8.html#building-fixed-bandwidth-gwr-model",
    "title": "Hands-on Exercise 8: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Building Fixed Bandwidth GWR Model",
    "text": "Building Fixed Bandwidth GWR Model\n\nComputing fixed bandwith\n\nbw.fixed <- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n                     PROX_CHILDCARE + PROX_ELDERLYCARE  + PROX_URA_GROWTH_AREA + \n                     PROX_MRT   + PROX_PARK + PROX_PRIMARY_SCH + \n                     PROX_SHOPPING_MALL + PROX_BUS_STOP + NO_Of_UNITS + \n                     FAMILY_FRIENDLY + FREEHOLD, \n                   data=condo_resale.sp, \n                   approach=\"CV\", \n                   kernel=\"gaussian\", \n                   adaptive=FALSE, \n                   longlat=FALSE)\n\nFixed bandwidth: 17660.96 CV score: 8.259118e+14 \nFixed bandwidth: 10917.26 CV score: 7.970454e+14 \nFixed bandwidth: 6749.419 CV score: 7.273273e+14 \nFixed bandwidth: 4173.553 CV score: 6.300006e+14 \nFixed bandwidth: 2581.58 CV score: 5.404958e+14 \nFixed bandwidth: 1597.687 CV score: 4.857515e+14 \nFixed bandwidth: 989.6077 CV score: 4.722431e+14 \nFixed bandwidth: 613.7939 CV score: 1.378294e+16 \nFixed bandwidth: 1221.873 CV score: 4.778717e+14 \nFixed bandwidth: 846.0596 CV score: 4.791629e+14 \nFixed bandwidth: 1078.325 CV score: 4.751406e+14 \nFixed bandwidth: 934.7772 CV score: 4.72518e+14 \nFixed bandwidth: 1023.495 CV score: 4.730305e+14 \nFixed bandwidth: 968.6643 CV score: 4.721317e+14 \nFixed bandwidth: 955.7206 CV score: 4.722072e+14 \nFixed bandwidth: 976.6639 CV score: 4.721387e+14 \nFixed bandwidth: 963.7202 CV score: 4.721484e+14 \nFixed bandwidth: 971.7199 CV score: 4.721293e+14 \nFixed bandwidth: 973.6083 CV score: 4.721309e+14 \nFixed bandwidth: 970.5527 CV score: 4.721295e+14 \nFixed bandwidth: 972.4412 CV score: 4.721296e+14 \nFixed bandwidth: 971.2741 CV score: 4.721292e+14 \nFixed bandwidth: 970.9985 CV score: 4.721293e+14 \nFixed bandwidth: 971.4443 CV score: 4.721292e+14 \nFixed bandwidth: 971.5496 CV score: 4.721293e+14 \nFixed bandwidth: 971.3793 CV score: 4.721292e+14 \nFixed bandwidth: 971.3391 CV score: 4.721292e+14 \nFixed bandwidth: 971.3143 CV score: 4.721292e+14 \nFixed bandwidth: 971.3545 CV score: 4.721292e+14 \nFixed bandwidth: 971.3296 CV score: 4.721292e+14 \nFixed bandwidth: 971.345 CV score: 4.721292e+14 \nFixed bandwidth: 971.3355 CV score: 4.721292e+14 \nFixed bandwidth: 971.3413 CV score: 4.721292e+14 \nFixed bandwidth: 971.3377 CV score: 4.721292e+14 \nFixed bandwidth: 971.34 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \nFixed bandwidth: 971.3408 CV score: 4.721292e+14 \nFixed bandwidth: 971.3403 CV score: 4.721292e+14 \nFixed bandwidth: 971.3406 CV score: 4.721292e+14 \nFixed bandwidth: 971.3404 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \n\n\n\n\nGWModel Method - Fixed Bandwidth\n\ngwr.fixed <- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n                         PROX_CHILDCARE + PROX_ELDERLYCARE  + PROX_URA_GROWTH_AREA + \n                         PROX_MRT   + PROX_PARK + PROX_PRIMARY_SCH + \n                         PROX_SHOPPING_MALL + PROX_BUS_STOP + NO_Of_UNITS + \n                         FAMILY_FRIENDLY + FREEHOLD, \n                       data=condo_resale.sp, \n                       bw=bw.fixed, \n                       kernel = 'gaussian', \n                       longlat = FALSE)\n\n\ngwr.fixed\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2023-03-12 15:31:24 \n   Call:\n   gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n    PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n    PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sp, bw = bw.fixed, kernel = \"gaussian\", \n    longlat = FALSE)\n\n   Dependent (y) variable:  SELLING_PRICE\n   Independent variables:  AREA_SQM AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE PROX_URA_GROWTH_AREA PROX_MRT PROX_PARK PROX_PRIMARY_SCH PROX_SHOPPING_MALL PROX_BUS_STOP NO_Of_UNITS FAMILY_FRIENDLY FREEHOLD\n   Number of data points: 1436\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n     Min       1Q   Median       3Q      Max \n-3470778  -298119   -23481   248917 12234210 \n\n   Coefficients:\n                          Estimate Std. Error t value Pr(>|t|)    \n   (Intercept)           527633.22  108183.22   4.877 1.20e-06 ***\n   AREA_SQM               12777.52     367.48  34.771  < 2e-16 ***\n   AGE                   -24687.74    2754.84  -8.962  < 2e-16 ***\n   PROX_CBD              -77131.32    5763.12 -13.384  < 2e-16 ***\n   PROX_CHILDCARE       -318472.75  107959.51  -2.950 0.003231 ** \n   PROX_ELDERLYCARE      185575.62   39901.86   4.651 3.61e-06 ***\n   PROX_URA_GROWTH_AREA   39163.25   11754.83   3.332 0.000885 ***\n   PROX_MRT             -294745.11   56916.37  -5.179 2.56e-07 ***\n   PROX_PARK             570504.81   65507.03   8.709  < 2e-16 ***\n   PROX_PRIMARY_SCH      159856.14   60234.60   2.654 0.008046 ** \n   PROX_SHOPPING_MALL   -220947.25   36561.83  -6.043 1.93e-09 ***\n   PROX_BUS_STOP         682482.22  134513.24   5.074 4.42e-07 ***\n   NO_Of_UNITS             -245.48      87.95  -2.791 0.005321 ** \n   FAMILY_FRIENDLY       146307.58   46893.02   3.120 0.001845 ** \n   FREEHOLD              350599.81   48506.48   7.228 7.98e-13 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 756000 on 1421 degrees of freedom\n   Multiple R-squared: 0.6507\n   Adjusted R-squared: 0.6472 \n   F-statistic: 189.1 on 14 and 1421 DF,  p-value: < 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 8.120609e+14\n   Sigma(hat): 752522.9\n   AIC:  42966.76\n   AICc:  42967.14\n   BIC:  41731.39\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Fixed bandwidth: 971.3405 \n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                               Min.     1st Qu.      Median     3rd Qu.\n   Intercept            -3.5988e+07 -5.1998e+05  7.6780e+05  1.7412e+06\n   AREA_SQM              1.0003e+03  5.2758e+03  7.4740e+03  1.2301e+04\n   AGE                  -1.3475e+05 -2.0813e+04 -8.6260e+03 -3.7784e+03\n   PROX_CBD             -7.7047e+07 -2.3608e+05 -8.3600e+04  3.4646e+04\n   PROX_CHILDCARE       -6.0097e+06 -3.3667e+05 -9.7425e+04  2.9007e+05\n   PROX_ELDERLYCARE     -3.5000e+06 -1.5970e+05  3.1971e+04  1.9577e+05\n   PROX_URA_GROWTH_AREA -3.0170e+06 -8.2013e+04  7.0749e+04  2.2612e+05\n   PROX_MRT             -3.5282e+06 -6.5836e+05 -1.8833e+05  3.6922e+04\n   PROX_PARK            -1.2062e+06 -2.1732e+05  3.5383e+04  4.1335e+05\n   PROX_PRIMARY_SCH     -2.2695e+07 -1.7066e+05  4.8472e+04  5.1555e+05\n   PROX_SHOPPING_MALL   -7.2585e+06 -1.6684e+05 -1.0517e+04  1.5923e+05\n   PROX_BUS_STOP        -1.4676e+06 -4.5207e+04  3.7601e+05  1.1664e+06\n   NO_Of_UNITS          -1.3170e+03 -2.4822e+02 -3.0846e+01  2.5496e+02\n   FAMILY_FRIENDLY      -2.2749e+06 -1.1140e+05  7.6214e+03  1.6107e+05\n   FREEHOLD             -9.2067e+06  3.8073e+04  1.5169e+05  3.7528e+05\n                             Max.\n   Intercept            112793548\n   AREA_SQM                 21575\n   AGE                     434201\n   PROX_CBD               2704596\n   PROX_CHILDCARE         1654087\n   PROX_ELDERLYCARE      38867814\n   PROX_URA_GROWTH_AREA  78515730\n   PROX_MRT               3124316\n   PROX_PARK             18122425\n   PROX_PRIMARY_SCH       4637503\n   PROX_SHOPPING_MALL     1529952\n   PROX_BUS_STOP         11342182\n   NO_Of_UNITS              12907\n   FAMILY_FRIENDLY        1720744\n   FREEHOLD               6073636\n   ************************Diagnostic information*************************\n   Number of data points: 1436 \n   Effective number of parameters (2trace(S) - trace(S'S)): 438.3804 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 997.6196 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 42263.61 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 41632.36 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 42515.71 \n   Residual sum of squares: 2.53407e+14 \n   R-square value:  0.8909912 \n   Adjusted R-square value:  0.8430417 \n\n   ***********************************************************************\n   Program stops at: 2023-03-12 15:31:25"
  },
  {
    "objectID": "exercises/hoex8.html#building-adaptive-bandwidth-gwr-model",
    "href": "exercises/hoex8.html#building-adaptive-bandwidth-gwr-model",
    "title": "Hands-on Exercise 8: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Building Adaptive Bandwidth GWR Model",
    "text": "Building Adaptive Bandwidth GWR Model\n\nComputing the adaptive bandwidth\n\nbw.adaptive <- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE  + \n                        PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE    + \n                        PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + \n                        PROX_PRIMARY_SCH + PROX_SHOPPING_MALL   + PROX_BUS_STOP + \n                        NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                      data=condo_resale.sp, \n                      approach=\"CV\", \n                      kernel=\"gaussian\", \n                      adaptive=TRUE, \n                      longlat=FALSE)\n\nAdaptive bandwidth: 895 CV score: 7.952401e+14 \nAdaptive bandwidth: 561 CV score: 7.667364e+14 \nAdaptive bandwidth: 354 CV score: 6.953454e+14 \nAdaptive bandwidth: 226 CV score: 6.15223e+14 \nAdaptive bandwidth: 147 CV score: 5.674373e+14 \nAdaptive bandwidth: 98 CV score: 5.426745e+14 \nAdaptive bandwidth: 68 CV score: 5.168117e+14 \nAdaptive bandwidth: 49 CV score: 4.859631e+14 \nAdaptive bandwidth: 37 CV score: 4.646518e+14 \nAdaptive bandwidth: 30 CV score: 4.422088e+14 \nAdaptive bandwidth: 25 CV score: 4.430816e+14 \nAdaptive bandwidth: 32 CV score: 4.505602e+14 \nAdaptive bandwidth: 27 CV score: 4.462172e+14 \nAdaptive bandwidth: 30 CV score: 4.422088e+14 \n\n\n\n\nConstructing the adaptive bandwidth gwr model\n\ngwr.adaptive <- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + \n                            PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE + \n                            PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + \n                            PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP + \n                            NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                          data=condo_resale.sp, bw=bw.adaptive, \n                          kernel = 'gaussian', \n                          adaptive=TRUE, \n                          longlat = FALSE)\n\n\ngwr.adaptive\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2023-03-12 15:31:31 \n   Call:\n   gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n    PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n    PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sp, bw = bw.adaptive, kernel = \"gaussian\", \n    adaptive = TRUE, longlat = FALSE)\n\n   Dependent (y) variable:  SELLING_PRICE\n   Independent variables:  AREA_SQM AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE PROX_URA_GROWTH_AREA PROX_MRT PROX_PARK PROX_PRIMARY_SCH PROX_SHOPPING_MALL PROX_BUS_STOP NO_Of_UNITS FAMILY_FRIENDLY FREEHOLD\n   Number of data points: 1436\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n     Min       1Q   Median       3Q      Max \n-3470778  -298119   -23481   248917 12234210 \n\n   Coefficients:\n                          Estimate Std. Error t value Pr(>|t|)    \n   (Intercept)           527633.22  108183.22   4.877 1.20e-06 ***\n   AREA_SQM               12777.52     367.48  34.771  < 2e-16 ***\n   AGE                   -24687.74    2754.84  -8.962  < 2e-16 ***\n   PROX_CBD              -77131.32    5763.12 -13.384  < 2e-16 ***\n   PROX_CHILDCARE       -318472.75  107959.51  -2.950 0.003231 ** \n   PROX_ELDERLYCARE      185575.62   39901.86   4.651 3.61e-06 ***\n   PROX_URA_GROWTH_AREA   39163.25   11754.83   3.332 0.000885 ***\n   PROX_MRT             -294745.11   56916.37  -5.179 2.56e-07 ***\n   PROX_PARK             570504.81   65507.03   8.709  < 2e-16 ***\n   PROX_PRIMARY_SCH      159856.14   60234.60   2.654 0.008046 ** \n   PROX_SHOPPING_MALL   -220947.25   36561.83  -6.043 1.93e-09 ***\n   PROX_BUS_STOP         682482.22  134513.24   5.074 4.42e-07 ***\n   NO_Of_UNITS             -245.48      87.95  -2.791 0.005321 ** \n   FAMILY_FRIENDLY       146307.58   46893.02   3.120 0.001845 ** \n   FREEHOLD              350599.81   48506.48   7.228 7.98e-13 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 756000 on 1421 degrees of freedom\n   Multiple R-squared: 0.6507\n   Adjusted R-squared: 0.6472 \n   F-statistic: 189.1 on 14 and 1421 DF,  p-value: < 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 8.120609e+14\n   Sigma(hat): 752522.9\n   AIC:  42966.76\n   AICc:  42967.14\n   BIC:  41731.39\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Adaptive bandwidth: 30 (number of nearest neighbours)\n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                               Min.     1st Qu.      Median     3rd Qu.\n   Intercept            -1.3487e+08 -2.4669e+05  7.7928e+05  1.6194e+06\n   AREA_SQM              3.3188e+03  5.6285e+03  7.7825e+03  1.2738e+04\n   AGE                  -9.6746e+04 -2.9288e+04 -1.4043e+04 -5.6119e+03\n   PROX_CBD             -2.5330e+06 -1.6256e+05 -7.7242e+04  2.6624e+03\n   PROX_CHILDCARE       -1.2790e+06 -2.0175e+05  8.7158e+03  3.7778e+05\n   PROX_ELDERLYCARE     -1.6212e+06 -9.2050e+04  6.1029e+04  2.8184e+05\n   PROX_URA_GROWTH_AREA -7.2686e+06 -3.0350e+04  4.5869e+04  2.4613e+05\n   PROX_MRT             -4.3781e+07 -6.7282e+05 -2.2115e+05 -7.4593e+04\n   PROX_PARK            -2.9020e+06 -1.6782e+05  1.1601e+05  4.6572e+05\n   PROX_PRIMARY_SCH     -8.6418e+05 -1.6627e+05 -7.7853e+03  4.3222e+05\n   PROX_SHOPPING_MALL   -1.8272e+06 -1.3175e+05 -1.4049e+04  1.3799e+05\n   PROX_BUS_STOP        -2.0579e+06 -7.1461e+04  4.1104e+05  1.2071e+06\n   NO_Of_UNITS          -2.1993e+03 -2.3685e+02 -3.4699e+01  1.1657e+02\n   FAMILY_FRIENDLY      -5.9879e+05 -5.0927e+04  2.6173e+04  2.2481e+05\n   FREEHOLD             -1.6340e+05  4.0765e+04  1.9023e+05  3.7960e+05\n                            Max.\n   Intercept            18758355\n   AREA_SQM                23064\n   AGE                     13303\n   PROX_CBD             11346650\n   PROX_CHILDCARE        2892127\n   PROX_ELDERLYCARE      2465671\n   PROX_URA_GROWTH_AREA  7384059\n   PROX_MRT              1186242\n   PROX_PARK             2588497\n   PROX_PRIMARY_SCH      3381462\n   PROX_SHOPPING_MALL   38038564\n   PROX_BUS_STOP        12081592\n   NO_Of_UNITS              1010\n   FAMILY_FRIENDLY       2072414\n   FREEHOLD              1813995\n   ************************Diagnostic information*************************\n   Number of data points: 1436 \n   Effective number of parameters (2trace(S) - trace(S'S)): 350.3088 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 1085.691 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 41982.22 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 41546.74 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 41914.08 \n   Residual sum of squares: 2.528227e+14 \n   R-square value:  0.8912425 \n   Adjusted R-square value:  0.8561185 \n\n   ***********************************************************************\n   Program stops at: 2023-03-12 15:31:31"
  },
  {
    "objectID": "exercises/hoex8.html#visualising-gwr-output",
    "href": "exercises/hoex8.html#visualising-gwr-output",
    "title": "Hands-on Exercise 8: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Visualising GWR Output",
    "text": "Visualising GWR Output"
  },
  {
    "objectID": "exercises/hoex8.html#converting-sdf-into-sf-data-frame",
    "href": "exercises/hoex8.html#converting-sdf-into-sf-data-frame",
    "title": "Hands-on Exercise 8: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Converting SDF into SF Data Frame",
    "text": "Converting SDF into SF Data Frame\n\ncondo_resale.sf.adaptive <- st_as_sf(gwr.adaptive$SDF) %>%\n  st_transform(crs=3414)\n\n\ncondo_resale.sf.adaptive.svy21 <- st_transform(condo_resale.sf.adaptive, 3414)\ncondo_resale.sf.adaptive.svy21  \n\nSimple feature collection with 1436 features and 51 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 14940.85 ymin: 24765.67 xmax: 43352.45 ymax: 48382.81\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n    Intercept  AREA_SQM        AGE  PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE\n1   2050011.7  9561.892  -9514.634 -120681.9      319266.92       -393417.79\n2   1633128.2 16576.853 -58185.479 -149434.2      441102.18        325188.74\n3   3433608.2 13091.861 -26707.386 -259397.8     -120116.82        535855.81\n4    234358.9 20730.601 -93308.988 2426853.7      480825.28        314783.72\n5   2285804.9  6722.836 -17608.018 -316835.5       90764.78       -137384.61\n6  -3568877.4  6039.581 -26535.592  327306.1     -152531.19       -700392.85\n7  -2874842.4 16843.575 -59166.727 -983577.2     -177810.50       -122384.02\n8   2038086.0  6905.135 -17681.897 -285076.6       70259.40        -96012.78\n9   1718478.4  9580.703 -14401.128  105803.4     -657698.02       -123276.00\n10  3457054.0 14072.011 -31579.884 -234895.4       79961.45        548581.04\n   PROX_URA_GROWTH_AREA    PROX_MRT  PROX_PARK PROX_PRIMARY_SCH\n1            -159980.20  -299742.96 -172104.47        242668.03\n2            -142290.39 -2510522.23  523379.72       1106830.66\n3            -253621.21  -936853.28  209099.85        571462.33\n4           -2679297.89 -2039479.50 -759153.26       3127477.21\n5             303714.81   -44567.05  -10284.62         30413.56\n6             -28051.25   733566.47 1511488.92        320878.23\n7            1397676.38 -2745430.34  710114.74       1786570.95\n8             269368.71   -14552.99   73533.34         53359.73\n9            -361974.72  -476785.32 -132067.59        -40128.92\n10           -150024.38 -1503835.53  574155.47        108996.67\n   PROX_SHOPPING_MALL PROX_BUS_STOP  NO_Of_UNITS FAMILY_FRIENDLY  FREEHOLD\n1          300881.390     1210615.4  104.8290640       -9075.370  303955.6\n2          -87693.378     1843587.2 -288.3441183      310074.664  396221.3\n3         -126732.712     1411924.9   -9.5532945        5949.746  168821.7\n4          -29593.342     7225577.5 -161.3551620     1556178.531 1212515.6\n5           -7490.586      677577.0   42.2659674       58986.951  328175.2\n6          258583.881     1086012.6 -214.3671271      201992.641  471873.1\n7         -384251.210     5094060.5   -0.9212521      359659.512  408871.9\n8          -39634.902      735767.1   30.1741069       55602.506  347075.0\n9          276718.757     2815772.4  675.1615559      -30453.297  503872.8\n10        -454726.822     2123557.0  -21.3044311     -100935.586  213324.6\n         y    yhat    residual CV_Score Stud_residual Intercept_SE AREA_SQM_SE\n1  3000000 2886532   113468.16        0    0.38207013     516105.5    823.2860\n2  3880000 3466801   413198.52        0    1.01433140     488083.5    825.2380\n3  3325000 3616527  -291527.20        0   -0.83780678     963711.4    988.2240\n4  4250000 5435482 -1185481.63        0   -2.84614670     444185.5    617.4007\n5  1400000 1388166    11834.26        0    0.03404453    2119620.6   1376.2778\n6  1320000 1516702  -196701.94        0   -0.72065800   28572883.7   2348.0091\n7  3410000 3266881   143118.77        0    0.41291992     679546.6    893.5893\n8  1420000 1431955   -11955.27        0   -0.03033109    2217773.1   1415.2604\n9  2025000 1832799   192200.83        0    0.52018109     814281.8    943.8434\n10 2550000 2223364   326635.53        0    1.10559735    2410252.0   1271.4073\n      AGE_SE PROX_CBD_SE PROX_CHILDCARE_SE PROX_ELDERLYCARE_SE\n1   5889.782    37411.22          319111.1           120633.34\n2   6226.916    23615.06          299705.3            84546.69\n3   6510.236    56103.77          349128.5           129687.07\n4   6010.511   469337.41          304965.2           127150.69\n5   8180.361   410644.47          698720.6           327371.55\n6  14601.909  5272846.47         1141599.8          1653002.19\n7   8970.629   346164.20          530101.1           148598.71\n8   8661.309   438035.69          742532.8           399221.05\n9  11791.208    89148.35          704630.7           329683.30\n10  9941.980   173532.77          500976.2           281876.74\n   PROX_URA_GROWTH_AREA_SE PROX_MRT_SE PROX_PARK_SE PROX_PRIMARY_SCH_SE\n1                 56207.39    185181.3     205499.6            152400.7\n2                 76956.50    281133.9     229358.7            165150.7\n3                 95774.60    275483.7     314124.3            196662.6\n4                470762.12    279877.1     227249.4            240878.9\n5                474339.56    363830.0     364580.9            249087.7\n6               5496627.21    730453.2    1741712.0            683265.5\n7                371692.97    375511.9     297400.9            344602.8\n8                517977.91    423155.4     440984.4            261251.2\n9                153436.22    285325.4     304998.4            278258.5\n10               239182.57    571355.7     599131.8            331284.8\n   PROX_SHOPPING_MALL_SE PROX_BUS_STOP_SE NO_Of_UNITS_SE FAMILY_FRIENDLY_SE\n1               109268.8         600668.6       218.1258           131474.7\n2                98906.8         410222.1       208.9410           114989.1\n3               119913.3         464156.7       210.9828           146607.2\n4               177104.1         562810.8       361.7767           108726.6\n5               301032.9         740922.4       299.5034           160663.7\n6              2931208.6        1418333.3       602.5571           331727.0\n7               249969.5         821236.4       532.1978           129241.2\n8               351634.0         775038.4       338.6777           171895.1\n9               289872.7         850095.5       439.9037           220223.4\n10              265529.7         631399.2       259.0169           189125.5\n   FREEHOLD_SE Intercept_TV AREA_SQM_TV     AGE_TV PROX_CBD_TV\n1     115954.0    3.9720784   11.614302  -1.615447 -3.22582173\n2     130110.0    3.3460017   20.087361  -9.344188 -6.32792021\n3     141031.5    3.5629010   13.247868  -4.102368 -4.62353528\n4     138239.1    0.5276150   33.577223 -15.524302  5.17080808\n5     210641.1    1.0784029    4.884795  -2.152474 -0.77155660\n6     374347.3   -0.1249043    2.572214  -1.817269  0.06207388\n7     182216.9   -4.2305303   18.849348  -6.595605 -2.84136028\n8     216649.4    0.9189786    4.879056  -2.041481 -0.65080678\n9     220473.7    2.1104224   10.150733  -1.221345  1.18682383\n10    206346.2    1.4343123   11.068059  -3.176418 -1.35360852\n   PROX_CHILDCARE_TV PROX_ELDERLYCARE_TV PROX_URA_GROWTH_AREA_TV PROX_MRT_TV\n1         1.00048819          -3.2612693            -2.846248368 -1.61864578\n2         1.47178634           3.8462625            -1.848971738 -8.92998600\n3        -0.34404755           4.1319138            -2.648105057 -3.40075727\n4         1.57665606           2.4756745            -5.691404992 -7.28705261\n5         0.12990138          -0.4196596             0.640289855 -0.12249416\n6        -0.13361179          -0.4237096            -0.005103357  1.00426206\n7        -0.33542751          -0.8235874             3.760298131 -7.31116712\n8         0.09462126          -0.2405003             0.520038994 -0.03439159\n9        -0.93339393          -0.3739225            -2.359121712 -1.67102293\n10        0.15961128           1.9461735            -0.627237944 -2.63204802\n   PROX_PARK_TV PROX_PRIMARY_SCH_TV PROX_SHOPPING_MALL_TV PROX_BUS_STOP_TV\n1   -0.83749312           1.5923022            2.75358842        2.0154464\n2    2.28192684           6.7019454           -0.88662640        4.4941192\n3    0.66565951           2.9058009           -1.05686949        3.0419145\n4   -3.34061770          12.9836105           -0.16709578       12.8383775\n5   -0.02820944           0.1220998           -0.02488294        0.9145046\n6    0.86781794           0.4696245            0.08821750        0.7656963\n7    2.38773567           5.1844351           -1.53719231        6.2029165\n8    0.16674816           0.2042469           -0.11271635        0.9493299\n9   -0.43301073          -0.1442145            0.95462153        3.3123012\n10   0.95831249           0.3290120           -1.71252687        3.3632555\n   NO_Of_UNITS_TV FAMILY_FRIENDLY_TV FREEHOLD_TV  Local_R2\n1     0.480589953        -0.06902748    2.621347 0.8846744\n2    -1.380026395         2.69655779    3.045280 0.8899773\n3    -0.045279967         0.04058290    1.197050 0.8947007\n4    -0.446007570        14.31276425    8.771149 0.9073605\n5     0.141120178         0.36714544    1.557983 0.9510057\n6    -0.355762335         0.60891234    1.260522 0.9247586\n7    -0.001731033         2.78285441    2.243875 0.8310458\n8     0.089093858         0.32346758    1.602012 0.9463936\n9     1.534793921        -0.13828365    2.285410 0.8380365\n10   -0.082251138        -0.53369623    1.033819 0.9080753\n                    geometry\n1  POINT (22085.12 29951.54)\n2   POINT (25656.84 34546.2)\n3   POINT (23963.99 32890.8)\n4  POINT (27044.28 32319.77)\n5  POINT (41042.56 33743.64)\n6   POINT (39717.04 32943.1)\n7   POINT (28419.1 33513.37)\n8  POINT (40763.57 33879.61)\n9  POINT (23595.63 28884.78)\n10 POINT (24586.56 33194.31)\n\n\n\ngwr.adaptive.output <- as.data.frame(gwr.adaptive$SDF)\ncondo_resale.sf.adaptive <- cbind(condo_resale.res.sf, as.matrix(gwr.adaptive.output))\n\n\nglimpse(condo_resale.sf.adaptive)\n\nRows: 1,436\nColumns: 77\n$ POSTCODE                <dbl> 118635, 288420, 267833, 258380, 467169, 466472…\n$ SELLING_PRICE           <dbl> 3000000, 3880000, 3325000, 4250000, 1400000, 1…\n$ AREA_SQM                <dbl> 309, 290, 248, 127, 145, 139, 218, 141, 165, 1…\n$ AGE                     <dbl> 30, 32, 33, 7, 28, 22, 24, 24, 27, 31, 17, 22,…\n$ PROX_CBD                <dbl> 7.941259, 6.609797, 6.898000, 4.038861, 11.783…\n$ PROX_CHILDCARE          <dbl> 0.16597932, 0.28027246, 0.42922669, 0.39473543…\n$ PROX_ELDERLYCARE        <dbl> 2.5198118, 1.9333338, 0.5021395, 1.9910316, 1.…\n$ PROX_URA_GROWTH_AREA    <dbl> 6.618741, 7.505109, 6.463887, 4.906512, 6.4106…\n$ PROX_HAWKER_MARKET      <dbl> 1.76542207, 0.54507614, 0.37789301, 1.68259969…\n$ PROX_KINDERGARTEN       <dbl> 0.05835552, 0.61592412, 0.14120309, 0.38200076…\n$ PROX_MRT                <dbl> 0.5607188, 0.6584461, 0.3053433, 0.6910183, 0.…\n$ PROX_PARK               <dbl> 1.1710446, 0.1992269, 0.2779886, 0.9832843, 0.…\n$ PROX_PRIMARY_SCH        <dbl> 1.6340256, 0.9747834, 1.4715016, 1.4546324, 0.…\n$ PROX_TOP_PRIMARY_SCH    <dbl> 3.3273195, 0.9747834, 1.4715016, 2.3006394, 0.…\n$ PROX_SHOPPING_MALL      <dbl> 2.2102717, 2.9374279, 1.2256850, 0.3525671, 1.…\n$ PROX_SUPERMARKET        <dbl> 0.9103958, 0.5900617, 0.4135583, 0.4162219, 0.…\n$ PROX_BUS_STOP           <dbl> 0.10336166, 0.28673408, 0.28504777, 0.29872340…\n$ NO_Of_UNITS             <dbl> 18, 20, 27, 30, 30, 31, 32, 32, 32, 32, 34, 34…\n$ FAMILY_FRIENDLY         <dbl> 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0…\n$ FREEHOLD                <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1…\n$ LEASEHOLD_99YR          <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ LOG_SELLING_PRICE       <dbl> 14.91412, 15.17135, 15.01698, 15.26243, 14.151…\n$ MLR_RES                 <dbl> -1489099.55, 415494.57, 194129.69, 1088992.71,…\n$ Intercept               <dbl> 2050011.67, 1633128.24, 3433608.17, 234358.91,…\n$ AREA_SQM.1              <dbl> 9561.892, 16576.853, 13091.861, 20730.601, 672…\n$ AGE.1                   <dbl> -9514.634, -58185.479, -26707.386, -93308.988,…\n$ PROX_CBD.1              <dbl> -120681.94, -149434.22, -259397.77, 2426853.66…\n$ PROX_CHILDCARE.1        <dbl> 319266.925, 441102.177, -120116.816, 480825.28…\n$ PROX_ELDERLYCARE.1      <dbl> -393417.795, 325188.741, 535855.806, 314783.72…\n$ PROX_URA_GROWTH_AREA.1  <dbl> -159980.203, -142290.389, -253621.206, -267929…\n$ PROX_MRT.1              <dbl> -299742.96, -2510522.23, -936853.28, -2039479.…\n$ PROX_PARK.1             <dbl> -172104.47, 523379.72, 209099.85, -759153.26, …\n$ PROX_PRIMARY_SCH.1      <dbl> 242668.03, 1106830.66, 571462.33, 3127477.21, …\n$ PROX_SHOPPING_MALL.1    <dbl> 300881.390, -87693.378, -126732.712, -29593.34…\n$ PROX_BUS_STOP.1         <dbl> 1210615.44, 1843587.22, 1411924.90, 7225577.51…\n$ NO_Of_UNITS.1           <dbl> 104.8290640, -288.3441183, -9.5532945, -161.35…\n$ FAMILY_FRIENDLY.1       <dbl> -9075.370, 310074.664, 5949.746, 1556178.531, …\n$ FREEHOLD.1              <dbl> 303955.61, 396221.27, 168821.75, 1212515.58, 3…\n$ y                       <dbl> 3000000, 3880000, 3325000, 4250000, 1400000, 1…\n$ yhat                    <dbl> 2886531.8, 3466801.5, 3616527.2, 5435481.6, 13…\n$ residual                <dbl> 113468.16, 413198.52, -291527.20, -1185481.63,…\n$ CV_Score                <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Stud_residual           <dbl> 0.38207013, 1.01433140, -0.83780678, -2.846146…\n$ Intercept_SE            <dbl> 516105.5, 488083.5, 963711.4, 444185.5, 211962…\n$ AREA_SQM_SE             <dbl> 823.2860, 825.2380, 988.2240, 617.4007, 1376.2…\n$ AGE_SE                  <dbl> 5889.782, 6226.916, 6510.236, 6010.511, 8180.3…\n$ PROX_CBD_SE             <dbl> 37411.22, 23615.06, 56103.77, 469337.41, 41064…\n$ PROX_CHILDCARE_SE       <dbl> 319111.1, 299705.3, 349128.5, 304965.2, 698720…\n$ PROX_ELDERLYCARE_SE     <dbl> 120633.34, 84546.69, 129687.07, 127150.69, 327…\n$ PROX_URA_GROWTH_AREA_SE <dbl> 56207.39, 76956.50, 95774.60, 470762.12, 47433…\n$ PROX_MRT_SE             <dbl> 185181.3, 281133.9, 275483.7, 279877.1, 363830…\n$ PROX_PARK_SE            <dbl> 205499.6, 229358.7, 314124.3, 227249.4, 364580…\n$ PROX_PRIMARY_SCH_SE     <dbl> 152400.7, 165150.7, 196662.6, 240878.9, 249087…\n$ PROX_SHOPPING_MALL_SE   <dbl> 109268.8, 98906.8, 119913.3, 177104.1, 301032.…\n$ PROX_BUS_STOP_SE        <dbl> 600668.6, 410222.1, 464156.7, 562810.8, 740922…\n$ NO_Of_UNITS_SE          <dbl> 218.1258, 208.9410, 210.9828, 361.7767, 299.50…\n$ FAMILY_FRIENDLY_SE      <dbl> 131474.73, 114989.07, 146607.22, 108726.62, 16…\n$ FREEHOLD_SE             <dbl> 115954.0, 130110.0, 141031.5, 138239.1, 210641…\n$ Intercept_TV            <dbl> 3.9720784, 3.3460017, 3.5629010, 0.5276150, 1.…\n$ AREA_SQM_TV             <dbl> 11.614302, 20.087361, 13.247868, 33.577223, 4.…\n$ AGE_TV                  <dbl> -1.6154474, -9.3441881, -4.1023685, -15.524301…\n$ PROX_CBD_TV             <dbl> -3.22582173, -6.32792021, -4.62353528, 5.17080…\n$ PROX_CHILDCARE_TV       <dbl> 1.000488185, 1.471786337, -0.344047555, 1.5766…\n$ PROX_ELDERLYCARE_TV     <dbl> -3.26126929, 3.84626245, 4.13191383, 2.4756745…\n$ PROX_URA_GROWTH_AREA_TV <dbl> -2.846248368, -1.848971738, -2.648105057, -5.6…\n$ PROX_MRT_TV             <dbl> -1.61864578, -8.92998600, -3.40075727, -7.2870…\n$ PROX_PARK_TV            <dbl> -0.83749312, 2.28192684, 0.66565951, -3.340617…\n$ PROX_PRIMARY_SCH_TV     <dbl> 1.59230221, 6.70194543, 2.90580089, 12.9836104…\n$ PROX_SHOPPING_MALL_TV   <dbl> 2.753588422, -0.886626400, -1.056869486, -0.16…\n$ PROX_BUS_STOP_TV        <dbl> 2.0154464, 4.4941192, 3.0419145, 12.8383775, 0…\n$ NO_Of_UNITS_TV          <dbl> 0.480589953, -1.380026395, -0.045279967, -0.44…\n$ FAMILY_FRIENDLY_TV      <dbl> -0.06902748, 2.69655779, 0.04058290, 14.312764…\n$ FREEHOLD_TV             <dbl> 2.6213469, 3.0452799, 1.1970499, 8.7711485, 1.…\n$ Local_R2                <dbl> 0.8846744, 0.8899773, 0.8947007, 0.9073605, 0.…\n$ coords.x1               <dbl> 22085.12, 25656.84, 23963.99, 27044.28, 41042.…\n$ coords.x2               <dbl> 29951.54, 34546.20, 32890.80, 32319.77, 33743.…\n$ geometry                <POINT [m]> POINT (22085.12 29951.54), POINT (25656.…\n\n\n\nsummary(gwr.adaptive$SDF$yhat)\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n  171347  1102001  1385528  1751842  1982307 13887901"
  },
  {
    "objectID": "exercises/hoex8.html#visualising-local-r2",
    "href": "exercises/hoex8.html#visualising-local-r2",
    "title": "Hands-on Exercise 8: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Visualising Local R2",
    "text": "Visualising Local R2\n\ntmap_mode(\"view\")\ntm_shape(mpsz)+\n  tm_polygons(alpha = 0.1) +\ntm_shape(condo_resale.sf.adaptive) +  \n  tm_dots(col = \"Local_R2\",\n          border.col = \"gray60\",\n          border.lwd = 1) +\n  tm_view(set.zoom.limits = c(11,14))"
  },
  {
    "objectID": "exercises/hoex8.html#visualising-coefficient-estimates",
    "href": "exercises/hoex8.html#visualising-coefficient-estimates",
    "title": "Hands-on Exercise 8: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Visualising Coefficient Estimates",
    "text": "Visualising Coefficient Estimates\n\ntmap_mode(\"view\")\nAREA_SQM_SE <- tm_shape(mpsz)+\n  tm_polygons(alpha = 0.1) +\ntm_shape(condo_resale.sf.adaptive) +  \n  tm_dots(col = \"AREA_SQM_SE\",\n          border.col = \"gray60\",\n          border.lwd = 1) +\n  tm_view(set.zoom.limits = c(11,14))\n\nAREA_SQM_TV <- tm_shape(mpsz)+\n  tm_polygons(alpha = 0.1) +\ntm_shape(condo_resale.sf.adaptive) +  \n  tm_dots(col = \"AREA_SQM_TV\",\n          border.col = \"gray60\",\n          border.lwd = 1) +\n  tm_view(set.zoom.limits = c(11,14))\n\ntmap_arrange(AREA_SQM_SE, AREA_SQM_TV, \n             asp=1, ncol=2,\n             sync = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntmap_mode(\"plot\")\n\n\nBy URA Planning Region\n\ntm_shape(mpsz[mpsz$REGION_N==\"CENTRAL REGION\", ])+\n  tm_polygons()+\ntm_shape(condo_resale.sf.adaptive) + \n  tm_bubbles(col = \"Local_R2\",\n           size = 0.15,\n           border.col = \"gray60\",\n           border.lwd = 1)"
  },
  {
    "objectID": "exercises/icex02.html",
    "href": "exercises/icex02.html",
    "title": "In-Class Exercise 2: Geospatial Data Wrangling",
    "section": "",
    "text": "Water is an important resource to mankind. Clean and accessible water is critical to human health. It provides a healthy environment, a sustainable economy, reduces poverty and ensures peace and security. Yet over 40% of the global population does not have access to sufficient clean water. By 2025, 1.8 billion people will be living in countries or regions with absolute water scarcity, according to UN-Water. The lack of water poses a major threat to several sectors, including food security. Agriculture uses about 70% of the world’s accessible freshwater.\nDeveloping countries are most affected by water shortages and poor water quality. Up to 80% of illnesses in the developing world are linked to inadequate water and sanitation. Despite technological advancement, providing clean water to the rural community is still a major development issues in many countries globally, especially countries in the Africa continent.\nTo address the issue of providing clean and sustainable water supply to the ruralcommunity, a global Water Point Data Exchange (WPdx) project has been initiated. The main aim of this initiative is to collect water point related data from rural areas at the water point or small water scheme level and share the data via WPdx Data Repository, a cloud-based data library. What is so special of this project is that data are collected based on WPDx Data Standard.\n\n\nGeospatial analytics hold tremendous potential to address complex problems facing society. In this study, you are tasked to apply appropriate geospatial data wrangling methods to prepare the data for water point mapping study. For the purpose of this study, Nigeria will be used as the study country.\n\n\n\nThe specific tasks of this take-home exercise are as follows:\n\nUsing appropriate sf method, import the shapefile into R and save it in a simple feature data frame format. Note that there are three Projected Coordinate Systems of Nigeria, they are: EPSG: 26391, 26392, and 26303. You can use any one of them.\nUsing appropriate tidyr and dplyr methods, derive the proportion of functional and non-functional water point at LGA level.\nCombining the geospatial and aspatial data frame into simple feature data frame.\nVisualising the distribution of water point by using appropriate analytical visualisation methods."
  },
  {
    "objectID": "exercises/icex02.html#installing-and-loading-packages",
    "href": "exercises/icex02.html#installing-and-loading-packages",
    "title": "In-Class Exercise 2: Geospatial Data Wrangling",
    "section": "2.1 Installing and Loading Packages",
    "text": "2.1 Installing and Loading Packages\nFirstly, the code below will check if pacman has been installed. If it has not been installed, R will download and install it, before activating it for use during this session.\n\nif (!require('pacman', character.only = T)){\n  install.packages('pacman')\n}\nlibrary('pacman')\n\nNext, pacman assists us by helping us load R packages that we require, sf, tidyverse and funModeling.\n\npacman::p_load(sf, tidyverse, funModeling)"
  },
  {
    "objectID": "exercises/icex02.html#data-acquisition",
    "href": "exercises/icex02.html#data-acquisition",
    "title": "In-Class Exercise 2: Geospatial Data Wrangling",
    "section": "2.2 Data Acquisition",
    "text": "2.2 Data Acquisition\nFor the purpose of this exercise, the following public datasets are used:\n\n\n\nDataset Name\nSource\n\n\n\n\nWPdx+ (Water_Point_Data_Exchange_-_Plus__WPdx__.csv)\nWPdx Global Data Repositories\n\n\ngeoBoundaries Nigeria Level-2 Administrative Boundary (geoBoundaries-NGA-ADM2.shp) - UN OCHA CODs\ngeoBoundaries\n\n\nHumanitarian Data Exchange Nigeria Level-2 Administrative Boundary (nga_admbnda_adm2_osgof_20190417.shp)\nHumanitarian Data Exchange\n\n\n\nThe data has been extracted to In-Class_Ex02/data/geospatial."
  },
  {
    "objectID": "exercises/icex02.html#geoboundaries-nigeria-level-2-administrative-boundary-dataset",
    "href": "exercises/icex02.html#geoboundaries-nigeria-level-2-administrative-boundary-dataset",
    "title": "In-Class Exercise 2: Geospatial Data Wrangling",
    "section": "2.3 geoBoundaries Nigeria Level-2 Administrative Boundary Dataset",
    "text": "2.3 geoBoundaries Nigeria Level-2 Administrative Boundary Dataset\n\n2.3.1 Importing geoBoundaries Nigeria Level-2 Administrative Boundary Dataset\nIn the code below, dsn specifies the filepath where the dataset is located and layer provides the filename of the dataset excluding the file extension.\n\ngbnigeria = st_read(dsn = \"In-Class_Ex02/data/geospatial\", layer = \"geoBoundaries-NGA-ADM2\")\n\nReading layer `geoBoundaries-NGA-ADM2' from data source \n  `C:\\renjie-teo\\IS415-GAA\\exercises\\In-Class_Ex02\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 774 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2.668534 ymin: 4.273007 xmax: 14.67882 ymax: 13.89442\nGeodetic CRS:  WGS 84\n\n\nFrom the above message, it tells us that the dataset contains multipolygon features, containing 774 multipolygon features and 5 fields in the gbnigeria simple feature data frame and is in the WGS84 geographic coordinates system.\nLet us check the other dataset from Humanitarian data exchange.\n\nnigeria = st_read(dsn = \"In-Class_Ex02/data/geospatial\", layer = \"nga_admbnda_adm2_osgof_20190417\")\n\nReading layer `nga_admbnda_adm2_osgof_20190417' from data source \n  `C:\\renjie-teo\\IS415-GAA\\exercises\\In-Class_Ex02\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 774 features and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2.668534 ymin: 4.273007 xmax: 14.67882 ymax: 13.89442\nGeodetic CRS:  WGS 84\n\n\nFrom the above message, it tells us that the dataset contains multipolygon features, containing 774 multipolygon features and 16 fields in the gbnigeria simple feature data frame and is in the WGS84 geographic coordinates system.\nBy comparing both datasets, the dataset from Humanitarian Data Exchange is more favourable as we can tell which state the LGA area belongs too which will be beneficial for our analysis\n\n\n2.3.2 Checking the Coordinate Reference System\nIn the code below, we will check if the Coordinate Reference System has been specified correctly.\n\nst_crs(nigeria)\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"latitude\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"longitude\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\n\nAs seen above, the file has been configured correctly, having a WGS84 Geographic Coordinate System which maps to EPSG:4326.\n\n\n2.3.2 Converting the Coordinate Reference System\nIn the code below, we will convert the Geographic Coordinate Reference System from WGS84 to EPSG:26391 Projected Coordinate System.\n\nnigeria26391 <- st_transform(nigeria, crs = 26391)\n\n\nst_crs(nigeria26391)\n\nCoordinate Reference System:\n  User input: EPSG:26391 \n  wkt:\nPROJCRS[\"Minna / Nigeria West Belt\",\n    BASEGEOGCRS[\"Minna\",\n        DATUM[\"Minna\",\n            ELLIPSOID[\"Clarke 1880 (RGS)\",6378249.145,293.465,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4263]],\n    CONVERSION[\"Nigeria West Belt\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",4,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",4.5,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.99975,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",230738.26,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Engineering survey, topographic mapping.\"],\n        AREA[\"Nigeria - onshore west of 6°30'E, onshore and offshore shelf.\"],\n        BBOX[3.57,2.69,13.9,6.5]],\n    ID[\"EPSG\",26391]]\n\n\nAfter running the code, we can confirm that the data frame has been converted to EPSG:26391 Projected Coordinate System."
  },
  {
    "objectID": "exercises/icex02.html#wpdx-aspatial-data",
    "href": "exercises/icex02.html#wpdx-aspatial-data",
    "title": "In-Class Exercise 2: Geospatial Data Wrangling",
    "section": "2.4 WPdx+ Aspatial Data",
    "text": "2.4 WPdx+ Aspatial Data\n\n2.4.1 Importing WPdx+ Aspatial Data\nSince WPdx+ data set is in csv format, we will use read_csv() of readr package to import Water_Point_Data_Exchange_-_Plus__WPdx__.csv and output it to an R object called wpdx.\n\nwpdx <- read_csv(\"In-Class_Ex02/data/aspatial/Water_Point_Data_Exchange_-_Plus__WPdx__.csv\") %>%\n  filter(`#clean_country_name` == \"Nigeria\")\n\n\nlist(wpdx)\n\n[[1]]\n# A tibble: 95,008 × 70\n   row_id `#source`      #lat_…¹ #lon_…² #repo…³ #stat…⁴ #wate…⁵ #wate…⁶ #wate…⁷\n    <dbl> <chr>            <dbl>   <dbl> <chr>   <chr>   <chr>   <chr>   <chr>  \n 1 429068 GRID3             7.98    5.12 08/29/… Unknown <NA>    <NA>    Tapsta…\n 2 222071 Federal Minis…    6.96    3.60 08/16/… Yes     Boreho… Well    Mechan…\n 3 160612 WaterAid          6.49    7.93 12/04/… Yes     Boreho… Well    Hand P…\n 4 160669 WaterAid          6.73    7.65 12/04/… Yes     Boreho… Well    <NA>   \n 5 160642 WaterAid          6.78    7.66 12/04/… Yes     Boreho… Well    Hand P…\n 6 160628 WaterAid          6.96    7.78 12/04/… Yes     Boreho… Well    Hand P…\n 7 160632 WaterAid          7.02    7.84 12/04/… Yes     Boreho… Well    Hand P…\n 8 642747 Living Water …    7.33    8.98 10/03/… Yes     Boreho… Well    Mechan…\n 9 642456 Living Water …    7.17    9.11 10/03/… Yes     Boreho… Well    Hand P…\n10 641347 Living Water …    7.20    9.22 03/28/… Yes     Boreho… Well    Hand P…\n# … with 94,998 more rows, 61 more variables: `#water_tech_category` <chr>,\n#   `#facility_type` <chr>, `#clean_country_name` <chr>, `#clean_adm1` <chr>,\n#   `#clean_adm2` <chr>, `#clean_adm3` <chr>, `#clean_adm4` <chr>,\n#   `#install_year` <dbl>, `#installer` <chr>, `#rehab_year` <lgl>,\n#   `#rehabilitator` <lgl>, `#management_clean` <chr>, `#status_clean` <chr>,\n#   `#pay` <chr>, `#fecal_coliform_presence` <chr>,\n#   `#fecal_coliform_value` <dbl>, `#subjective_quality` <chr>, …\n\n\nOur output shows our wpdx tibble data frame consists of 95,008 rows and 70 columns. The useful fields we would be paying attention to is the #lat_deg and #lon_deg columns, which are in the decimal degree format. By viewing the Data Standard on wpdx’s website, we know that the latitude and longitude is in the wgs84 Geographic Coordinate System.\n\n\n2.4.2 Creating a Simple Feature Data Frame from an Aspatial Data Frame\nAs the geometry is available in wkt in the column New Georeferenced Column, we can use st_as_sfc() to import the geomtry\n\nwpdx$Geometry <- st_as_sfc(wpdx$`New Georeferenced Column`)\n\nAs there is no spatial data information, firstly, we assign the original projection when converting the tibble dataframe to sf. The original is wgs84 which is EPSG:4326.\n\nwpdx_sf <- st_sf(wpdx, crs=4326)\nwpdx_sf\n\nSimple feature collection with 95008 features and 70 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 2.707441 ymin: 4.301812 xmax: 14.21828 ymax: 13.86568\nGeodetic CRS:  WGS 84\n# A tibble: 95,008 × 71\n   row_id `#source`      #lat_…¹ #lon_…² #repo…³ #stat…⁴ #wate…⁵ #wate…⁶ #wate…⁷\n *  <dbl> <chr>            <dbl>   <dbl> <chr>   <chr>   <chr>   <chr>   <chr>  \n 1 429068 GRID3             7.98    5.12 08/29/… Unknown <NA>    <NA>    Tapsta…\n 2 222071 Federal Minis…    6.96    3.60 08/16/… Yes     Boreho… Well    Mechan…\n 3 160612 WaterAid          6.49    7.93 12/04/… Yes     Boreho… Well    Hand P…\n 4 160669 WaterAid          6.73    7.65 12/04/… Yes     Boreho… Well    <NA>   \n 5 160642 WaterAid          6.78    7.66 12/04/… Yes     Boreho… Well    Hand P…\n 6 160628 WaterAid          6.96    7.78 12/04/… Yes     Boreho… Well    Hand P…\n 7 160632 WaterAid          7.02    7.84 12/04/… Yes     Boreho… Well    Hand P…\n 8 642747 Living Water …    7.33    8.98 10/03/… Yes     Boreho… Well    Mechan…\n 9 642456 Living Water …    7.17    9.11 10/03/… Yes     Boreho… Well    Hand P…\n10 641347 Living Water …    7.20    9.22 03/28/… Yes     Boreho… Well    Hand P…\n# … with 94,998 more rows, 62 more variables: `#water_tech_category` <chr>,\n#   `#facility_type` <chr>, `#clean_country_name` <chr>, `#clean_adm1` <chr>,\n#   `#clean_adm2` <chr>, `#clean_adm3` <chr>, `#clean_adm4` <chr>,\n#   `#install_year` <dbl>, `#installer` <chr>, `#rehab_year` <lgl>,\n#   `#rehabilitator` <lgl>, `#management_clean` <chr>, `#status_clean` <chr>,\n#   `#pay` <chr>, `#fecal_coliform_presence` <chr>,\n#   `#fecal_coliform_value` <dbl>, `#subjective_quality` <chr>, …\n\n\nNext, we then convert the projection to the appropriate decimal based projection system.\n\nwpdx_sf <- wpdx_sf %>%\n  st_transform(crs = 26391)"
  },
  {
    "objectID": "exercises/icex02.html#excluding-redundant-fields",
    "href": "exercises/icex02.html#excluding-redundant-fields",
    "title": "In-Class Exercise 2: Geospatial Data Wrangling",
    "section": "3.1 Excluding Redundant Fields",
    "text": "3.1 Excluding Redundant Fields\nAs the wpdx sf dataframe consist of many redundant field, we use select() to select the fields which we want to retain.\n\nnigeria26391 <- nigeria26391 %>%\n  select(c(3:4, 8:9))"
  },
  {
    "objectID": "exercises/icex02.html#checking-for-duplicate-name",
    "href": "exercises/icex02.html#checking-for-duplicate-name",
    "title": "In-Class Exercise 2: Geospatial Data Wrangling",
    "section": "3.2 Checking for Duplicate Name",
    "text": "3.2 Checking for Duplicate Name\nIt is important to check for duplicate name in the data main data fields. Using duplicated(), we can flag out LGA names that might be duplicated as shown below:\n\nnigeria26391$ADM2_EN[duplicated(nigeria26391$ADM2_EN) == TRUE]\n\n[1] \"Bassa\"    \"Ifelodun\" \"Irepodun\" \"Nasarawa\" \"Obi\"      \"Surulere\"\n\n\nTo reduce duplication of LGA names, we will put the state names behind to make it more specific.\n\nnigeria26391$ADM2_EN[94] <- \"Bassa, Kogi\"\nnigeria26391$ADM2_EN[95] <- \"Bassa, Plateau\"\nnigeria26391$ADM2_EN[304] <- \"Ifelodun, Kwara\"\nnigeria26391$ADM2_EN[305] <- \"Ifelodun, Osun\"\nnigeria26391$ADM2_EN[355] <- \"Irepodun, Kwara\"\nnigeria26391$ADM2_EN[356] <- \"Ireopodun, Osun\"\nnigeria26391$ADM2_EN[519] <- \"Nasarawa, Kano\"\nnigeria26391$ADM2_EN[520] <- \"Nasarawa, Nasarawa\"\nnigeria26391$ADM2_EN[546] <- \"Obi, Benue\"\nnigeria26391$ADM2_EN[547] <- \"Obi, Nasarawa\"\nnigeria26391$ADM2_EN[693] <- \"Surulere, Lagos\"\nnigeria26391$ADM2_EN[694] <- \"Surulere, Oyo\"\n\nLet us check now if the duplication has been resolved.\n\nnigeria26391$ADM2_EN[duplicated(nigeria26391$ADM2_EN) == TRUE]\n\ncharacter(0)"
  },
  {
    "objectID": "exercises/icex02.html#understanding-field-names",
    "href": "exercises/icex02.html#understanding-field-names",
    "title": "In-Class Exercise 2: Geospatial Data Wrangling",
    "section": "4.1 Understanding Field Names",
    "text": "4.1 Understanding Field Names\nFirst, let us have a look at the #status_clean column which stores the information about Functional and Non-Functional data points. The code below returns all values that were used in the column.\n\nfreq(data = wpdx_sf,\n     input = '#status_clean')\n\n\n\n\n                     #status_clean frequency percentage cumulative_perc\n1                       Functional     45883      48.29           48.29\n2                   Non-Functional     29385      30.93           79.22\n3                             <NA>     10656      11.22           90.44\n4      Functional but needs repair      4579       4.82           95.26\n5 Non-Functional due to dry season      2403       2.53           97.79\n6        Functional but not in use      1686       1.77           99.56\n7         Abandoned/Decommissioned       234       0.25           99.81\n8                        Abandoned       175       0.18           99.99\n9 Non functional due to dry season         7       0.01          100.00\n\n\nAs there might be issues performing mathematical calculations with NA labels, we will rename them to unknown.\nThe code below renames the column #status_clean to status_clean, select only the status_clean for manipulation and then replace all na values to unknown.\n\nwpdx_sf_nga <- wpdx_sf %>%\n  rename(status_clean = '#status_clean') %>%\n  select(status_clean) %>%\n  mutate(status_clean = replace_na(status_clean, \"unknown\"))"
  },
  {
    "objectID": "exercises/icex02.html#filtering-data",
    "href": "exercises/icex02.html#filtering-data",
    "title": "In-Class Exercise 2: Geospatial Data Wrangling",
    "section": "4.2 Filtering Data",
    "text": "4.2 Filtering Data\nWith our previous knowledge, we can filter the data to obtain functional proportion counts in each LGA level. We will filter the wpdx_sf_nga dataframes to option functional and non-functional water points.\n\nwpdx_func <- wpdx_sf_nga %>% \n  filter(status_clean %in% \n           c(\"Functional\", \n             \"Functional but not in use\", \n             \"Functional but needs repair\"))\nwpdx_nonfunc <- wpdx_sf_nga %>% \n  filter(status_clean %in%\n          c(\"Abadoned/Decommissioned\", \n            \"Abandoned\",\n            \"Non-Functional due to dry season\",\n            \"Non-Functional\",\n            \"Non functional due to dry season\"))\nwpdx_unknown <- wpdx_sf_nga %>%\n  filter(status_clean == \"unknown\")"
  },
  {
    "objectID": "exercises/icex02.html#point-in-polygon-count",
    "href": "exercises/icex02.html#point-in-polygon-count",
    "title": "In-Class Exercise 2: Geospatial Data Wrangling",
    "section": "4.3 Point-in-polygon Count",
    "text": "4.3 Point-in-polygon Count\nUtilising st_intersects() of sf package and lengths, we check where each data point for the water point which fall inside each LGA. We do each calculation separation so we can cross check later to ensure all the values sum to the same total.\n\nnigeria_wp <- nigeria26391 %>%\n  mutate(`total_wp` = lengths(\n    st_intersects(nigeria26391, wpdx_sf_nga))) %>%\n  mutate(`wp_functional` = lengths(\n    st_intersects(nigeria26391, wpdx_func))) %>%\n  mutate(`wp_nonfunctional` = lengths(\n    st_intersects(nigeria26391, wpdx_nonfunc))) %>%\n  mutate(`wp_unknown` = lengths(\n    st_intersects(nigeria26391, wpdx_unknown)))"
  },
  {
    "objectID": "exercises/icex02.html#saving-the-analytical-data-in-rds-format",
    "href": "exercises/icex02.html#saving-the-analytical-data-in-rds-format",
    "title": "In-Class Exercise 2: Geospatial Data Wrangling",
    "section": "4.4 Saving the Analytical Data in rds format",
    "text": "4.4 Saving the Analytical Data in rds format\nIn order to retain the sf data structure for subsequent analysis, we should save the sf dataframe into rds format.\n\nwrite_rds(nigeria_wp, \"In-Class_Ex02/data/rds/nigeria_wp.rds\")"
  },
  {
    "objectID": "exercises/icex02.html#plotting-the-distribution-of-total-water-points-by-lga-in-histogram",
    "href": "exercises/icex02.html#plotting-the-distribution-of-total-water-points-by-lga-in-histogram",
    "title": "In-Class Exercise 2: Geospatial Data Wrangling",
    "section": "4.5 Plotting the Distribution of Total Water Points by LGA in Histogram",
    "text": "4.5 Plotting the Distribution of Total Water Points by LGA in Histogram\nNext, we will use mutate() of dplyr package to compute the proportion of Functional and Non- water points.\nThis is given by Functional Proportion = Functional Count / Total Count.\n\nggplot(data = nigeria_wp,\n       aes(x = total_wp)) +\n  geom_histogram(bins = 20,\n                 color = \"black\",\n                 fill = \"light blue\") +\n  geom_vline(aes(xintercept = mean(\n    total_wp, na.rm = T)),\n    color = \"red\",\n    linetype = \"dashed\",\n    size = 0.8) +\n  ggtitle(\"Distribution of total water points by LGA\") +\n  xlab(\"No. of water points\") +\n  ylab(\"No of\\nLGAs\") +\n  theme(axis.title.y = element_text(angle = 0))"
  },
  {
    "objectID": "exercises/icex03.html",
    "href": "exercises/icex03.html",
    "title": "In-Class Exercise 3: Analytical Mapping",
    "section": "",
    "text": "In this in-class exercise, you will gain hands-on experience on using appropriate R methods to plot analytical maps. For the purpose of this exercise, Nigeria water point data prepared during In-class Exercise 2 will be used.\n\n\n\nBy the end of this in-class exercise, you will be able to use appropriate functions of tmap and tidyverse to perform the following tasks:\n\nImporting geospatial data in rds format into R environment.\nCreating cartographic quality choropleth maps by using appropriate tmap functions.\nCreating rate map\nCreating percentile map\nCreating boxmap"
  },
  {
    "objectID": "exercises/icex03.html#installing-and-loading-packages",
    "href": "exercises/icex03.html#installing-and-loading-packages",
    "title": "In-Class Exercise 3: Analytical Mapping",
    "section": "2.1 Installing and Loading Packages",
    "text": "2.1 Installing and Loading Packages\nFirstly, the code below will check if pacman has been installed. If it has not been installed, R will download and install it, before activating it for use during this session.\n\nif (!require('pacman', character.only = T)){\n  install.packages('pacman')\n}\nlibrary('pacman')\n\nNext, pacman assists us by helping us load R packages that we require, sf, tidyverse and tmap.\n\npacman::p_load(sf, tidyverse, tmap)"
  },
  {
    "objectID": "exercises/icex03.html#importing-data",
    "href": "exercises/icex03.html#importing-data",
    "title": "In-Class Exercise 3: Analytical Mapping",
    "section": "2.2 Importing Data",
    "text": "2.2 Importing Data\nWe want to import the sf dataframe we have cleaned and prepared earlier in In Class Exercise 02.\n\nNGA_wp <- read_rds(\"In-Class_Ex03/data/rds/nigeria_wp.rds\")"
  },
  {
    "objectID": "exercises/icex03.html#visualising-distribution-of-non-functional-water-points",
    "href": "exercises/icex03.html#visualising-distribution-of-non-functional-water-points",
    "title": "In-Class Exercise 3: Analytical Mapping",
    "section": "2.3 Visualising Distribution of Non-Functional Water Points",
    "text": "2.3 Visualising Distribution of Non-Functional Water Points\nHere, we will plot 2 maps, p1 which shows the functional water points and p2 by total number of water points for side-by-side visualisation.\n\np1 <- tm_shape(NGA_wp) +\n  tm_fill(\"wp_functional\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Blues\") +\n  tm_borders(lwd = 0.1,\n             alpha = 1) +\n  tm_layout(main.title = \"Distribution of functional water points by LGA\",\n            legend.outside = FALSE)\n\n\np2 <- tm_shape(NGA_wp) +\n  tm_fill(\"total_wp\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Blues\") +\n  tm_borders(lwd = 0.1,\n             alpha = 1) +\n  tm_layout(main.title = \"Distribution of total water points by LGA\",\n            legend.outside = FALSE)\n\nUsing the tmap_arrange() function, we can arrange the two maps plotted on a single row for side-by-side comparison.\n\ntmap_arrange(p2, p1, nrow = 1)"
  },
  {
    "objectID": "exercises/icex03.html#deriving-proportion-of-functional-water-points-and-non-functional-water-points",
    "href": "exercises/icex03.html#deriving-proportion-of-functional-water-points-and-non-functional-water-points",
    "title": "In-Class Exercise 3: Analytical Mapping",
    "section": "3.1 Deriving Proportion of Functional Water Points and Non-Functional Water Points",
    "text": "3.1 Deriving Proportion of Functional Water Points and Non-Functional Water Points\nWith the code below, we use mutate() to calculate the percentages of functional and nonpfunctional water points.\n\nNGA_wp <- NGA_wp %>%\n  mutate(pct_functional = wp_functional / total_wp) %>%\n  mutate(pct_nonfunctional = wp_nonfunctional / total_wp)"
  },
  {
    "objectID": "exercises/icex03.html#plotting-map-of-rate",
    "href": "exercises/icex03.html#plotting-map-of-rate",
    "title": "In-Class Exercise 3: Analytical Mapping",
    "section": "3.2 Plotting Map of Rate",
    "text": "3.2 Plotting Map of Rate\nUtilising tmap, we can specify the NGA_wp dataframe to colour by pct_functional water points.\n\ntm_shape(NGA_wp) +\n  tm_fill(\"pct_functional\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Blues\") +\n  tm_borders(lwd = 0.1,\n             alpha = 1) +\n  tm_layout(main.title = \"Rate map of functional water points by LGA\",\n            legend.outside = FALSE)"
  },
  {
    "objectID": "exercises/icex03.html#percentile-map",
    "href": "exercises/icex03.html#percentile-map",
    "title": "In-Class Exercise 3: Analytical Mapping",
    "section": "4.1 Percentile Map",
    "text": "4.1 Percentile Map\nA percentile is a special type of quantile map with the following categories:\n\n0-1%\n1-10%\n10-50%\n50-90%\n90-99%\n99 - 100%\n\nTo create the map, we can set the breakpoints as c(0, 0.01, 0.1, 0.5, 0.9, 0.99, 1). Note that the start and endpoints needs to be included.\n\n4.1.1 Data Preparation\nFirstly, we exclude records with NA using the code below:\n\nNGA_wp <- NGA_wp %>%\n  drop_na()\n\nSecondly, we create a customised classification andextract the values.\n\npercent <- c(0, 0.01, 0.1, 0.5, 0.9, 0.99, 1)\nvar <- NGA_wp[\"pct_functional\"] %>%\n  st_set_geometry(NULL)\nquantile(var[,1], percent)\n\n       0%        1%       10%       50%       90%       99%      100% \n0.0000000 0.0000000 0.2169811 0.4791667 0.8611111 1.0000000 1.0000000 \n\n\n\n\n4.1.2 Function to Get Variable Data Frame\nWith the function below, we can extract a variable out of the sf dataframe as a vector.\n\nget.var <- function(vname, df) {\n  v <- df[vname] %>%\n    st_set_geometry(NULL)\n  v <- unname(v[,1])\n  return(v)\n}\n\n\n\n4.1.3 Percentile Mapping Function\nThis percentmap function allows us to take various inputs and automatically calculate the values and points needed for the percentile map.\nThe use of functions allows us to easily plot percentile maps of other variables flexibly without rewriting the entire code.\n\npercentmap <- function(vnam, df, legtitle = NA, mtitle = \"Percentile Map\"){\n  percent <- c(0, 0.01, 0.1, 0.5, 0.9, 0.99, 1)\n  var <- get.var(vnam, df)\n  bperc <- quantile(var, percent)\n  tm_shape(df) +\n  tm_polygons() +\n  tm_shape(df) +\n    tm_fill(vnam,\n            title = legtitle,\n            breaks = bperc,\n            palette = \"Blues\",\n            labels = c(\"< 1%\", \"1% - 10%\", \"10% - 50%\", \"50% - 90%\", \"90% - 99%\", \"99% - 100%\")) +\n  tm_borders() +\n  tm_layout(main.title = mtitle,\n            title.position = c(\"right\", \"bottom\"))\n  }\n\nPlotting the Percentile Map of functional water points.\n\npercentmap(\"wp_functional\", NGA_wp)"
  },
  {
    "objectID": "exercises/icex04.html",
    "href": "exercises/icex04.html",
    "title": "In-Class Exercise 4: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "",
    "text": "Spatial Point Pattern Analysis is the evaluation of the pattern or distribution, of a set of points on a surface. The point can be location of:\n\nevents such as crime, traffic accident and disease onset, or\nbusiness services (coffee and fastfood outlets) or facilities such as childcare and eldercare.\n\nUsing appropriate functions of spatstat, this In Class exercise aims to discover the spatial point processes of childecare centres in Singapore.\nThe specific questions we would like to answer are as follows:\n\nare the childcare centres in Singapore randomly distributed throughout the country?\nif the answer is not, then the next logical question is where are the locations with higher concentration of childcare centres?\n\n\n\n\nFirstly, the code below will check if pacman has been installed. If it has not been installed, R will download and install it, before activating it for use during this session.\n\nif (!require('pacman', character.only = T)){\n  install.packages('pacman')\n}\n\nLoading required package: pacman\n\nlibrary('pacman')\n\nNext, pacman assists us by helping us load R packages that we require, sf, tidyverse and tmap.\n\npacman::p_load(maptools, sf, raster, spatstat, tmap)\n\n\n\n\nThe following public datasets are used:\n\n\n\nDataset Name\nSource\n\n\n\n\nMaster Plan 2014 Subzone Boundary (Web) (MP14_SUBZONE_WEB_PL.shp)\ndata.gov.sg\n\n\nPre-Schools Location (preschools-location.geojson)\ndata.gov.sg\n\n\nCoastal Outline (CostalOutline.shp)\nProf Kam - SLA"
  },
  {
    "objectID": "exercises/icex04.html#importing-spatial-data",
    "href": "exercises/icex04.html#importing-spatial-data",
    "title": "In-Class Exercise 4: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "2.1 Importing Spatial Data",
    "text": "2.1 Importing Spatial Data\nWe will use st_read() of sf package to import the three geospatial datasets.\n\nchildcare_sf <- st_read(dsn = \"In-Class_Ex04/data/geospatial/child-care-services-geojson.geojson\")\n\nReading layer `child-care-services-geojson' from data source \n  `C:\\renjie-teo\\IS415-GAA\\exercises\\In-Class_Ex04\\data\\geospatial\\child-care-services-geojson.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1545 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nsg_sf <- st_read(dsn = \"In-Class_Ex04/data/geospatial\", layer = \"CostalOutline\")\n\nReading layer `CostalOutline' from data source \n  `C:\\renjie-teo\\IS415-GAA\\exercises\\In-Class_Ex04\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21\n\n\n\nmpsz_sf <- st_read(dsn = \"In-Class_Ex04/data/geospatial\", layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\renjie-teo\\IS415-GAA\\exercises\\In-Class_Ex04\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21"
  },
  {
    "objectID": "exercises/icex04.html#inspect-and-reproject-coordinate-system",
    "href": "exercises/icex04.html#inspect-and-reproject-coordinate-system",
    "title": "In-Class Exercise 4: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "2.2 Inspect and Reproject Coordinate System",
    "text": "2.2 Inspect and Reproject Coordinate System\n\n2.2.1 Childcare Dataset\nFirst, we inspect the crs of the sf dataframe.\n\nst_crs(childcare_sf)\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"geodetic latitude (Lat)\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"geodetic longitude (Lon)\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\n\nThe ID provided is EPSG:4326 which matches the intended WGS84 Coordinate reference. We will now convert the CRS from WGS84 Geographic Coordinate System to SVY21 Projected Coordinate System for further analysis.\n\nchildcare_sf <- st_transform(childcare_sf , crs = 3414)\n\n\n\n2.2.2 Coastal Outline Dataset\nFirst, we inspect the crs of the sf dataframe.\n\nst_crs(sg_sf)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nThe ID provided is EPSG:9001 which does not match the intended Projected CRS input of SVY21. Now, we correct the CRS ID using the code below.\n\nsg_sf <- st_set_crs(sg_sf,3414)\n\nWarning: st_crs<- : replacing crs does not reproject data; use st_transform for\nthat\n\n\nNow, let us check if the CRS ID has been set correctly:\n\nst_crs(sg_sf)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\n2.2.3 Master Plan Subzone Dataset\nFirst, we inspect the crs of the sf dataframe.\n\nst_crs(mpsz_sf)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nThe ID provided is EPSG:9001 which does not match the intended Projected CRS input of SVY21. Now, we correct the CRS ID using the code below.\n\nmpsz_sf <- st_set_crs(mpsz_sf,3414)\n\nWarning: st_crs<- : replacing crs does not reproject data; use st_transform for\nthat\n\n\nNow, let us check if the CRS ID has been set correctly:\n\nst_crs(mpsz_sf)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]"
  },
  {
    "objectID": "exercises/icex04.html#mapping-the-geospatial-datasets",
    "href": "exercises/icex04.html#mapping-the-geospatial-datasets",
    "title": "In-Class Exercise 4: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "2.3 Mapping the Geospatial Datasets",
    "text": "2.3 Mapping the Geospatial Datasets\nAfter checking the CRS of each geospatial data frame, we can plot a map to see their spatial patterns.\n\n2.3.1 Static Map\nFirst, we will create a static map to get a general feel of the dataset.\n\nchildcare_sf\n\nSimple feature collection with 1545 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 11203.01 ymin: 25667.6 xmax: 45404.24 ymax: 49300.88\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n     Name\n1   kml_1\n2   kml_2\n3   kml_3\n4   kml_4\n5   kml_5\n6   kml_6\n7   kml_7\n8   kml_8\n9   kml_9\n10 kml_10\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Description\n1                     <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSBLOCKHOUSENUMBER</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSBUILDINGNAME</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSPOSTALCODE</th> <td>760742</td> </tr><tr bgcolor=\"\"> <th>ADDRESSSTREETNAME</th> <td>742, YISHUN AVENUE 5, #01 - 470, SINGAPORE 760742</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSTYPE</th> <td></td> </tr><tr bgcolor=\"\"> <th>DESCRIPTION</th> <td>Child Care Services</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>HYPERLINK</th> <td></td> </tr><tr bgcolor=\"\"> <th>LANDXADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>LANDYADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"\"> <th>NAME</th> <td>AVERBEL CHILD DEVELOPMENT CENTRE PTE LTD</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>PHOTOURL</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSFLOORNUMBER</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>AEA27114446235CE</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20200826094036</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSUNITNUMBER</th> <td></td> </tr></table></center>\n2                                                        <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSBLOCKHOUSENUMBER</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSBUILDINGNAME</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSPOSTALCODE</th> <td>159053</td> </tr><tr bgcolor=\"\"> <th>ADDRESSSTREETNAME</th> <td>20, LENGKOK BAHRU, #02 - 05, SINGAPORE 159053</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSTYPE</th> <td></td> </tr><tr bgcolor=\"\"> <th>DESCRIPTION</th> <td>Child Care Services</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>HYPERLINK</th> <td></td> </tr><tr bgcolor=\"\"> <th>LANDXADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>LANDYADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"\"> <th>NAME</th> <td>AWWA LTD.</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>PHOTOURL</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSFLOORNUMBER</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>86B24416FB1663C6</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20200826094036</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSUNITNUMBER</th> <td></td> </tr></table></center>\n3                            <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSBLOCKHOUSENUMBER</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSBUILDINGNAME</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSPOSTALCODE</th> <td>556912</td> </tr><tr bgcolor=\"\"> <th>ADDRESSSTREETNAME</th> <td>22, LI HWAN VIEW, GOLDEN HILL ESTATE, SINGAPORE 556912</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSTYPE</th> <td></td> </tr><tr bgcolor=\"\"> <th>DESCRIPTION</th> <td>Child Care Services</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>HYPERLINK</th> <td></td> </tr><tr bgcolor=\"\"> <th>LANDXADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>LANDYADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"\"> <th>NAME</th> <td>BABIES BY-THE-PARK PTE. LTD.</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>PHOTOURL</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSFLOORNUMBER</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>F971CBBA973E1AE5</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20200826094036</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSUNITNUMBER</th> <td></td> </tr></table></center>\n4                     <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSBLOCKHOUSENUMBER</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSBUILDINGNAME</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSPOSTALCODE</th> <td>569139</td> </tr><tr bgcolor=\"\"> <th>ADDRESSSTREETNAME</th> <td>3, ANG MO KIO STREET 62, #01 - 36, LINK@AMK, SINGAPORE 569139</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSTYPE</th> <td></td> </tr><tr bgcolor=\"\"> <th>DESCRIPTION</th> <td>Child Care Services</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>HYPERLINK</th> <td></td> </tr><tr bgcolor=\"\"> <th>LANDXADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>LANDYADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"\"> <th>NAME</th> <td>Baby Elk Infant Care Pte Ltd</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>PHOTOURL</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSFLOORNUMBER</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>86A4F25D1C7C9D85</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20200826094036</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSUNITNUMBER</th> <td></td> </tr></table></center>\n5                                               <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSBLOCKHOUSENUMBER</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSBUILDINGNAME</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSPOSTALCODE</th> <td>467961</td> </tr><tr bgcolor=\"\"> <th>ADDRESSSTREETNAME</th> <td>22A, KEW DRIVE, SINGAPORE 467961</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSTYPE</th> <td></td> </tr><tr bgcolor=\"\"> <th>DESCRIPTION</th> <td>Child Care Services</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>HYPERLINK</th> <td></td> </tr><tr bgcolor=\"\"> <th>LANDXADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>LANDYADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"\"> <th>NAME</th> <td>BABYPLANET MONTESSORI PTE. LTD.</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>PHOTOURL</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSFLOORNUMBER</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>CFE3F056F8171C7B</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20200826094036</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSUNITNUMBER</th> <td></td> </tr></table></center>\n6                                           <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSBLOCKHOUSENUMBER</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSBUILDINGNAME</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSPOSTALCODE</th> <td>598523</td> </tr><tr bgcolor=\"\"> <th>ADDRESSSTREETNAME</th> <td>3 Jalan Kakatua, JURONG PARK, SINGAPORE 598523</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSTYPE</th> <td></td> </tr><tr bgcolor=\"\"> <th>DESCRIPTION</th> <td>Child Care Services</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>HYPERLINK</th> <td></td> </tr><tr bgcolor=\"\"> <th>LANDXADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>LANDYADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"\"> <th>NAME</th> <td>BAMBINI CHILDCARE LLP</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>PHOTOURL</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSFLOORNUMBER</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>2B4F0B285ED28C4A</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20200826094036</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSUNITNUMBER</th> <td></td> </tr></table></center>\n7                              <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSBLOCKHOUSENUMBER</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSBUILDINGNAME</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSPOSTALCODE</th> <td>160131</td> </tr><tr bgcolor=\"\"> <th>ADDRESSSTREETNAME</th> <td>131, JALAN BUKIT MERAH, #01 - 1591, SINGAPORE 160131</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSTYPE</th> <td></td> </tr><tr bgcolor=\"\"> <th>DESCRIPTION</th> <td>Child Care Services</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>HYPERLINK</th> <td></td> </tr><tr bgcolor=\"\"> <th>LANDXADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>LANDYADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"\"> <th>NAME</th> <td>BAMBINI MONTESSORI PTE. LTD.</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>PHOTOURL</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSFLOORNUMBER</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>F62A225197813BBD</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20200826094036</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSUNITNUMBER</th> <td></td> </tr></table></center>\n8                        <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSBLOCKHOUSENUMBER</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSBUILDINGNAME</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSPOSTALCODE</th> <td>543319</td> </tr><tr bgcolor=\"\"> <th>ADDRESSSTREETNAME</th> <td>319C, ANCHORVALE DRIVE, #01 - 66, SINGAPORE 543319</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSTYPE</th> <td></td> </tr><tr bgcolor=\"\"> <th>DESCRIPTION</th> <td>Child Care Services</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>HYPERLINK</th> <td></td> </tr><tr bgcolor=\"\"> <th>LANDXADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>LANDYADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"\"> <th>NAME</th> <td>BERRY TREE PRESCHOOL PRIVATE LIMITED</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>PHOTOURL</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSFLOORNUMBER</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>AE242159867D5EB2</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20200826094036</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSUNITNUMBER</th> <td></td> </tr></table></center>\n9  <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSBLOCKHOUSENUMBER</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSBUILDINGNAME</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSPOSTALCODE</th> <td>750511</td> </tr><tr bgcolor=\"\"> <th>ADDRESSSTREETNAME</th> <td>511, CANBERRA ROAD, #03 - 02, SEMBAWANG MART, SINGAPORE 750511</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSTYPE</th> <td></td> </tr><tr bgcolor=\"\"> <th>DESCRIPTION</th> <td>Child Care Services</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>HYPERLINK</th> <td></td> </tr><tr bgcolor=\"\"> <th>LANDXADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>LANDYADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"\"> <th>NAME</th> <td>BERRY TREE PRESCHOOL@SEMBAWANG PRIVATE LIMITED</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>PHOTOURL</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSFLOORNUMBER</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>C1456F97A17ED64A</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20200826094036</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSUNITNUMBER</th> <td></td> </tr></table></center>\n10                    <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSBLOCKHOUSENUMBER</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSBUILDINGNAME</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSPOSTALCODE</th> <td>823195</td> </tr><tr bgcolor=\"\"> <th>ADDRESSSTREETNAME</th> <td>195C, PUNGGOL ROAD, #01 - 532, THE PERIWINKLE, SINGAPORE 823195</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSTYPE</th> <td></td> </tr><tr bgcolor=\"\"> <th>DESCRIPTION</th> <td>Child Care Services</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>HYPERLINK</th> <td></td> </tr><tr bgcolor=\"\"> <th>LANDXADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>LANDYADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"\"> <th>NAME</th> <td>BERRY TREE@PUNGGOL PTE LTD</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>PHOTOURL</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSFLOORNUMBER</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>4F6A8FCA467C3437</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20200826094036</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSUNITNUMBER</th> <td></td> </tr></table></center>\n                        geometry\n1   POINT Z (27976.73 45716.7 0)\n2     POINT Z (25824 29900.09 0)\n3  POINT Z (31399.04 37416.36 0)\n4   POINT Z (29268.43 40942.1 0)\n5  POINT Z (41217.74 33554.94 0)\n6  POINT Z (20644.07 36118.78 0)\n7  POINT Z (27427.95 29182.36 0)\n8  POINT Z (34378.47 41423.03 0)\n9  POINT Z (26467.04 48384.34 0)\n10 POINT Z (36173.81 42550.33 0)\n\n\n\ntm_shape(sg_sf)+\n  tm_polygons() +\ntm_shape(mpsz_sf) +\n  tm_polygons() +\ntm_shape(childcare_sf) +\n  tm_dots() +\ntmap_options(check.and.fix = TRUE)\n\nWarning: The shape sg_sf is invalid. See sf::st_is_valid\n\n\nWarning: The shape mpsz_sf is invalid. See sf::st_is_valid\n\n\n\n\n\nHere, we do not see any anomalies, all the geospatial points are within the map’s context, which means that the reference system and coordinate values are referred to the similar spatial context.\nWe can also prepare a pin map (interactive) by using the code below\n\ntmap_mode('view') +\ntm_shape(childcare_sf) +\n  tm_dots(alph = 0.5, size = 0.01) +\n  tm_view(set.zoom.limits = c(11, 14))\n\ntmap mode set to interactive viewing\n\n\n\n\n\n\n\nFrom the interactive map above, we can see that tmap is ustilising the leaflet for R API, which allows us to interact, navigate, zoom and query each simple feature. Changing the background of the map is also possible.\nBy using alph = 0.5 it allows us to plot the dots. The setting will allow for dots to be translucent so that we can tell if\nAfter setting the tmap_mode() to view we need to remember to switch it back to plot."
  },
  {
    "objectID": "exercises/icex04.html#converting-sf-dataframes-to-sps-spatial-class",
    "href": "exercises/icex04.html#converting-sf-dataframes-to-sps-spatial-class",
    "title": "In-Class Exercise 4: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "3.1 Converting sf Dataframes to sp’s Spatial* Class",
    "text": "3.1 Converting sf Dataframes to sp’s Spatial* Class\nWhile simple feature data frame is gaining in popularity, many geospatial analysis packages still require the input geospatial data in sp’s Spatial* classes. We will convert the sf data frames to sp’s Spatial* Class below.\n\nchildcare <- as_Spatial(childcare_sf)\nmpsz <- as_Spatial(mpsz_sf)\nsg <- as_Spatial(sg_sf)\n\nNow, let’s view the information of the Spatial* classes below:\n\nchildcare\n\nclass       : SpatialPointsDataFrame \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 2\nnames       :    Name,                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Description \nmin values  :   kml_1, <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSBLOCKHOUSENUMBER</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSBUILDINGNAME</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSPOSTALCODE</th> <td>018989</td> </tr><tr bgcolor=\"\"> <th>ADDRESSSTREETNAME</th> <td>1, MARINA BOULEVARD, #B1 - 01, ONE MARINA BOULEVARD, SINGAPORE 018989</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSTYPE</th> <td></td> </tr><tr bgcolor=\"\"> <th>DESCRIPTION</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>HYPERLINK</th> <td></td> </tr><tr bgcolor=\"\"> <th>LANDXADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>LANDYADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"\"> <th>NAME</th> <td>THE LITTLE SKOOL-HOUSE INTERNATIONAL PTE. LTD.</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>PHOTOURL</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSFLOORNUMBER</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>08F73931F4A691F4</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20200826094036</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSUNITNUMBER</th> <td></td> </tr></table></center> \nmax values  : kml_999,                  <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSBLOCKHOUSENUMBER</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSBUILDINGNAME</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSPOSTALCODE</th> <td>829646</td> </tr><tr bgcolor=\"\"> <th>ADDRESSSTREETNAME</th> <td>200, PONGGOL SEVENTEENTH AVENUE, SINGAPORE 829646</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSTYPE</th> <td></td> </tr><tr bgcolor=\"\"> <th>DESCRIPTION</th> <td>Child Care Services</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>HYPERLINK</th> <td></td> </tr><tr bgcolor=\"\"> <th>LANDXADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>LANDYADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"\"> <th>NAME</th> <td>RAFFLES KIDZ @ PUNGGOL PTE LTD</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>PHOTOURL</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSFLOORNUMBER</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>379D017BF244B0FA</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20200826094036</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSUNITNUMBER</th> <td></td> </tr></table></center> \n\n\n\nmpsz\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 323 \nextent      : 2667.538, 56396.44, 15748.72, 50256.33  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 15\nnames       : OBJECTID, SUBZONE_NO, SUBZONE_N, SUBZONE_C, CA_IND, PLN_AREA_N, PLN_AREA_C,       REGION_N, REGION_C,          INC_CRC, FMEL_UPD_D,     X_ADDR,     Y_ADDR,    SHAPE_Leng,    SHAPE_Area \nmin values  :        1,          1, ADMIRALTY,    AMSZ01,      N, ANG MO KIO,         AM, CENTRAL REGION,       CR, 00F5E30B5C9B7AD8,      16409,  5092.8949,  19579.069, 871.554887798, 39437.9352703 \nmax values  :      323,         17,    YUNNAN,    YSSZ09,      Y,     YISHUN,         YS,    WEST REGION,       WR, FFCCF172717C2EAF,      16409, 50424.7923, 49552.7904, 68083.9364708,  69748298.792 \n\n\n\nsg\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 4\nnames       : GDO_GID, MSLINK, MAPID,              COSTAL_NAM \nmin values  :       1,      1,     0,             ISLAND LINK \nmax values  :      60,     67,     0, SINGAPORE - MAIN ISLAND \n\n\nNow, they have been correctly converted into sp’s Spatial* classes."
  },
  {
    "objectID": "exercises/icex04.html#converting-the-spatial-class-into-generic-sp-format",
    "href": "exercises/icex04.html#converting-the-spatial-class-into-generic-sp-format",
    "title": "In-Class Exercise 4: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "3.2 Converting the Spatial* Class into Generic sp Format",
    "text": "3.2 Converting the Spatial* Class into Generic sp Format\nspstat requires the analytical data to be in ppp object form. As there is no direct method to convert Spatial* classes to ppp object, we need to convert the Spatial* classes into an intermediate Spatial object first.\nThecode below converts Spatial* Classes into generic sp objects\n\nchildcare_sp <- as(childcare, \"SpatialPoints\")\nsg_sp <- as(sg, \"SpatialPolygons\")\n\nNext, we can check the sp object properties.\n\nchildcare_sp\n\nclass       : SpatialPoints \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \n\n\n\nsg_sp\n\nclass       : SpatialPolygons \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \n\n\nComparing the sp object and Spatial* Classes, the variables, names, min and max values are omitted from the sp object but present in Spatial* Classes."
  },
  {
    "objectID": "exercises/icex04.html#converting-the-generic-sp-format-into-spatstats-ppp-format",
    "href": "exercises/icex04.html#converting-the-generic-sp-format-into-spatstats-ppp-format",
    "title": "In-Class Exercise 4: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "3.3 Converting the Generic sp Format into spatstat’s ppp Format",
    "text": "3.3 Converting the Generic sp Format into spatstat’s ppp Format\nNow, we will use as.ppp() function of spatstat to convert the spatial data into spatstat’s ppp object format.\n\nchildcare_ppp <- as(childcare_sp, \"ppp\")\nchildcare_ppp\n\nPlanar point pattern: 1545 points\nwindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n\n\nNow, let us plot childcare_ppp and examine the difference\n\nplot(childcare_ppp)\n\n\n\n\nWe can take a quick look at the summary statistics of the newly created ppp object by using the code below:\n\nsummary(childcare_ppp)\n\nPlanar point pattern:  1545 points\nAverage intensity 1.91145e-06 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 3 decimal places\ni.e. rounded to the nearest multiple of 0.001 units\n\nWindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n                    (34200 x 23630 units)\nWindow area = 808287000 square units\n\n\nNote the warning message about duplicates. The statistical methodology used for spatial points pattern processes is based largely on the assumption that processes are simple, that means that the points cannot be coincident."
  },
  {
    "objectID": "exercises/icex04.html#handling-duplicated-points",
    "href": "exercises/icex04.html#handling-duplicated-points",
    "title": "In-Class Exercise 4: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "3.4 Handling duplicated points",
    "text": "3.4 Handling duplicated points\nWe can check the duplication in a ppp object using the code below\n\nany(duplicated(childcare_ppp))\n\n[1] TRUE\n\n\nTo count the number of coincident points, we can use the multiplicity() function as shown in the code chunk below.\n\nmultiplicity(childcare_ppp)\n\n   1    2    3    4    5    6    7    8    9   10   11   12   13   14   15   16 \n   1    1    1    3    1    1    1    1    2    1    1    1    1    1    1    1 \n  17   18   19   20   21   22   23   24   25   26   27   28   29   30   31   32 \n   1    1    1    1    1    1    1    1    1    1    9    1    1    1    1    1 \n  33   34   35   36   37   38   39   40   41   42   43   44   45   46   47   48 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n  49   50   51   52   53   54   55   56   57   58   59   60   61   62   63   64 \n   1    1    1    1    1    1    2    1    1    3    1    1    1    1    1    1 \n  65   66   67   68   69   70   71   72   73   74   75   76   77   78   79   80 \n   1    1    1    1    1    2    1    1    1    1    1    2    1    1    1    1 \n  81   82   83   84   85   86   87   88   89   90   91   92   93   94   95   96 \n   1    1    1    3    1    1    1    1    1    1    1    1    1    1    1    1 \n  97   98   99  100  101  102  103  104  105  106  107  108  109  110  111  112 \n   1    1    1    1    1    1    1    1    2    1    1    1    1    1    1    1 \n 113  114  115  116  117  118  119  120  121  122  123  124  125  126  127  128 \n   1    1    1    1    1    1    2    1    1    1    3    1    1    1    2    1 \n 129  130  131  132  133  134  135  136  137  138  139  140  141  142  143  144 \n   1    1    1    1    1    2    1    1    1    1    1    1    1    1    3    2 \n 145  146  147  148  149  150  151  152  153  154  155  156  157  158  159  160 \n   1    2    1    1    1    2    2    3    1    5    1    5    1    1    1    2 \n 161  162  163  164  165  166  167  168  169  170  171  172  173  174  175  176 \n   1    1    1    1    2    1    1    1    1    1    1    2    1    1    1    1 \n 177  178  179  180  181  182  183  184  185  186  187  188  189  190  191  192 \n   1    4    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 193  194  195  196  197  198  199  200  201  202  203  204  205  206  207  208 \n   1    1    1    1    1    2    2    1    1    1    1    2    1    4    1    1 \n 209  210  211  212  213  214  215  216  217  218  219  220  221  222  223  224 \n   2    1    1    1    1    1    1    1    1    1    1    1    2    1    1    1 \n 225  226  227  228  229  230  231  232  233  234  235  236  237  238  239  240 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 241  242  243  244  245  246  247  248  249  250  251  252  253  254  255  256 \n   1    1    1    1    2    1    1    1    1    1    1    1    1    1    1    1 \n 257  258  259  260  261  262  263  264  265  266  267  268  269  270  271  272 \n   1    1    1    1    1    1    1    1    1    1    2    1    1    1    1    3 \n 273  274  275  276  277  278  279  280  281  282  283  284  285  286  287  288 \n   1    1    1    1    1    1    3    1    1    1    1    1    1    1    1    1 \n 289  290  291  292  293  294  295  296  297  298  299  300  301  302  303  304 \n   1    1    1    1    1    1    1    9    1    1    2    1    1    1    1    1 \n 305  306  307  308  309  310  311  312  313  314  315  316  317  318  319  320 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 321  322  323  324  325  326  327  328  329  330  331  332  333  334  335  336 \n   1    1    1    5    1    1    1    1    1    2    1    1    2    2    1    1 \n 337  338  339  340  341  342  343  344  345  346  347  348  349  350  351  352 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    2    2    1 \n 353  354  355  356  357  358  359  360  361  362  363  364  365  366  367  368 \n   1    1    1    1    9    1    1    1    1    1    1    1    1    1    1    1 \n 369  370  371  372  373  374  375  376  377  378  379  380  381  382  383  384 \n   1    3    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 385  386  387  388  389  390  391  392  393  394  395  396  397  398  399  400 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 401  402  403  404  405  406  407  408  409  410  411  412  413  414  415  416 \n   1    1    2    1    1    1    1    1    1    1    2    1    1    1    1    1 \n 417  418  419  420  421  422  423  424  425  426  427  428  429  430  431  432 \n   1    1    1    1    1    1    1    2    1    1    2    1    1    1    1    1 \n 433  434  435  436  437  438  439  440  441  442  443  444  445  446  447  448 \n   1    1    1    1    2    1    1    1    1    1    1    1    1    1    1    1 \n 449  450  451  452  453  454  455  456  457  458  459  460  461  462  463  464 \n   1    1    9    9    1    1    1    1    1    1    1    1    1    1    2    1 \n 465  466  467  468  469  470  471  472  473  474  475  476  477  478  479  480 \n   2    1    1    1    1    1    1    1    1    1    1    1    2    2    1    1 \n 481  482  483  484  485  486  487  488  489  490  491  492  493  494  495  496 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 497  498  499  500  501  502  503  504  505  506  507  508  509  510  511  512 \n   1    1    1    1    1    1    2    1    1    1    1    1    1    1    1    2 \n 513  514  515  516  517  518  519  520  521  522  523  524  525  526  527  528 \n   1    1    1    1    1    1    1    1    1    1    1    2    1    1    3    1 \n 529  530  531  532  533  534  535  536  537  538  539  540  541  542  543  544 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 545  546  547  548  549  550  551  552  553  554  555  556  557  558  559  560 \n   1    1    1    1    1    1    1    1    1    3    1    1    1    1    1    1 \n 561  562  563  564  565  566  567  568  569  570  571  572  573  574  575  576 \n   2    2    2    1    1    1    1    2    1    1    2    1    1    1    2    1 \n 577  578  579  580  581  582  583  584  585  586  587  588  589  590  591  592 \n   1    2    1    1    1    1    1    9    1    4    1    2    1    1    1    1 \n 593  594  595  596  597  598  599  600  601  602  603  604  605  606  607  608 \n   2    1    1    1    1    1    1    1    2    1    2    1    1    1    1    1 \n 609  610  611  612  613  614  615  616  617  618  619  620  621  622  623  624 \n   1    1    1    1    1    1    1    1    1    2    1    2    1    1    1    1 \n 625  626  627  628  629  630  631  632  633  634  635  636  637  638  639  640 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 641  642  643  644  645  646  647  648  649  650  651  652  653  654  655  656 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    4 \n 657  658  659  660  661  662  663  664  665  666  667  668  669  670  671  672 \n   1    1    1    1    1    1    1    3    1    1    1    1    1    1    1    1 \n 673  674  675  676  677  678  679  680  681  682  683  684  685  686  687  688 \n   1    1    1    1    1    4    1    1    1    1    1    4    1    1    1    1 \n 689  690  691  692  693  694  695  696  697  698  699  700  701  702  703  704 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 705  706  707  708  709  710  711  712  713  714  715  716  717  718  719  720 \n   1    1    2    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 721  722  723  724  725  726  727  728  729  730  731  732  733  734  735  736 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 737  738  739  740  741  742  743  744  745  746  747  748  749  750  751  752 \n   1    2    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 753  754  755  756  757  758  759  760  761  762  763  764  765  766  767  768 \n   1    1    1    1    1    2    1    1    1    1    1    1    1    1    1    1 \n 769  770  771  772  773  774  775  776  777  778  779  780  781  782  783  784 \n   1    1    1    1    1    1    1    1    1    4    1    1    1    1    1    1 \n 785  786  787  788  789  790  791  792  793  794  795  796  797  798  799  800 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 801  802  803  804  805  806  807  808  809  810  811  812  813  814  815  816 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 817  818  819  820  821  822  823  824  825  826  827  828  829  830  831  832 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 833  834  835  836  837  838  839  840  841  842  843  844  845  846  847  848 \n   1    1    1    1    1    1    1    2    1    1    1    1    1    1    1    1 \n 849  850  851  852  853  854  855  856  857  858  859  860  861  862  863  864 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 865  866  867  868  869  870  871  872  873  874  875  876  877  878  879  880 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    2 \n 881  882  883  884  885  886  887  888  889  890  891  892  893  894  895  896 \n   3    1    1    1    2    1    1    1    3    1    1    3    1    1    1    1 \n 897  898  899  900  901  902  903  904  905  906  907  908  909  910  911  912 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 913  914  915  916  917  918  919  920  921  922  923  924  925  926  927  928 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 929  930  931  932  933  934  935  936  937  938  939  940  941  942  943  944 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 945  946  947  948  949  950  951  952  953  954  955  956  957  958  959  960 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    2 \n 961  962  963  964  965  966  967  968  969  970  971  972  973  974  975  976 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 977  978  979  980  981  982  983  984  985  986  987  988  989  990  991  992 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 993  994  995  996  997  998  999 1000 1001 1002 1003 1004 1005 1006 1007 1008 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 \n   1    1    1    1    1    1    1    1    1    2    2    1    1    1    1    1 \n1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 \n   1    1    1    1    1    2    1    1    1    1    1    1    1    1    1    1 \n1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 \n   1    1    1    1    1    1    1    1    2    2    1    1    1    5    1    1 \n1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 \n   1    1    1    1    1    1    1    1    1    2    1    1    1    1    1    1 \n1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 \n   1    1    1    1    1    1    1    1    1    1    2    1    1    1    1    1 \n1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 \n   1    9    1    2    2    1    1    1    2    1    1    1    1    1    1    1 \n1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 \n   1    1    1    1    2    1    1    1    3    1    1    1    1    1    1    1 \n1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 \n   9    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 \n   1    1    1    2    1    1    1    1    1    1    1    1    1    1    1    1 \n1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    2 \n1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 \n   1    1    1    2    1    2    1    1    1    2    2    2    1    1    1    1 \n1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 \n   1    1    2    1    1    1    1    1    1    1    1    1    2    1    1    1 \n1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 \n   1    1    1    1    3    1    1    1    1    1    1    1    1    1    1    1 \n1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 \n   1    1    1    1    1    1    1    1    4    1    1    1    1    1    2    1 \n1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 \n   1    1    1    1    1    1    1    1    1    9    1    1    1    1    1    1 \n1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 1424 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1425 1426 1427 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    2    1 \n1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 \n   1    2    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1457 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 1471 1472 \n   1    1    1    1    1    1    1    1    1    1    2    1    1    1    1    1 \n1473 1474 1475 1476 1477 1478 1479 1480 1481 1482 1483 1484 1485 1486 1487 1488 \n   1    1    1    1    1    1    2    1    1    1    1    1    1    1    1    1 \n1489 1490 1491 1492 1493 1494 1495 1496 1497 1498 1499 1500 1501 1502 1503 1504 \n   1    1    1    1    1    1    1    1    1    1    5    1    1    1    1    1 \n1505 1506 1507 1508 1509 1510 1511 1512 1513 1514 1515 1516 1517 1518 1519 1520 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1521 1522 1523 1524 1525 1526 1527 1528 1529 1530 1531 1532 1533 1534 1535 1536 \n   1    1    1    1    1    2    1    1    1    1    2    1    1    1    1    3 \n1537 1538 1539 1540 1541 1542 1543 1544 1545 \n   1    1    1    1    1    1    2    1    1 \n\n\nIf we want to know how many locations have more than one point event, we can use the code chunk below.\n\nsum(multiplicity(childcare_ppp) > 1)\n\n[1] 128\n\n\nThe output shows that there are 128 duplicated point events.\nTo view the locations of the duplicated point events, we can plot the childcare dataset by using the code chunk below.\n\ntmap_mode('view')\n\ntmap mode set to interactive viewing\n\ntm_shape(childcare) +\n  tm_dots(alpha = 0.4,\n          size = 0.05)\n\n\n\n\n\n\n\ntmap_mode('plot')\n\ntmap mode set to plotting\n\n\nFrom the interactive map above, you can see that the duplicated points have points that are darker in color, as the transparency of 1 point has been set to an alpha of 0.4, two overlapping points will make it more opaque.\nThere are a few ways to overcome this problem:\n\nDelete the duplicates. However, some useful point events will be lost\njittering. Adds small perturrbations to duplicate points so that they do not occupy the same exact space\nMake each point “unique” and then attach duplicates of points to the patterns as marks, as attributes of the points. Then we can use analytical techniques that take into account the marks.\n\nWe use the second approach, jittering to manipulate the points below\n\nchildcare_ppp_jit <- rjitter(childcare_ppp,\n                             retry = TRUE,\n                             nsim = 1,\n                             drop = TRUE)\n\nNow, let’s check the if there are still any duplicated points below\n\nany(duplicated(childcare_ppp_jit))\n\n[1] FALSE"
  },
  {
    "objectID": "exercises/icex04.html#creating-owin-object",
    "href": "exercises/icex04.html#creating-owin-object",
    "title": "In-Class Exercise 4: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "3.5 Creating owin object",
    "text": "3.5 Creating owin object\nWhen analysing spatial point patterns, it is good practice to confine the analysis with a geographical area like Singapore boundary. In spatstat, an object called owin is specially designed to represent this polygonal region.\nThe code cunk below is used to convert the sg SpatialPolygon object into owin object of spatstat.\n\nsg_owin <- as(sg_sp, \"owin\")\n\nThe output object can be displayed by using plot() function.\n\nplot(sg_owin)\n\n\n\n\nand summary() function of Base R.\n\nsummary(sg_owin)\n\nWindow: polygonal boundary\n60 separate polygons (no holes)\n            vertices        area relative.area\npolygon 1         38 1.56140e+04      2.09e-05\npolygon 2        735 4.69093e+06      6.27e-03\npolygon 3         49 1.66986e+04      2.23e-05\npolygon 4         76 3.12332e+05      4.17e-04\npolygon 5       5141 6.36179e+08      8.50e-01\npolygon 6         42 5.58317e+04      7.46e-05\npolygon 7         67 1.31354e+06      1.75e-03\npolygon 8         15 4.46420e+03      5.96e-06\npolygon 9         14 5.46674e+03      7.30e-06\npolygon 10        37 5.26194e+03      7.03e-06\npolygon 11        53 3.44003e+04      4.59e-05\npolygon 12        74 5.82234e+04      7.78e-05\npolygon 13        69 5.63134e+04      7.52e-05\npolygon 14       143 1.45139e+05      1.94e-04\npolygon 15       165 3.38736e+05      4.52e-04\npolygon 16       130 9.40465e+04      1.26e-04\npolygon 17        19 1.80977e+03      2.42e-06\npolygon 18        16 2.01046e+03      2.69e-06\npolygon 19        93 4.30642e+05      5.75e-04\npolygon 20        90 4.15092e+05      5.54e-04\npolygon 21       721 1.92795e+06      2.57e-03\npolygon 22       330 1.11896e+06      1.49e-03\npolygon 23       115 9.28394e+05      1.24e-03\npolygon 24        37 1.01705e+04      1.36e-05\npolygon 25        25 1.66227e+04      2.22e-05\npolygon 26        10 2.14507e+03      2.86e-06\npolygon 27       190 2.02489e+05      2.70e-04\npolygon 28       175 9.25904e+05      1.24e-03\npolygon 29      1993 9.99217e+06      1.33e-02\npolygon 30        38 2.42492e+04      3.24e-05\npolygon 31        24 6.35239e+03      8.48e-06\npolygon 32        53 6.35791e+05      8.49e-04\npolygon 33        41 1.60161e+04      2.14e-05\npolygon 34        22 2.54368e+03      3.40e-06\npolygon 35        30 1.08382e+04      1.45e-05\npolygon 36       327 2.16921e+06      2.90e-03\npolygon 37       111 6.62927e+05      8.85e-04\npolygon 38        90 1.15991e+05      1.55e-04\npolygon 39        98 6.26829e+04      8.37e-05\npolygon 40       415 3.25384e+06      4.35e-03\npolygon 41       222 1.51142e+06      2.02e-03\npolygon 42       107 6.33039e+05      8.45e-04\npolygon 43         7 2.48299e+03      3.32e-06\npolygon 44        17 3.28303e+04      4.38e-05\npolygon 45        26 8.34758e+03      1.11e-05\npolygon 46       177 4.67446e+05      6.24e-04\npolygon 47        16 3.19460e+03      4.27e-06\npolygon 48        15 4.87296e+03      6.51e-06\npolygon 49        66 1.61841e+04      2.16e-05\npolygon 50       149 5.63430e+06      7.53e-03\npolygon 51       609 2.62570e+07      3.51e-02\npolygon 52         8 7.82256e+03      1.04e-05\npolygon 53       976 2.33447e+07      3.12e-02\npolygon 54        55 8.25379e+04      1.10e-04\npolygon 55       976 2.33447e+07      3.12e-02\npolygon 56        61 3.33449e+05      4.45e-04\npolygon 57         6 1.68410e+04      2.25e-05\npolygon 58         4 9.45963e+03      1.26e-05\npolygon 59        46 6.99702e+05      9.35e-04\npolygon 60        13 7.00873e+04      9.36e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 748741000 square units\nFraction of frame area: 0.414"
  },
  {
    "objectID": "exercises/icex04.html#combining-point-events-object-and-owin-object",
    "href": "exercises/icex04.html#combining-point-events-object-and-owin-object",
    "title": "In-Class Exercise 4: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "3.6 Combining Point Events Object and owin Object",
    "text": "3.6 Combining Point Events Object and owin Object\nIn this last step of geospatial data wrangling, we will extract childcare events that are located within Singapore using the code below\n\nchildcareSG_ppp = childcare_ppp[sg_owin]\n\nThe output object combined both the point and polygon feature in one ppp object class as shown below.\n\nsummary(childcareSG_ppp)\n\nPlanar point pattern:  1545 points\nAverage intensity 2.063463e-06 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 3 decimal places\ni.e. rounded to the nearest multiple of 0.001 units\n\nWindow: polygonal boundary\n60 separate polygons (no holes)\n            vertices        area relative.area\npolygon 1         38 1.56140e+04      2.09e-05\npolygon 2        735 4.69093e+06      6.27e-03\npolygon 3         49 1.66986e+04      2.23e-05\npolygon 4         76 3.12332e+05      4.17e-04\npolygon 5       5141 6.36179e+08      8.50e-01\npolygon 6         42 5.58317e+04      7.46e-05\npolygon 7         67 1.31354e+06      1.75e-03\npolygon 8         15 4.46420e+03      5.96e-06\npolygon 9         14 5.46674e+03      7.30e-06\npolygon 10        37 5.26194e+03      7.03e-06\npolygon 11        53 3.44003e+04      4.59e-05\npolygon 12        74 5.82234e+04      7.78e-05\npolygon 13        69 5.63134e+04      7.52e-05\npolygon 14       143 1.45139e+05      1.94e-04\npolygon 15       165 3.38736e+05      4.52e-04\npolygon 16       130 9.40465e+04      1.26e-04\npolygon 17        19 1.80977e+03      2.42e-06\npolygon 18        16 2.01046e+03      2.69e-06\npolygon 19        93 4.30642e+05      5.75e-04\npolygon 20        90 4.15092e+05      5.54e-04\npolygon 21       721 1.92795e+06      2.57e-03\npolygon 22       330 1.11896e+06      1.49e-03\npolygon 23       115 9.28394e+05      1.24e-03\npolygon 24        37 1.01705e+04      1.36e-05\npolygon 25        25 1.66227e+04      2.22e-05\npolygon 26        10 2.14507e+03      2.86e-06\npolygon 27       190 2.02489e+05      2.70e-04\npolygon 28       175 9.25904e+05      1.24e-03\npolygon 29      1993 9.99217e+06      1.33e-02\npolygon 30        38 2.42492e+04      3.24e-05\npolygon 31        24 6.35239e+03      8.48e-06\npolygon 32        53 6.35791e+05      8.49e-04\npolygon 33        41 1.60161e+04      2.14e-05\npolygon 34        22 2.54368e+03      3.40e-06\npolygon 35        30 1.08382e+04      1.45e-05\npolygon 36       327 2.16921e+06      2.90e-03\npolygon 37       111 6.62927e+05      8.85e-04\npolygon 38        90 1.15991e+05      1.55e-04\npolygon 39        98 6.26829e+04      8.37e-05\npolygon 40       415 3.25384e+06      4.35e-03\npolygon 41       222 1.51142e+06      2.02e-03\npolygon 42       107 6.33039e+05      8.45e-04\npolygon 43         7 2.48299e+03      3.32e-06\npolygon 44        17 3.28303e+04      4.38e-05\npolygon 45        26 8.34758e+03      1.11e-05\npolygon 46       177 4.67446e+05      6.24e-04\npolygon 47        16 3.19460e+03      4.27e-06\npolygon 48        15 4.87296e+03      6.51e-06\npolygon 49        66 1.61841e+04      2.16e-05\npolygon 50       149 5.63430e+06      7.53e-03\npolygon 51       609 2.62570e+07      3.51e-02\npolygon 52         8 7.82256e+03      1.04e-05\npolygon 53       976 2.33447e+07      3.12e-02\npolygon 54        55 8.25379e+04      1.10e-04\npolygon 55       976 2.33447e+07      3.12e-02\npolygon 56        61 3.33449e+05      4.45e-04\npolygon 57         6 1.68410e+04      2.25e-05\npolygon 58         4 9.45963e+03      1.26e-05\npolygon 59        46 6.99702e+05      9.35e-04\npolygon 60        13 7.00873e+04      9.36e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 748741000 square units\nFraction of frame area: 0.414\n\n\n\nplot(childcareSG_ppp)\n\n\n\n\n\n3.6.1 Extracting Study Areas\nThe code below will help us to extract the target planning areas\n\npg = mpsz[mpsz@data$PLN_AREA_N == \"PUNGGOL\",]\ntm = mpsz[mpsz@data$PLN_AREA_N == \"TAMPINES\",]\nck = mpsz[mpsz@data$PLN_AREA_N == \"CHOA CHU KANG\",]\njw = mpsz[mpsz@data$PLN_AREA_N == \"JURONG WEST\",]\n\nPlotting target planning areas\n\npar(mfrow=c(2,2))\nplot(pg, main = \"Punggol\")\nplot(tm, main = \"Tampines\")\nplot(ck, main = \"Choa Chu Kang\")\nplot(jw, main = \"Jurong West\")\n\n\n\n\n\n\n3.6.2 Converting the Spatial Point Data Frame into Generic sp Format\n\npg_sp = as(pg, \"SpatialPolygons\")\ntm_sp = as(tm, \"SpatialPolygons\")\nck_sp = as(ck, \"SpatialPolygons\")\njw_sp = as(jw, \"SpatialPolygons\")\n\n\n\n3.6.3 Creating owin Object\n\npg_owin = as(pg_sp, \"owin\")\ntm_owin = as(tm_sp, \"owin\")\nck_owin = as(ck_sp, \"owin\")\njw_owin = as(jw_sp, \"owin\")\n\n\n\n3.6.4 Combining Childcare Points and the Study Area\nBy using the code chunk below, we are able to extract childcare that is within the specific region to do our analysis later on.\n\nchildcare_pg_ppp = childcare_ppp_jit[pg_owin]\nchildcare_tm_ppp = childcare_ppp_jit[tm_owin]\nchildcare_ck_ppp = childcare_ppp_jit[ck_owin]\nchildcare_jw_ppp = childcare_ppp_jit[jw_owin]\n\nWe use rescale() to transform the units of measurement from metre to kilometre\n\nchildcare_pg_ppp.km = rescale(childcare_pg_ppp, 1000, \"km\")\nchildcare_tm_ppp.km = rescale(childcare_tm_ppp, 1000, \"km\")\nchildcare_ck_ppp.km = rescale(childcare_ck_ppp, 1000, \"km\")\nchildcare_jw_ppp.km = rescale(childcare_jw_ppp, 1000, \"km\")\n\nNow, we will plot the four study areas and locations of childcare centres\n\npar(mfrow=c(2,2))\nplot(childcare_pg_ppp.km, main=\"Punggol\")\nplot(childcare_tm_ppp.km, main=\"Tampines\")\nplot(childcare_ck_ppp.km, main=\"Choa Chu Kang\")\nplot(childcare_jw_ppp.km, main=\"Jurong West\")"
  },
  {
    "objectID": "exercises/icex04.html#analysing-spatial-point-process-using-g-function",
    "href": "exercises/icex04.html#analysing-spatial-point-process-using-g-function",
    "title": "In-Class Exercise 4: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "4.1 Analysing Spatial Point Process Using G-Function",
    "text": "4.1 Analysing Spatial Point Process Using G-Function\nThe G function measures the distribution of distances from an arbitary event to its nearest event. Here, we will use G-function estimation (Gest()) and Monte Carlo simulation test (envelope()) to perform the analysis.\n\n4.1.1 Choa Chu Kang Planning Area\n\n4.1.1.1 Computing G-Function Estimation\nThe code below is used to compute G-function using Gest() of spatstat package.\n\nG_CK = Gest(childcare_ck_ppp, correction = \"border\")\nplot(G_CK, xlim=c(0,500))\n\n\n\n\n\n\n4.1.1.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, we will conduct a hypothesis test. The hypothesis and test are shown below:\n\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\n\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nMonte Carlo test with G-function:\n\nG_CK.csr <- envelope(childcare_ck_ppp, Gest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60........\n.70.........80.........90.........100.........110.........120.........130......\n...140.........150.........160.........170.........180.........190.........200....\n.....210.........220.........230.........240.........250.........260.........270..\n.......280.........290.........300.........310.........320.........330.........340\n.........350.........360.........370.........380.........390.........400........\n.410.........420.........430.........440.........450.........460.........470......\n...480.........490.........500.........510.........520.........530.........540....\n.....550.........560.........570.........580.........590.........600.........610..\n.......620.........630.........640.........650.........660.........670.........680\n.........690.........700.........710.........720.........730.........740........\n.750.........760.........770.........780.........790.........800.........810......\n...820.........830.........840.........850.........860.........870.........880....\n.....890.........900.........910.........920.........930.........940.........950..\n.......960.........970.........980.........990........ 999.\n\nDone.\n\n\n\nplot(G_CK.csr)\n\n\n\n\n\n\n\n4.1.2 Tampines Planning Area\n\n4.1.2.1 Computing G-function estimation\n\nG_tm = Gest(childcare_tm_ppp, correction = \"best\")\nplot(G_tm)\n\n\n\n\n\n\n4.1.2.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, we will conduct a hypothesis test. The hypothesis and test are shown below:\n\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\n\nThe null hypothesis will be rejected is p-value is smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing.\n\nG_tm.csr <- envelope(childcare_tm_ppp, Gest, correction = \"all\", nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60........\n.70.........80.........90.........100.........110.........120.........130......\n...140.........150.........160.........170.........180.........190.........200....\n.....210.........220.........230.........240.........250.........260.........270..\n.......280.........290.........300.........310.........320.........330.........340\n.........350.........360.........370.........380.........390.........400........\n.410.........420.........430.........440.........450.........460.........470......\n...480.........490.........500.........510.........520.........530.........540....\n.....550.........560.........570.........580.........590.........600.........610..\n.......620.........630.........640.........650.........660.........670.........680\n.........690.........700.........710.........720.........730.........740........\n.750.........760.........770.........780.........790.........800.........810......\n...820.........830.........840.........850.........860.........870.........880....\n.....890.........900.........910.........920.........930.........940.........950..\n.......960.........970.........980.........990........ 999.\n\nDone.\n\n\n\nplot(G_tm.csr)"
  },
  {
    "objectID": "exercises/icex04.html#analysing-spatial-point-process-using-f-function",
    "href": "exercises/icex04.html#analysing-spatial-point-process-using-f-function",
    "title": "In-Class Exercise 4: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "4.2 Analysing Spatial Point Process Using F-Function",
    "text": "4.2 Analysing Spatial Point Process Using F-Function\n\n4.2.1 Choa Chu Kang planning area\n\n4.2.1.1 Computing F-function estimation\nThe code below is used to compute F-function using Fest() of spatstat package.\n\nF_CK = Fest(childcare_ck_ppp)\nplot(F_CK)\n\n\n\n\n\n\n4.2.1.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, we will conduct a hypothesis test. The hypothesis and test are shown below:\n\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\n\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nMonte Carlo test with G-function:\n\nF_CK.csr <- envelope(childcare_ck_ppp, Fest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60........\n.70.........80.........90.........100.........110.........120.........130......\n...140.........150.........160.........170.........180.........190.........200....\n.....210.........220.........230.........240.........250.........260.........270..\n.......280.........290.........300.........310.........320.........330.........340\n.........350.........360.........370.........380.........390.........400........\n.410.........420.........430.........440.........450.........460.........470......\n...480.........490.........500.........510.........520.........530.........540....\n.....550.........560.........570.........580.........590.........600.........610..\n.......620.........630.........640.........650.........660.........670.........680\n.........690.........700.........710.........720.........730.........740........\n.750.........760.........770.........780.........790.........800.........810......\n...820.........830.........840.........850.........860.........870.........880....\n.....890.........900.........910.........920.........930.........940.........950..\n.......960.........970.........980.........990........ 999.\n\nDone.\n\n\n\nplot(F_CK.csr)\n\n\n\n\n\n\n\n4.2.2 Tampines Planning Area\n\n4.2.2.1 Computing K-function estimation\n\nK_tm = Kest(childcare_tm_ppp, correction = \"Ripley\")\nplot(K_tm, . -r ~ r, \n     ylab= \"K(d)-r\", xlab = \"d(m)\", \n     xlim=c(0,1000))\n\n\n\n\n\n\n4.2.2.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, we will conduct a hypothesis test. The hypothesis and test are shown below:\n\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\n\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing.\n\nK_tm.csr <- envelope(childcare_tm_ppp, Kest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98,  99.\n\nDone.\n\n\n\nplot(K_tm.csr, . - r ~ r, \n     xlab=\"d\", ylab=\"K(d)-r\", xlim=c(0,500))"
  },
  {
    "objectID": "exercises/icex04.html#analysing-spatial-point-process-using-l-function",
    "href": "exercises/icex04.html#analysing-spatial-point-process-using-l-function",
    "title": "In-Class Exercise 4: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "4.3 Analysing Spatial Point Process Using L-Function",
    "text": "4.3 Analysing Spatial Point Process Using L-Function\nIn this section, we will use Lest() of spatstat to compute L Function estimation and also perform Monte Carlo simulation test using envelope() of spatstat.\n\n4.3.1 Choa Chu Kang planning area\n\n4.3.1.1 Computing L Function Estimation\n\nL_ck = Lest(childcare_ck_ppp, correction = \"Ripley\")\nplot(L_ck, . -r ~ r, \n     ylab= \"L(d)-r\", xlab = \"d(m)\")\n\n\n\n\n\n\n4.3.1.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, we will conduct a hypothesis test. The hypothesis and test are shown below:\n\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\n\nThe null hypothesis will be rejected if p-value if smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing.\n\nL_ck.csr <- envelope(childcare_ck_ppp, Lest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98,  99.\n\nDone.\n\n\n\nplot(L_ck.csr, . - r ~ r, xlab=\"d\", ylab=\"L(d)-r\")\n\n\n\n\n\n\n\n4.3.2 Tampines Planning Area\n\n4.3.2.1 Computing L Function Estimate\n\nL_tm = Lest(childcare_tm_ppp, correction = \"Ripley\")\nplot(L_tm, . -r ~ r, \n     ylab= \"L(d)-r\", xlab = \"d(m)\", \n     xlim=c(0,1000))\n\n\n\n\n\n\n4.3.2.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, we will conduct a hypothesis test. The hypothesis and test are shown below:\n\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\n\nThe null hypothesis will be rejected if p-value if smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing.\n\nL_tm.csr <- envelope(childcare_tm_ppp, Lest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98,  99.\n\nDone.\n\n\nWe can plot the model using the code below:\n\nplot(L_tm.csr, . - r ~ r, \n     xlab=\"d\", ylab=\"L(d)-r\", xlim=c(0,500))"
  },
  {
    "objectID": "exercises/icex05.html",
    "href": "exercises/icex05.html",
    "title": "In-Class Exercise 5: Local Colocation Quotients",
    "section": "",
    "text": "Firstly, the code below will check if pacman has been installed. If it has not been installed, R will download and install it, before activating it for use during this session.\n\nif (!require('pacman', character.only = T)){\n  install.packages('pacman')\n}\n\nLoading required package: pacman\n\nlibrary('pacman')\n\nNext, pacman assists us by helping us load R packages that we require, sf, tidyverse and tmap.\n\npacman::p_load(tidyverse, tmap, sf, sfdep)\n\n\n\n\n\nstudyArea <- st_read(dsn = \"In-Class_Ex05/data\", layer = \"study_area\") %>%\n  st_transform(crs = 3829)\n\nReading layer `study_area' from data source \n  `C:\\renjie-teo\\IS415-GAA\\exercises\\In-Class_Ex05\\data' using driver `ESRI Shapefile'\nSimple feature collection with 7 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 121.4836 ymin: 25.00776 xmax: 121.592 ymax: 25.09288\nGeodetic CRS:  TWD97\n\n\n\nstores <- st_read(dsn = \"In-Class_Ex05/data\", layer = \"stores\") %>%\n  st_transform(crs = 3829)\n\nReading layer `stores' from data source \n  `C:\\renjie-teo\\IS415-GAA\\exercises\\In-Class_Ex05\\data' using driver `ESRI Shapefile'\nSimple feature collection with 1409 features and 4 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 121.4902 ymin: 25.01257 xmax: 121.5874 ymax: 25.08557\nGeodetic CRS:  TWD97\n\n\n\n\n\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\ntm_shape(studyArea) +\n  tm_polygons() +\ntm_shape(stores) +\n  tm_dots(col = \"Name\",\n          size = 0.01,\n          border.col = \"black\",\n          border.lwd = 0.5) +\ntm_view(set.zoom.limits = c(12,16))\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe polygon layers should always be above the dots. The geospatial layers are rendered in sequence, hence if polygons are rendered after the dots (ie. dots are ontop of the polygon code), the dots might be coverd by the polygon line/fill."
  },
  {
    "objectID": "exercises/icex06.html",
    "href": "exercises/icex06.html",
    "title": "In-Class Exercise 6: Spatial Weights and Applications",
    "section": "",
    "text": "Pacman assists us by helping us load R packages that we require, sf, sfdep, tidyverse and tmap.\n\npacman::p_load(tidyverse, tmap, sf, sfdep)\n\n\n\n\nThe following datasets are used:\n\n\n\nDataset Name\nSource\n\n\n\n\nHunan (Hunan.shp)\nProf Kam\n\n\nHunan 2021 (Hunan-2021.csv)\nProf Kam"
  },
  {
    "objectID": "exercises/icex06.html#importing-spatial-data",
    "href": "exercises/icex06.html#importing-spatial-data",
    "title": "In-Class Exercise 6: Spatial Weights and Applications",
    "section": "2.1 Importing Spatial Data",
    "text": "2.1 Importing Spatial Data\nWe will use st_read() of sf package to import the three geospatial datasets.\n\nhunan <- st_read(dsn = \"In-Class_Ex06/data/geospatial\", layer = \"hunan\")\n\nReading layer `hunan' from data source \n  `C:\\renjie-teo\\IS415-GAA\\exercises\\In-Class_Ex06\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\nhunan_2012 <- read_csv(\"In-Class_Ex06/data/aspatial/Hunan_2012.csv\")\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "exercises/icex06.html#combining-both-data-frame-by-using-left-join",
    "href": "exercises/icex06.html#combining-both-data-frame-by-using-left-join",
    "title": "In-Class Exercise 6: Spatial Weights and Applications",
    "section": "2.2 Combining both data frame by using left join",
    "text": "2.2 Combining both data frame by using left join\n\nhunan_GDPPC <- left_join(hunan, hunan_2012) %>%\n  select(1:4, 7, 15)\n\nJoining with `by = join_by(County)`\n\n\nIf two columns have the same name, they will automatically be joined, else, the following code has to be specified after the dataframes to be joined. A == B"
  },
  {
    "objectID": "exercises/icex06.html#contiguity-neighbours-methods",
    "href": "exercises/icex06.html#contiguity-neighbours-methods",
    "title": "In-Class Exercise 6: Spatial Weights and Applications",
    "section": "4.1 Contiguity Neighbours Methods",
    "text": "4.1 Contiguity Neighbours Methods\n\n4.1.1 Queen’s Method\nIn the code chunk below st_contiguity() is used to derive a contiguity neighbour list by using Queen’s method.\n\nnb_queen <- hunan_GDPPC %>%\n  mutate(nb = st_contiguity(geometry),\n         .before = 1)\n\nThe code chunk below prints the neighbours found using the Queen’s method:\n\nsummary(nb_queen)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\n    nb          NAME_2               ID_3          NAME_3         \n NULL:NULL   Length:88          Min.   :21098   Length:88         \n             Class :character   1st Qu.:21125   Class :character  \n             Mode  :character   Median :21150   Mode  :character  \n                                Mean   :21150                     \n                                3rd Qu.:21174                     \n                                Max.   :21201                     \n  ENGTYPE_3            County              GDPPC                geometry \n Length:88          Length:88          Min.   : 8497   POLYGON      :88  \n Class :character   Class :character   1st Qu.:14566   epsg:4326    : 0  \n Mode  :character   Mode  :character   Median :20433   +proj=long...: 0  \n                                       Mean   :24405                     \n                                       3rd Qu.:27224                     \n                                       Max.   :88656                     \n\n\n\n\n4.1.2 Rook’s Method\n\nnb_rook <- hunan_GDPPC %>%\n  mutate(nb = st_contiguity(geometry, queen = FALSE),\n         .before = 1)\n\nThe code chunk below prints the neighbours found using the Rook’s method:\n\nsummary(nb_rook)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 440 \nPercentage nonzero weights: 5.681818 \nAverage number of links: 5 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 10 \n 2  2 12 20 21 14 11  3  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 10 links\n\n\n    nb          NAME_2               ID_3          NAME_3         \n NULL:NULL   Length:88          Min.   :21098   Length:88         \n             Class :character   1st Qu.:21125   Class :character  \n             Mode  :character   Median :21150   Mode  :character  \n                                Mean   :21150                     \n                                3rd Qu.:21174                     \n                                Max.   :21201                     \n  ENGTYPE_3            County              GDPPC                geometry \n Length:88          Length:88          Min.   : 8497   POLYGON      :88  \n Class :character   Class :character   1st Qu.:14566   epsg:4326    : 0  \n Mode  :character   Mode  :character   Median :20433   +proj=long...: 0  \n                                       Mean   :24405                     \n                                       3rd Qu.:27224                     \n                                       Max.   :88656"
  },
  {
    "objectID": "exercises/icex06.html#contiguity-weights-queens-method",
    "href": "exercises/icex06.html#contiguity-weights-queens-method",
    "title": "In-Class Exercise 6: Spatial Weights and Applications",
    "section": "5.1 Contiguity Weights: Queen’s Method",
    "text": "5.1 Contiguity Weights: Queen’s Method\n\nwm_q <- hunan_GDPPC %>%\n  mutate(nb = st_contiguity(geometry),\n         wt = st_weights(nb),\n         .before = 1)\n\n\nwm_q\n\nSimple feature collection with 88 features and 8 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\nFirst 10 features:\n                               nb\n1                 2, 3, 4, 57, 85\n2               1, 57, 58, 78, 85\n3                     1, 4, 5, 85\n4                      1, 3, 5, 6\n5                     3, 4, 6, 85\n6                4, 5, 69, 75, 85\n7                  67, 71, 74, 84\n8       9, 46, 47, 56, 78, 80, 86\n9           8, 66, 68, 78, 84, 86\n10 16, 17, 19, 20, 22, 70, 72, 73\n                                                                            wt\n1                                                      0.2, 0.2, 0.2, 0.2, 0.2\n2                                                      0.2, 0.2, 0.2, 0.2, 0.2\n3                                                       0.25, 0.25, 0.25, 0.25\n4                                                       0.25, 0.25, 0.25, 0.25\n5                                                       0.25, 0.25, 0.25, 0.25\n6                                                      0.2, 0.2, 0.2, 0.2, 0.2\n7                                                       0.25, 0.25, 0.25, 0.25\n8  0.1428571, 0.1428571, 0.1428571, 0.1428571, 0.1428571, 0.1428571, 0.1428571\n9             0.1666667, 0.1666667, 0.1666667, 0.1666667, 0.1666667, 0.1666667\n10                      0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125\n     NAME_2  ID_3    NAME_3   ENGTYPE_3    County GDPPC\n1   Changde 21098   Anxiang      County   Anxiang 23667\n2   Changde 21100   Hanshou      County   Hanshou 20981\n3   Changde 21101    Jinshi County City    Jinshi 34592\n4   Changde 21102        Li      County        Li 24473\n5   Changde 21103     Linli      County     Linli 25554\n6   Changde 21104    Shimen      County    Shimen 27137\n7  Changsha 21109   Liuyang County City   Liuyang 63118\n8  Changsha 21110 Ningxiang      County Ningxiang 62202\n9  Changsha 21111 Wangcheng      County Wangcheng 70666\n10 Chenzhou 21112     Anren      County     Anren 12761\n                         geometry\n1  POLYGON ((112.0625 29.75523...\n2  POLYGON ((112.2288 29.11684...\n3  POLYGON ((111.8927 29.6013,...\n4  POLYGON ((111.3731 29.94649...\n5  POLYGON ((111.6324 29.76288...\n6  POLYGON ((110.8825 30.11675...\n7  POLYGON ((113.9905 28.5682,...\n8  POLYGON ((112.7181 28.38299...\n9  POLYGON ((112.7914 28.52688...\n10 POLYGON ((113.1757 26.82734..."
  },
  {
    "objectID": "exercises/icex06.html#contiguity-weights-rooks-method",
    "href": "exercises/icex06.html#contiguity-weights-rooks-method",
    "title": "In-Class Exercise 6: Spatial Weights and Applications",
    "section": "5.2 Contiguity Weights: Rook’s Method",
    "text": "5.2 Contiguity Weights: Rook’s Method\n\nwm_r <- hunan_GDPPC %>%\n  mutate(nb = st_contiguity(geometry, queen = FALSE),\n         wt = st_weights(nb),\n         .before = 1)\n\n\nwm_r\n\nSimple feature collection with 88 features and 8 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\nFirst 10 features:\n                           nb\n1                3, 4, 57, 85\n2              57, 58, 78, 85\n3                 1, 4, 5, 85\n4                  1, 3, 5, 6\n5                 3, 4, 6, 85\n6            4, 5, 69, 75, 85\n7              67, 71, 74, 84\n8   9, 46, 47, 56, 78, 80, 86\n9       8, 66, 68, 78, 84, 86\n10 16, 19, 20, 22, 70, 72, 73\n                                                                            wt\n1                                                       0.25, 0.25, 0.25, 0.25\n2                                                       0.25, 0.25, 0.25, 0.25\n3                                                       0.25, 0.25, 0.25, 0.25\n4                                                       0.25, 0.25, 0.25, 0.25\n5                                                       0.25, 0.25, 0.25, 0.25\n6                                                      0.2, 0.2, 0.2, 0.2, 0.2\n7                                                       0.25, 0.25, 0.25, 0.25\n8  0.1428571, 0.1428571, 0.1428571, 0.1428571, 0.1428571, 0.1428571, 0.1428571\n9             0.1666667, 0.1666667, 0.1666667, 0.1666667, 0.1666667, 0.1666667\n10 0.1428571, 0.1428571, 0.1428571, 0.1428571, 0.1428571, 0.1428571, 0.1428571\n     NAME_2  ID_3    NAME_3   ENGTYPE_3    County GDPPC\n1   Changde 21098   Anxiang      County   Anxiang 23667\n2   Changde 21100   Hanshou      County   Hanshou 20981\n3   Changde 21101    Jinshi County City    Jinshi 34592\n4   Changde 21102        Li      County        Li 24473\n5   Changde 21103     Linli      County     Linli 25554\n6   Changde 21104    Shimen      County    Shimen 27137\n7  Changsha 21109   Liuyang County City   Liuyang 63118\n8  Changsha 21110 Ningxiang      County Ningxiang 62202\n9  Changsha 21111 Wangcheng      County Wangcheng 70666\n10 Chenzhou 21112     Anren      County     Anren 12761\n                         geometry\n1  POLYGON ((112.0625 29.75523...\n2  POLYGON ((112.2288 29.11684...\n3  POLYGON ((111.8927 29.6013,...\n4  POLYGON ((111.3731 29.94649...\n5  POLYGON ((111.6324 29.76288...\n6  POLYGON ((110.8825 30.11675...\n7  POLYGON ((113.9905 28.5682,...\n8  POLYGON ((112.7181 28.38299...\n9  POLYGON ((112.7914 28.52688...\n10 POLYGON ((113.1757 26.82734..."
  },
  {
    "objectID": "exercises/icex06.html#deriving-fixed-distance-weights",
    "href": "exercises/icex06.html#deriving-fixed-distance-weights",
    "title": "In-Class Exercise 6: Spatial Weights and Applications",
    "section": "6.1 Deriving Fixed Distance Weights",
    "text": "6.1 Deriving Fixed Distance Weights\nBefore we can derive the fixed distance weights, we need to determine the upper limit for distance band using the code chunk below\n\ngeo <- sf::st_geometry((hunan_GDPPC))\nnb <- st_knn(geo, longlat = TRUE)\n\n! Polygon provided. Using point on surface.\n\n\nWarning in st_point_on_surface.sfc(geometry): st_point_on_surface may not give\ncorrect results for longitude/latitude data\n\ndists <- unlist(st_nb_dists(geo, nb))\n\n! Polygon provided. Using point on surface.\n\n\nWarning in st_point_on_surface.sfc(geometry): st_point_on_surface may not give\ncorrect results for longitude/latitude data\n\n\nFrom the code chunk above, we can know that:\nst_nb_dists() of sfdep is used to calculate nearest neighbour distance. It outputs a list of distances for each observation’s neighbours list.\nunlist() of Base R is used to return output as vector so the summary statistics of nearest neighbour distances can be derived\nNow, let’s derived the summary statistics of nearest neighbour distances vector (ie. dists) by using the code chunk below:\n\nsummary(dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  21.56   29.11   36.89   37.34   43.21   65.80 \n\n\nFrom the code chunk above, we know that the maximum nearest neighbour distance is 65.80km. By using a threshold value of 66km, we can ensure that each area has at least one neighbour.\nNow, we will go ahead to compute the fixed distance weights using the code chunk below.\n\nwm_fd <- hunan_GDPPC %>% \n  mutate(nb = st_dist_band(geometry, upper = 66),\n         wt = st_weights(nb),\n         .before = 1)\n\n! Polygon provided. Using point on surface.\n\n\nWarning: There was 1 warning in `stopifnot()`.\nℹ In argument: `nb = st_dist_band(geometry, upper = 66)`.\nCaused by warning in `st_point_on_surface.sfc()`:\n! st_point_on_surface may not give correct results for longitude/latitude data\n\n\nFrom the code above, we can know that:\nst_dists_band() of sfdep is used to identity neighbours based on a distance band. Output is a list of neighbours\nst_weights() is used to calculate polygon spatial weights of nb list.\n\nthe default style argument is set to “W” for row standardised weights and\nthe default allow_zero is set to TRUE, assigns zero as lagged value to zone without neighbours\n\nLet us examine the dataframe of the fixed distance weights\n\nwm_fd\n\nSimple feature collection with 88 features and 8 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\nFirst 10 features:\n                       nb\n1      2, 3, 4, 5, 57, 64\n2       1, 57, 58, 78, 85\n3             1, 4, 5, 57\n4              1, 3, 5, 6\n5          1, 3, 4, 6, 69\n6                4, 5, 69\n7              67, 71, 84\n8       9, 46, 47, 78, 80\n9   8, 46, 66, 68, 84, 86\n10 16, 20, 22, 70, 72, 73\n                                                                 wt   NAME_2\n1  0.1666667, 0.1666667, 0.1666667, 0.1666667, 0.1666667, 0.1666667  Changde\n2                                           0.2, 0.2, 0.2, 0.2, 0.2  Changde\n3                                            0.25, 0.25, 0.25, 0.25  Changde\n4                                            0.25, 0.25, 0.25, 0.25  Changde\n5                                           0.2, 0.2, 0.2, 0.2, 0.2  Changde\n6                                   0.3333333, 0.3333333, 0.3333333  Changde\n7                                   0.3333333, 0.3333333, 0.3333333 Changsha\n8                                           0.2, 0.2, 0.2, 0.2, 0.2 Changsha\n9  0.1666667, 0.1666667, 0.1666667, 0.1666667, 0.1666667, 0.1666667 Changsha\n10 0.1666667, 0.1666667, 0.1666667, 0.1666667, 0.1666667, 0.1666667 Chenzhou\n    ID_3    NAME_3   ENGTYPE_3    County GDPPC                       geometry\n1  21098   Anxiang      County   Anxiang 23667 POLYGON ((112.0625 29.75523...\n2  21100   Hanshou      County   Hanshou 20981 POLYGON ((112.2288 29.11684...\n3  21101    Jinshi County City    Jinshi 34592 POLYGON ((111.8927 29.6013,...\n4  21102        Li      County        Li 24473 POLYGON ((111.3731 29.94649...\n5  21103     Linli      County     Linli 25554 POLYGON ((111.6324 29.76288...\n6  21104    Shimen      County    Shimen 27137 POLYGON ((110.8825 30.11675...\n7  21109   Liuyang County City   Liuyang 63118 POLYGON ((113.9905 28.5682,...\n8  21110 Ningxiang      County Ningxiang 62202 POLYGON ((112.7181 28.38299...\n9  21111 Wangcheng      County Wangcheng 70666 POLYGON ((112.7914 28.52688...\n10 21112     Anren      County     Anren 12761 POLYGON ((113.1757 26.82734..."
  },
  {
    "objectID": "exercises/icex06.html#deriving-adaptive-distance-weights",
    "href": "exercises/icex06.html#deriving-adaptive-distance-weights",
    "title": "In-Class Exercise 6: Spatial Weights and Applications",
    "section": "6.2 Deriving Adaptive Distance Weights",
    "text": "6.2 Deriving Adaptive Distance Weights\n\nwm_ad <- hunan_GDPPC %>%\n  mutate(nb = st_knn(geometry,\n                     k = 8),\n         wt = st_weights(nb),\n         .before = 1)\n\n! Polygon provided. Using point on surface.\n\n\nWarning: There was 1 warning in `stopifnot()`.\nℹ In argument: `nb = st_knn(geometry, k = 8)`.\nCaused by warning in `st_point_on_surface.sfc()`:\n! st_point_on_surface may not give correct results for longitude/latitude data\n\n\nFrom the code above, we can learn that:\nst_knn() of sfdep is used to identify neighbours based on k (ie. k = 8 indicates 8 nearest neighbours). Output similarly is a list of neighbours (ie. nb)\nst_weights() is used to calculate polygon spatial weights of nb list. Note\n\nthe default style argument is set to “W” for row standardised weights and\nthe default allow_zero is set to TRUE, assigns zero as lagged value to zone without neighbours\n\n\nwm_ad\n\nSimple feature collection with 88 features and 8 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\nFirst 10 features:\n                               nb\n1      2, 3, 4, 5, 57, 58, 64, 76\n2     1, 3, 8, 57, 58, 68, 78, 85\n3       1, 2, 4, 5, 6, 57, 64, 85\n4       1, 2, 3, 5, 6, 57, 64, 69\n5       1, 2, 3, 4, 6, 57, 69, 85\n6       1, 2, 3, 4, 5, 69, 75, 85\n7   9, 66, 67, 68, 71, 74, 84, 86\n8    2, 9, 35, 46, 47, 78, 80, 86\n9   8, 46, 47, 66, 68, 78, 84, 86\n10 16, 17, 19, 20, 22, 70, 72, 73\n                                                       wt   NAME_2  ID_3\n1  0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125  Changde 21098\n2  0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125  Changde 21100\n3  0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125  Changde 21101\n4  0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125  Changde 21102\n5  0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125  Changde 21103\n6  0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125  Changde 21104\n7  0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125 Changsha 21109\n8  0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125 Changsha 21110\n9  0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125 Changsha 21111\n10 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125 Chenzhou 21112\n      NAME_3   ENGTYPE_3    County GDPPC                       geometry\n1    Anxiang      County   Anxiang 23667 POLYGON ((112.0625 29.75523...\n2    Hanshou      County   Hanshou 20981 POLYGON ((112.2288 29.11684...\n3     Jinshi County City    Jinshi 34592 POLYGON ((111.8927 29.6013,...\n4         Li      County        Li 24473 POLYGON ((111.3731 29.94649...\n5      Linli      County     Linli 25554 POLYGON ((111.6324 29.76288...\n6     Shimen      County    Shimen 27137 POLYGON ((110.8825 30.11675...\n7    Liuyang County City   Liuyang 63118 POLYGON ((113.9905 28.5682,...\n8  Ningxiang      County Ningxiang 62202 POLYGON ((112.7181 28.38299...\n9  Wangcheng      County Wangcheng 70666 POLYGON ((112.7914 28.52688...\n10     Anren      County     Anren 12761 POLYGON ((113.1757 26.82734..."
  },
  {
    "objectID": "exercises/icex06.html#deriving-inverse-distance-weights",
    "href": "exercises/icex06.html#deriving-inverse-distance-weights",
    "title": "In-Class Exercise 6: Spatial Weights and Applications",
    "section": "6.3 Deriving Inverse Distance Weights",
    "text": "6.3 Deriving Inverse Distance Weights\n\nwm_idw <- hunan_GDPPC %>%\n  mutate(nb = st_contiguity(geometry),\n         wts = st_inverse_distance(nb, geometry,\n                                   scale = 1,\n                                   alpha = 1),\n         .before = 1)\n\n! Polygon provided. Using point on surface.\n\n\nWarning: There was 1 warning in `stopifnot()`.\nℹ In argument: `wts = st_inverse_distance(nb, geometry, scale = 1, alpha = 1)`.\nCaused by warning in `st_point_on_surface.sfc()`:\n! st_point_on_surface may not give correct results for longitude/latitude data\n\n\nFrom the code above, we can learn that:\nst_contiguity() of sfdep is used to identify neighbours by contiguity criteria. The output is a list of neighbours (ie. nb)\nst_inverse_distance() is used to calculate inverse distance weights of neighbours on the nb list\nNote:\n\nthe default style argument is set to “W” for row standardised weights and\nthe default allow_zero is set to TRUE, assigns zero as lagged value to zone without neighbours\n\n\nwm_idw\n\nSimple feature collection with 88 features and 8 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\nFirst 10 features:\n                               nb\n1                 2, 3, 4, 57, 85\n2               1, 57, 58, 78, 85\n3                     1, 4, 5, 85\n4                      1, 3, 5, 6\n5                     3, 4, 6, 85\n6                4, 5, 69, 75, 85\n7                  67, 71, 74, 84\n8       9, 46, 47, 56, 78, 80, 86\n9           8, 66, 68, 78, 84, 86\n10 16, 17, 19, 20, 22, 70, 72, 73\n                                                                                              wts\n1                                      0.01526149, 0.03515537, 0.02176677, 0.02836978, 0.01029857\n2                                      0.01526149, 0.01601100, 0.01911052, 0.02327058, 0.01591694\n3                                                  0.03515537, 0.04581089, 0.04116397, 0.01208437\n4                                                  0.02176677, 0.04581089, 0.04637578, 0.01585302\n5                                                  0.04116397, 0.04637578, 0.01896212, 0.01351099\n6                                      0.01585302, 0.01896212, 0.02710909, 0.01140718, 0.01080890\n7                                                  0.01621067, 0.01536702, 0.01133628, 0.01836488\n8              0.01930410, 0.02675555, 0.02151751, 0.01076895, 0.02608065, 0.01519804, 0.01337412\n9                          0.01930410, 0.01651371, 0.01798519, 0.01473155, 0.03015561, 0.01612293\n10 0.02737233, 0.01390810, 0.01458881, 0.02156771, 0.02419268, 0.02350470, 0.01784174, 0.01621545\n     NAME_2  ID_3    NAME_3   ENGTYPE_3    County GDPPC\n1   Changde 21098   Anxiang      County   Anxiang 23667\n2   Changde 21100   Hanshou      County   Hanshou 20981\n3   Changde 21101    Jinshi County City    Jinshi 34592\n4   Changde 21102        Li      County        Li 24473\n5   Changde 21103     Linli      County     Linli 25554\n6   Changde 21104    Shimen      County    Shimen 27137\n7  Changsha 21109   Liuyang County City   Liuyang 63118\n8  Changsha 21110 Ningxiang      County Ningxiang 62202\n9  Changsha 21111 Wangcheng      County Wangcheng 70666\n10 Chenzhou 21112     Anren      County     Anren 12761\n                         geometry\n1  POLYGON ((112.0625 29.75523...\n2  POLYGON ((112.2288 29.11684...\n3  POLYGON ((111.8927 29.6013,...\n4  POLYGON ((111.3731 29.94649...\n5  POLYGON ((111.6324 29.76288...\n6  POLYGON ((110.8825 30.11675...\n7  POLYGON ((113.9905 28.5682,...\n8  POLYGON ((112.7181 28.38299...\n9  POLYGON ((112.7914 28.52688...\n10 POLYGON ((113.1757 26.82734..."
  },
  {
    "objectID": "exercises/icex07.html",
    "href": "exercises/icex07.html",
    "title": "In-Class Exercise 7: Spatial Weights and Applications",
    "section": "",
    "text": "Pacman assists us by helping us load R packages that we require, sf, sfdep, tidyverse, plotly and tmap.\n\npacman::p_load(tidyverse, tmap, sf, sfdep, plotly)\n\nPlotly helps to make our charts interactive.\n\n\n\nThe following datasets are used:\n\n\n\nDataset Name\nSource\n\n\n\n\nHunan (Hunan.shp)\nProf Kam\n\n\nHunan 2021 (Hunan-2021.csv)\nProf Kam"
  },
  {
    "objectID": "exercises/icex07.html#importing-spatial-data",
    "href": "exercises/icex07.html#importing-spatial-data",
    "title": "In-Class Exercise 7: Spatial Weights and Applications",
    "section": "2.1 Importing Spatial Data",
    "text": "2.1 Importing Spatial Data\nWe will use st_read() of sf package to import the three geospatial datasets.\n\nhunan <- st_read(dsn = \"In-Class_Ex07/data/geospatial\", layer = \"hunan\")\n\nReading layer `hunan' from data source \n  `C:\\renjie-teo\\IS415-GAA\\exercises\\In-Class_Ex07\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\nhunan_2012 <- read_csv(\"In-Class_Ex07/data/aspatial/Hunan_2012.csv\")\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "exercises/icex07.html#combining-both-data-frame-by-using-left-join",
    "href": "exercises/icex07.html#combining-both-data-frame-by-using-left-join",
    "title": "In-Class Exercise 7: Spatial Weights and Applications",
    "section": "2.2 Combining both data frame by using left join",
    "text": "2.2 Combining both data frame by using left join\n\nhunan_GDPPC <- left_join(hunan, hunan_2012) %>%\n  select(1:4, 7, 15)\n\nJoining with `by = join_by(County)`\n\n\nIf two columns have the same name, they will automatically be joined, else, the following code has to be specified after the dataframes to be joined. A == B"
  },
  {
    "objectID": "exercises/icex07.html#contiguity-neighbours-methods",
    "href": "exercises/icex07.html#contiguity-neighbours-methods",
    "title": "In-Class Exercise 7: Spatial Weights and Applications",
    "section": "4.1 Contiguity Neighbours Methods",
    "text": "4.1 Contiguity Neighbours Methods\n\n4.1.1 Queen’s Method\nIn the code chunk below st_contiguity() is used to derive a contiguity neighbour list by using Queen’s method.\n\nnb_queen <- hunan_GDPPC %>%\n  mutate(nb = st_contiguity(geometry),\n         wt = st_weights(nb, style = \"W\"),\n         .before = 1)\n\nThe code chunk below prints the neighbours found using the Queen’s method:\n\nsummary(nb_queen)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\n    nb       wt.Length  wt.Class  wt.Mode    NAME_2               ID_3      \n NULL:NULL    5       -none-   numeric    Length:88          Min.   :21098  \n              5       -none-   numeric    Class :character   1st Qu.:21125  \n              4       -none-   numeric    Mode  :character   Median :21150  \n              4       -none-   numeric                       Mean   :21150  \n              4       -none-   numeric                       3rd Qu.:21174  \n              5       -none-   numeric                       Max.   :21201  \n              4       -none-   numeric                                      \n              7       -none-   numeric                                      \n              6       -none-   numeric                                      \n              8       -none-   numeric                                      \n              3       -none-   numeric                                      \n              5       -none-   numeric                                      \n              4       -none-   numeric                                      \n              3       -none-   numeric                                      \n              4       -none-   numeric                                      \n              5       -none-   numeric                                      \n              7       -none-   numeric                                      \n              5       -none-   numeric                                      \n              6       -none-   numeric                                      \n              7       -none-   numeric                                      \n              5       -none-   numeric                                      \n              5       -none-   numeric                                      \n              7       -none-   numeric                                      \n              5       -none-   numeric                                      \n              5       -none-   numeric                                      \n              4       -none-   numeric                                      \n              3       -none-   numeric                                      \n              5       -none-   numeric                                      \n              3       -none-   numeric                                      \n              1       -none-   numeric                                      \n              8       -none-   numeric                                      \n              8       -none-   numeric                                      \n              5       -none-   numeric                                      \n              3       -none-   numeric                                      \n              6       -none-   numeric                                      \n              6       -none-   numeric                                      \n              4       -none-   numeric                                      \n              4       -none-   numeric                                      \n              5       -none-   numeric                                      \n              6       -none-   numeric                                      \n              6       -none-   numeric                                      \n              7       -none-   numeric                                      \n              6       -none-   numeric                                      \n              4       -none-   numeric                                      \n              6       -none-   numeric                                      \n              3       -none-   numeric                                      \n              5       -none-   numeric                                      \n              5       -none-   numeric                                      \n              4       -none-   numeric                                      \n              5       -none-   numeric                                      \n              3       -none-   numeric                                      \n              5       -none-   numeric                                      \n              3       -none-   numeric                                      \n              6       -none-   numeric                                      \n              5       -none-   numeric                                      \n              7       -none-   numeric                                      \n              6       -none-   numeric                                      \n              5       -none-   numeric                                      \n              4       -none-   numeric                                      \n              4       -none-   numeric                                      \n              7       -none-   numeric                                      \n              3       -none-   numeric                                      \n              4       -none-   numeric                                      \n              2       -none-   numeric                                      \n              1       -none-   numeric                                      \n              5       -none-   numeric                                      \n              4       -none-   numeric                                      \n              5       -none-   numeric                                      \n              3       -none-   numeric                                      \n              3       -none-   numeric                                      \n              3       -none-   numeric                                      \n              5       -none-   numeric                                      \n              5       -none-   numeric                                      \n              6       -none-   numeric                                      \n              6       -none-   numeric                                      \n              7       -none-   numeric                                      \n              7       -none-   numeric                                      \n              7       -none-   numeric                                      \n              7       -none-   numeric                                      \n              8       -none-   numeric                                      \n              6       -none-   numeric                                      \n              5       -none-   numeric                                      \n              9       -none-   numeric                                      \n              6       -none-   numeric                                      \n             11       -none-   numeric                                      \n              9       -none-   numeric                                      \n              4       -none-   numeric                                      \n              2       -none-   numeric                                      \n    NAME_3           ENGTYPE_3            County              GDPPC      \n Length:88          Length:88          Length:88          Min.   : 8497  \n Class :character   Class :character   Class :character   1st Qu.:14566  \n Mode  :character   Mode  :character   Mode  :character   Median :20433  \n                                                          Mean   :24405  \n                                                          3rd Qu.:27224  \n                                                          Max.   :88656  \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n          geometry \n POLYGON      :88  \n epsg:4326    : 0  \n +proj=long...: 0"
  },
  {
    "objectID": "exercises/icex07.html#contiguity-weights-queens-method",
    "href": "exercises/icex07.html#contiguity-weights-queens-method",
    "title": "In-Class Exercise 7: Spatial Weights and Applications",
    "section": "5.1 Contiguity Weights: Queen’s Method",
    "text": "5.1 Contiguity Weights: Queen’s Method\n\nwm_q <- hunan_GDPPC %>%\n  mutate(nb = st_contiguity(geometry),\n         wt = st_weights(nb),\n         .before = 1)\n\n\nwm_q\n\nSimple feature collection with 88 features and 8 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\nFirst 10 features:\n                               nb\n1                 2, 3, 4, 57, 85\n2               1, 57, 58, 78, 85\n3                     1, 4, 5, 85\n4                      1, 3, 5, 6\n5                     3, 4, 6, 85\n6                4, 5, 69, 75, 85\n7                  67, 71, 74, 84\n8       9, 46, 47, 56, 78, 80, 86\n9           8, 66, 68, 78, 84, 86\n10 16, 17, 19, 20, 22, 70, 72, 73\n                                                                            wt\n1                                                      0.2, 0.2, 0.2, 0.2, 0.2\n2                                                      0.2, 0.2, 0.2, 0.2, 0.2\n3                                                       0.25, 0.25, 0.25, 0.25\n4                                                       0.25, 0.25, 0.25, 0.25\n5                                                       0.25, 0.25, 0.25, 0.25\n6                                                      0.2, 0.2, 0.2, 0.2, 0.2\n7                                                       0.25, 0.25, 0.25, 0.25\n8  0.1428571, 0.1428571, 0.1428571, 0.1428571, 0.1428571, 0.1428571, 0.1428571\n9             0.1666667, 0.1666667, 0.1666667, 0.1666667, 0.1666667, 0.1666667\n10                      0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125\n     NAME_2  ID_3    NAME_3   ENGTYPE_3    County GDPPC\n1   Changde 21098   Anxiang      County   Anxiang 23667\n2   Changde 21100   Hanshou      County   Hanshou 20981\n3   Changde 21101    Jinshi County City    Jinshi 34592\n4   Changde 21102        Li      County        Li 24473\n5   Changde 21103     Linli      County     Linli 25554\n6   Changde 21104    Shimen      County    Shimen 27137\n7  Changsha 21109   Liuyang County City   Liuyang 63118\n8  Changsha 21110 Ningxiang      County Ningxiang 62202\n9  Changsha 21111 Wangcheng      County Wangcheng 70666\n10 Chenzhou 21112     Anren      County     Anren 12761\n                         geometry\n1  POLYGON ((112.0625 29.75523...\n2  POLYGON ((112.2288 29.11684...\n3  POLYGON ((111.8927 29.6013,...\n4  POLYGON ((111.3731 29.94649...\n5  POLYGON ((111.6324 29.76288...\n6  POLYGON ((110.8825 30.11675...\n7  POLYGON ((113.9905 28.5682,...\n8  POLYGON ((112.7181 28.38299...\n9  POLYGON ((112.7914 28.52688...\n10 POLYGON ((113.1757 26.82734..."
  },
  {
    "objectID": "exercises/icex07.html#contiguity-weights-rooks-method",
    "href": "exercises/icex07.html#contiguity-weights-rooks-method",
    "title": "In-Class Exercise 7: Spatial Weights and Applications",
    "section": "5.2 Contiguity Weights: Rook’s Method",
    "text": "5.2 Contiguity Weights: Rook’s Method\n\nwm_r <- hunan_GDPPC %>%\n  mutate(nb = st_contiguity(geometry, queen = FALSE),\n         wt = st_weights(nb),\n         .before = 1)\n\n\nwm_r\n\nSimple feature collection with 88 features and 8 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\nFirst 10 features:\n                           nb\n1                3, 4, 57, 85\n2              57, 58, 78, 85\n3                 1, 4, 5, 85\n4                  1, 3, 5, 6\n5                 3, 4, 6, 85\n6            4, 5, 69, 75, 85\n7              67, 71, 74, 84\n8   9, 46, 47, 56, 78, 80, 86\n9       8, 66, 68, 78, 84, 86\n10 16, 19, 20, 22, 70, 72, 73\n                                                                            wt\n1                                                       0.25, 0.25, 0.25, 0.25\n2                                                       0.25, 0.25, 0.25, 0.25\n3                                                       0.25, 0.25, 0.25, 0.25\n4                                                       0.25, 0.25, 0.25, 0.25\n5                                                       0.25, 0.25, 0.25, 0.25\n6                                                      0.2, 0.2, 0.2, 0.2, 0.2\n7                                                       0.25, 0.25, 0.25, 0.25\n8  0.1428571, 0.1428571, 0.1428571, 0.1428571, 0.1428571, 0.1428571, 0.1428571\n9             0.1666667, 0.1666667, 0.1666667, 0.1666667, 0.1666667, 0.1666667\n10 0.1428571, 0.1428571, 0.1428571, 0.1428571, 0.1428571, 0.1428571, 0.1428571\n     NAME_2  ID_3    NAME_3   ENGTYPE_3    County GDPPC\n1   Changde 21098   Anxiang      County   Anxiang 23667\n2   Changde 21100   Hanshou      County   Hanshou 20981\n3   Changde 21101    Jinshi County City    Jinshi 34592\n4   Changde 21102        Li      County        Li 24473\n5   Changde 21103     Linli      County     Linli 25554\n6   Changde 21104    Shimen      County    Shimen 27137\n7  Changsha 21109   Liuyang County City   Liuyang 63118\n8  Changsha 21110 Ningxiang      County Ningxiang 62202\n9  Changsha 21111 Wangcheng      County Wangcheng 70666\n10 Chenzhou 21112     Anren      County     Anren 12761\n                         geometry\n1  POLYGON ((112.0625 29.75523...\n2  POLYGON ((112.2288 29.11684...\n3  POLYGON ((111.8927 29.6013,...\n4  POLYGON ((111.3731 29.94649...\n5  POLYGON ((111.6324 29.76288...\n6  POLYGON ((110.8825 30.11675...\n7  POLYGON ((113.9905 28.5682,...\n8  POLYGON ((112.7181 28.38299...\n9  POLYGON ((112.7914 28.52688...\n10 POLYGON ((113.1757 26.82734..."
  },
  {
    "objectID": "exercises/icex07.html#performing-global-morans-i-test",
    "href": "exercises/icex07.html#performing-global-morans-i-test",
    "title": "In-Class Exercise 7: Spatial Weights and Applications",
    "section": "6.1 Performing Global Moran’s I Test",
    "text": "6.1 Performing Global Moran’s I Test\n\nmoranI <- global_moran(wm_q$GDPPC,\n                       wm_q$nb,\n                       wm_q$wt)\n\n\n\n\n\n\n\nNote\n\n\n\nTypically global_moran test is not run, we can just run the global_moran_test as shown below\n\n\nPerforming Global Moran I Test\n\nglobal_moran_test(wm_q$GDPPC,\n                  wm_q$nb,\n                  wm_q$wt)\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\nSince p-value < 0.05, we reject the null hypothesis. We observe clustering at the Moran I statistic is > 0."
  },
  {
    "objectID": "exercises/icex07.html#performing-global-moran-i-permutation-test",
    "href": "exercises/icex07.html#performing-global-moran-i-permutation-test",
    "title": "In-Class Exercise 7: Spatial Weights and Applications",
    "section": "6.2 Performing Global Moran I Permutation Test",
    "text": "6.2 Performing Global Moran I Permutation Test\nIn Global Moran I test, it is called permutation test, but in other cases, it might be called Monte Carlo Simulation.\nIn the code below, we set a particular seed to ensure our results are reproducible.\nIf we run nsim = 99 we are actually running 100 simulations, the more simulations, especially if observations are small, the more stable the results.\n\nset.seed(1234)\nglobal_moran_perm(wm_q$GDPPC,\n                  wm_q$nb,\n                  wm_q$wt,\n                  nsim = 99)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.30075, observed rank = 100, p-value < 2.2e-16\nalternative hypothesis: two.sided"
  },
  {
    "objectID": "exercises/icex07.html#computing-local-morans-i",
    "href": "exercises/icex07.html#computing-local-morans-i",
    "title": "In-Class Exercise 7: Spatial Weights and Applications",
    "section": "7.1 Computing Local Moran’s I",
    "text": "7.1 Computing Local Moran’s I\n\nlisa <- wm_q %>%\n  mutate(local_moran = local_moran(\n    GDPPC, nb, wt, nsim = 99),\n    .before = 1) %>%\n  unnest(local_moran)\nlisa\n\nSimple feature collection with 88 features and 20 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n# A tibble: 88 × 21\n         ii        eii   var_ii    z_ii    p_ii p_ii_…¹ p_fol…² skewn…³ kurtosis\n      <dbl>      <dbl>    <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>    <dbl>\n 1 -0.00147  0.00177    4.18e-4 -0.158  0.874      0.82    0.41  -0.812  0.652  \n 2  0.0259   0.00641    1.05e-2  0.190  0.849      0.96    0.48  -1.09   1.89   \n 3 -0.0120  -0.0374     1.02e-1  0.0796 0.937      0.76    0.38   0.824  0.0461 \n 4  0.00102 -0.0000349  4.37e-6  0.506  0.613      0.64    0.32   1.04   1.61   \n 5  0.0148  -0.00340    1.65e-3  0.449  0.654      0.5     0.25   1.64   3.96   \n 6 -0.0388  -0.00339    5.45e-3 -0.480  0.631      0.82    0.41   0.614 -0.264  \n 7  3.37    -0.198      1.41e+0  3.00   0.00266    0.08    0.04   1.46   2.74   \n 8  1.56    -0.265      8.04e-1  2.04   0.0417     0.08    0.04   0.459 -0.519  \n 9  4.42     0.0450     1.79e+0  3.27   0.00108    0.02    0.01   0.746 -0.00582\n10 -0.399   -0.0505     8.59e-2 -1.19   0.234      0.28    0.14  -0.685  0.134  \n# … with 78 more rows, 12 more variables: mean <fct>, median <fct>,\n#   pysal <fct>, nb <nb>, wt <list>, NAME_2 <chr>, ID_3 <int>, NAME_3 <chr>,\n#   ENGTYPE_3 <chr>, County <chr>, GDPPC <dbl>, geometry <POLYGON [°]>, and\n#   abbreviated variable names ¹​p_ii_sim, ²​p_folded_sim, ³​skewness\n\n\n\n\n\n\n\n\nNote\n\n\n\nunnest is necessary to be able to plot the data. unnest is to unnest the values from a list to be able to plot it on tmap\n\n\nIn general, for lisa var, the mean or pysal should be the same, we can use either to plot the graph. In general, we do not need to use median unless we are concerned about non-normality assumptions."
  },
  {
    "objectID": "exercises/icex07.html#visualising-local-morans-i",
    "href": "exercises/icex07.html#visualising-local-morans-i",
    "title": "In-Class Exercise 7: Spatial Weights and Applications",
    "section": "7.2 Visualising Local Moran’s I",
    "text": "7.2 Visualising Local Moran’s I\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(lisa) +\n  tm_fill(\"ii\") +\n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8))\n\nVariable(s) \"ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(lisa) +\n  tm_fill(\"p_ii_sim\") +\n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8))\n\n\n\n\nWe avoid using p_ii under lisa as it was not run over several simulations, we would prefer to use p_ii_sim instead.\n\nlisa_sig <- lisa %>% filter(p_ii < 0.05) # to modify code to plot non-significant values as a class itself also\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(lisa) +\n  tm_polygons() + \n  tm_borders(alpha = 0.5) +\ntm_shape(lisa_sig) +\n  tm_fill(\"mean\") +\n  tm_view(set.zoom.limits = c(6,8))\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them)."
  },
  {
    "objectID": "exercises/icex07.html#visualising-p-value-of-hcsa",
    "href": "exercises/icex07.html#visualising-p-value-of-hcsa",
    "title": "In-Class Exercise 7: Spatial Weights and Applications",
    "section": "8.1 Visualising p-value of HCSA",
    "text": "8.1 Visualising p-value of HCSA\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(HCSA) +\n  tm_fill(\"p_sim\") +\n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8))"
  },
  {
    "objectID": "exercises/icex08.html",
    "href": "exercises/icex08.html",
    "title": "In-Class Exercise 7: Spatial Weights and Applications",
    "section": "",
    "text": "Pacman assists us by helping us load R packages that we require, sf, sfdep, tidyverse, plotly and tmap.\n\npacman::p_load(tidyverse, tmap, sf, sfdep, plotly)\n\nPlotly helps to make our charts interactive.\n\n\n\nThe following datasets are used:\n\n\n\nDataset Name\nSource\n\n\n\n\nHunan (Hunan.shp)\nProf Kam\n\n\nHunan 2021 (Hunan-2021.csv)\nProf Kam"
  },
  {
    "objectID": "exercises/icex08.html#importing-spatial-data",
    "href": "exercises/icex08.html#importing-spatial-data",
    "title": "In-Class Exercise 7: Spatial Weights and Applications",
    "section": "2.1 Importing Spatial Data",
    "text": "2.1 Importing Spatial Data\nWe will use st_read() of sf package to import the three geospatial datasets.\n\nhunan <- st_read(dsn = \"In-Class_Ex07/data/geospatial\", layer = \"hunan\")\n\nReading layer `hunan' from data source \n  `C:\\renjie-teo\\IS415-GAA\\exercises\\In-Class_Ex07\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\nhunan_2012 <- read_csv(\"In-Class_Ex07/data/aspatial/Hunan_2012.csv\")\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "exercises/icex08.html#combining-both-data-frame-by-using-left-join",
    "href": "exercises/icex08.html#combining-both-data-frame-by-using-left-join",
    "title": "In-Class Exercise 7: Spatial Weights and Applications",
    "section": "2.2 Combining both data frame by using left join",
    "text": "2.2 Combining both data frame by using left join\n\nhunan_GDPPC <- left_join(hunan, hunan_2012) %>%\n  select(1:4, 7, 15)\n\nJoining with `by = join_by(County)`\n\n\nIf two columns have the same name, they will automatically be joined, else, the following code has to be specified after the dataframes to be joined. A == B"
  },
  {
    "objectID": "exercises/icex08.html#contiguity-neighbours-methods",
    "href": "exercises/icex08.html#contiguity-neighbours-methods",
    "title": "In-Class Exercise 7: Spatial Weights and Applications",
    "section": "4.1 Contiguity Neighbours Methods",
    "text": "4.1 Contiguity Neighbours Methods\n\n4.1.1 Queen’s Method\nIn the code chunk below st_contiguity() is used to derive a contiguity neighbour list by using Queen’s method.\n\nnb_queen <- hunan_GDPPC %>%\n  mutate(nb = st_contiguity(geometry),\n         wt = st_weights(nb, style = \"W\"),\n         .before = 1)\n\nThe code chunk below prints the neighbours found using the Queen’s method:\n\nsummary(nb_queen)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\n    nb       wt.Length  wt.Class  wt.Mode    NAME_2               ID_3      \n NULL:NULL    5       -none-   numeric    Length:88          Min.   :21098  \n              5       -none-   numeric    Class :character   1st Qu.:21125  \n              4       -none-   numeric    Mode  :character   Median :21150  \n              4       -none-   numeric                       Mean   :21150  \n              4       -none-   numeric                       3rd Qu.:21174  \n              5       -none-   numeric                       Max.   :21201  \n              4       -none-   numeric                                      \n              7       -none-   numeric                                      \n              6       -none-   numeric                                      \n              8       -none-   numeric                                      \n              3       -none-   numeric                                      \n              5       -none-   numeric                                      \n              4       -none-   numeric                                      \n              3       -none-   numeric                                      \n              4       -none-   numeric                                      \n              5       -none-   numeric                                      \n              7       -none-   numeric                                      \n              5       -none-   numeric                                      \n              6       -none-   numeric                                      \n              7       -none-   numeric                                      \n              5       -none-   numeric                                      \n              5       -none-   numeric                                      \n              7       -none-   numeric                                      \n              5       -none-   numeric                                      \n              5       -none-   numeric                                      \n              4       -none-   numeric                                      \n              3       -none-   numeric                                      \n              5       -none-   numeric                                      \n              3       -none-   numeric                                      \n              1       -none-   numeric                                      \n              8       -none-   numeric                                      \n              8       -none-   numeric                                      \n              5       -none-   numeric                                      \n              3       -none-   numeric                                      \n              6       -none-   numeric                                      \n              6       -none-   numeric                                      \n              4       -none-   numeric                                      \n              4       -none-   numeric                                      \n              5       -none-   numeric                                      \n              6       -none-   numeric                                      \n              6       -none-   numeric                                      \n              7       -none-   numeric                                      \n              6       -none-   numeric                                      \n              4       -none-   numeric                                      \n              6       -none-   numeric                                      \n              3       -none-   numeric                                      \n              5       -none-   numeric                                      \n              5       -none-   numeric                                      \n              4       -none-   numeric                                      \n              5       -none-   numeric                                      \n              3       -none-   numeric                                      \n              5       -none-   numeric                                      \n              3       -none-   numeric                                      \n              6       -none-   numeric                                      \n              5       -none-   numeric                                      \n              7       -none-   numeric                                      \n              6       -none-   numeric                                      \n              5       -none-   numeric                                      \n              4       -none-   numeric                                      \n              4       -none-   numeric                                      \n              7       -none-   numeric                                      \n              3       -none-   numeric                                      \n              4       -none-   numeric                                      \n              2       -none-   numeric                                      \n              1       -none-   numeric                                      \n              5       -none-   numeric                                      \n              4       -none-   numeric                                      \n              5       -none-   numeric                                      \n              3       -none-   numeric                                      \n              3       -none-   numeric                                      \n              3       -none-   numeric                                      \n              5       -none-   numeric                                      \n              5       -none-   numeric                                      \n              6       -none-   numeric                                      \n              6       -none-   numeric                                      \n              7       -none-   numeric                                      \n              7       -none-   numeric                                      \n              7       -none-   numeric                                      \n              7       -none-   numeric                                      \n              8       -none-   numeric                                      \n              6       -none-   numeric                                      \n              5       -none-   numeric                                      \n              9       -none-   numeric                                      \n              6       -none-   numeric                                      \n             11       -none-   numeric                                      \n              9       -none-   numeric                                      \n              4       -none-   numeric                                      \n              2       -none-   numeric                                      \n    NAME_3           ENGTYPE_3            County              GDPPC      \n Length:88          Length:88          Length:88          Min.   : 8497  \n Class :character   Class :character   Class :character   1st Qu.:14566  \n Mode  :character   Mode  :character   Mode  :character   Median :20433  \n                                                          Mean   :24405  \n                                                          3rd Qu.:27224  \n                                                          Max.   :88656  \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n          geometry \n POLYGON      :88  \n epsg:4326    : 0  \n +proj=long...: 0"
  },
  {
    "objectID": "exercises/icex08.html#contiguity-weights-queens-method",
    "href": "exercises/icex08.html#contiguity-weights-queens-method",
    "title": "In-Class Exercise 7: Spatial Weights and Applications",
    "section": "5.1 Contiguity Weights: Queen’s Method",
    "text": "5.1 Contiguity Weights: Queen’s Method\n\nwm_q <- hunan_GDPPC %>%\n  mutate(nb = st_contiguity(geometry),\n         wt = st_weights(nb),\n         .before = 1)\n\n\nwm_q\n\nSimple feature collection with 88 features and 8 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\nFirst 10 features:\n                               nb\n1                 2, 3, 4, 57, 85\n2               1, 57, 58, 78, 85\n3                     1, 4, 5, 85\n4                      1, 3, 5, 6\n5                     3, 4, 6, 85\n6                4, 5, 69, 75, 85\n7                  67, 71, 74, 84\n8       9, 46, 47, 56, 78, 80, 86\n9           8, 66, 68, 78, 84, 86\n10 16, 17, 19, 20, 22, 70, 72, 73\n                                                                            wt\n1                                                      0.2, 0.2, 0.2, 0.2, 0.2\n2                                                      0.2, 0.2, 0.2, 0.2, 0.2\n3                                                       0.25, 0.25, 0.25, 0.25\n4                                                       0.25, 0.25, 0.25, 0.25\n5                                                       0.25, 0.25, 0.25, 0.25\n6                                                      0.2, 0.2, 0.2, 0.2, 0.2\n7                                                       0.25, 0.25, 0.25, 0.25\n8  0.1428571, 0.1428571, 0.1428571, 0.1428571, 0.1428571, 0.1428571, 0.1428571\n9             0.1666667, 0.1666667, 0.1666667, 0.1666667, 0.1666667, 0.1666667\n10                      0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125\n     NAME_2  ID_3    NAME_3   ENGTYPE_3    County GDPPC\n1   Changde 21098   Anxiang      County   Anxiang 23667\n2   Changde 21100   Hanshou      County   Hanshou 20981\n3   Changde 21101    Jinshi County City    Jinshi 34592\n4   Changde 21102        Li      County        Li 24473\n5   Changde 21103     Linli      County     Linli 25554\n6   Changde 21104    Shimen      County    Shimen 27137\n7  Changsha 21109   Liuyang County City   Liuyang 63118\n8  Changsha 21110 Ningxiang      County Ningxiang 62202\n9  Changsha 21111 Wangcheng      County Wangcheng 70666\n10 Chenzhou 21112     Anren      County     Anren 12761\n                         geometry\n1  POLYGON ((112.0625 29.75523...\n2  POLYGON ((112.2288 29.11684...\n3  POLYGON ((111.8927 29.6013,...\n4  POLYGON ((111.3731 29.94649...\n5  POLYGON ((111.6324 29.76288...\n6  POLYGON ((110.8825 30.11675...\n7  POLYGON ((113.9905 28.5682,...\n8  POLYGON ((112.7181 28.38299...\n9  POLYGON ((112.7914 28.52688...\n10 POLYGON ((113.1757 26.82734..."
  },
  {
    "objectID": "exercises/icex08.html#contiguity-weights-rooks-method",
    "href": "exercises/icex08.html#contiguity-weights-rooks-method",
    "title": "In-Class Exercise 7: Spatial Weights and Applications",
    "section": "5.2 Contiguity Weights: Rook’s Method",
    "text": "5.2 Contiguity Weights: Rook’s Method\n\nwm_r <- hunan_GDPPC %>%\n  mutate(nb = st_contiguity(geometry, queen = FALSE),\n         wt = st_weights(nb),\n         .before = 1)\n\n\nwm_r\n\nSimple feature collection with 88 features and 8 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\nFirst 10 features:\n                           nb\n1                3, 4, 57, 85\n2              57, 58, 78, 85\n3                 1, 4, 5, 85\n4                  1, 3, 5, 6\n5                 3, 4, 6, 85\n6            4, 5, 69, 75, 85\n7              67, 71, 74, 84\n8   9, 46, 47, 56, 78, 80, 86\n9       8, 66, 68, 78, 84, 86\n10 16, 19, 20, 22, 70, 72, 73\n                                                                            wt\n1                                                       0.25, 0.25, 0.25, 0.25\n2                                                       0.25, 0.25, 0.25, 0.25\n3                                                       0.25, 0.25, 0.25, 0.25\n4                                                       0.25, 0.25, 0.25, 0.25\n5                                                       0.25, 0.25, 0.25, 0.25\n6                                                      0.2, 0.2, 0.2, 0.2, 0.2\n7                                                       0.25, 0.25, 0.25, 0.25\n8  0.1428571, 0.1428571, 0.1428571, 0.1428571, 0.1428571, 0.1428571, 0.1428571\n9             0.1666667, 0.1666667, 0.1666667, 0.1666667, 0.1666667, 0.1666667\n10 0.1428571, 0.1428571, 0.1428571, 0.1428571, 0.1428571, 0.1428571, 0.1428571\n     NAME_2  ID_3    NAME_3   ENGTYPE_3    County GDPPC\n1   Changde 21098   Anxiang      County   Anxiang 23667\n2   Changde 21100   Hanshou      County   Hanshou 20981\n3   Changde 21101    Jinshi County City    Jinshi 34592\n4   Changde 21102        Li      County        Li 24473\n5   Changde 21103     Linli      County     Linli 25554\n6   Changde 21104    Shimen      County    Shimen 27137\n7  Changsha 21109   Liuyang County City   Liuyang 63118\n8  Changsha 21110 Ningxiang      County Ningxiang 62202\n9  Changsha 21111 Wangcheng      County Wangcheng 70666\n10 Chenzhou 21112     Anren      County     Anren 12761\n                         geometry\n1  POLYGON ((112.0625 29.75523...\n2  POLYGON ((112.2288 29.11684...\n3  POLYGON ((111.8927 29.6013,...\n4  POLYGON ((111.3731 29.94649...\n5  POLYGON ((111.6324 29.76288...\n6  POLYGON ((110.8825 30.11675...\n7  POLYGON ((113.9905 28.5682,...\n8  POLYGON ((112.7181 28.38299...\n9  POLYGON ((112.7914 28.52688...\n10 POLYGON ((113.1757 26.82734..."
  },
  {
    "objectID": "exercises/icex08.html#performing-global-morans-i-test",
    "href": "exercises/icex08.html#performing-global-morans-i-test",
    "title": "In-Class Exercise 7: Spatial Weights and Applications",
    "section": "6.1 Performing Global Moran’s I Test",
    "text": "6.1 Performing Global Moran’s I Test\n\nmoranI <- global_moran(wm_q$GDPPC,\n                       wm_q$nb,\n                       wm_q$wt)\n\n\n\n\n\n\n\nNote\n\n\n\nTypically global_moran test is not run, we can just run the global_moran_test as shown below\n\n\nPerforming Global Moran I Test\n\nglobal_moran_test(wm_q$GDPPC,\n                  wm_q$nb,\n                  wm_q$wt)\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\nSince p-value < 0.05, we reject the null hypothesis. We observe clustering at the Moran I statistic is > 0."
  },
  {
    "objectID": "exercises/icex08.html#performing-global-moran-i-permutation-test",
    "href": "exercises/icex08.html#performing-global-moran-i-permutation-test",
    "title": "In-Class Exercise 7: Spatial Weights and Applications",
    "section": "6.2 Performing Global Moran I Permutation Test",
    "text": "6.2 Performing Global Moran I Permutation Test\nIn Global Moran I test, it is called permutation test, but in other cases, it might be called Monte Carlo Simulation.\nIn the code below, we set a particular seed to ensure our results are reproducible.\nIf we run nsim = 99 we are actually running 100 simulations, the more simulations, especially if observations are small, the more stable the results.\n\nset.seed(1234)\nglobal_moran_perm(wm_q$GDPPC,\n                  wm_q$nb,\n                  wm_q$wt,\n                  nsim = 99)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.30075, observed rank = 100, p-value < 2.2e-16\nalternative hypothesis: two.sided"
  },
  {
    "objectID": "exercises/icex08.html#computing-local-morans-i",
    "href": "exercises/icex08.html#computing-local-morans-i",
    "title": "In-Class Exercise 7: Spatial Weights and Applications",
    "section": "7.1 Computing Local Moran’s I",
    "text": "7.1 Computing Local Moran’s I\n\nlisa <- wm_q %>%\n  mutate(local_moran = local_moran(\n    GDPPC, nb, wt, nsim = 99),\n    .before = 1) %>%\n  unnest(local_moran)\nlisa\n\nSimple feature collection with 88 features and 20 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n# A tibble: 88 × 21\n         ii        eii   var_ii    z_ii    p_ii p_ii_…¹ p_fol…² skewn…³ kurtosis\n      <dbl>      <dbl>    <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>    <dbl>\n 1 -0.00147  0.00177    4.18e-4 -0.158  0.874      0.82    0.41  -0.812  0.652  \n 2  0.0259   0.00641    1.05e-2  0.190  0.849      0.96    0.48  -1.09   1.89   \n 3 -0.0120  -0.0374     1.02e-1  0.0796 0.937      0.76    0.38   0.824  0.0461 \n 4  0.00102 -0.0000349  4.37e-6  0.506  0.613      0.64    0.32   1.04   1.61   \n 5  0.0148  -0.00340    1.65e-3  0.449  0.654      0.5     0.25   1.64   3.96   \n 6 -0.0388  -0.00339    5.45e-3 -0.480  0.631      0.82    0.41   0.614 -0.264  \n 7  3.37    -0.198      1.41e+0  3.00   0.00266    0.08    0.04   1.46   2.74   \n 8  1.56    -0.265      8.04e-1  2.04   0.0417     0.08    0.04   0.459 -0.519  \n 9  4.42     0.0450     1.79e+0  3.27   0.00108    0.02    0.01   0.746 -0.00582\n10 -0.399   -0.0505     8.59e-2 -1.19   0.234      0.28    0.14  -0.685  0.134  \n# … with 78 more rows, 12 more variables: mean <fct>, median <fct>,\n#   pysal <fct>, nb <nb>, wt <list>, NAME_2 <chr>, ID_3 <int>, NAME_3 <chr>,\n#   ENGTYPE_3 <chr>, County <chr>, GDPPC <dbl>, geometry <POLYGON [°]>, and\n#   abbreviated variable names ¹​p_ii_sim, ²​p_folded_sim, ³​skewness\n\n\n\n\n\n\n\n\nNote\n\n\n\nunnest is necessary to be able to plot the data. unnest is to unnest the values from a list to be able to plot it on tmap\n\n\nIn general, for lisa var, the mean or pysal should be the same, we can use either to plot the graph. In general, we do not need to use median unless we are concerned about non-normality assumptions."
  },
  {
    "objectID": "exercises/icex08.html#visualising-local-morans-i",
    "href": "exercises/icex08.html#visualising-local-morans-i",
    "title": "In-Class Exercise 7: Spatial Weights and Applications",
    "section": "7.2 Visualising Local Moran’s I",
    "text": "7.2 Visualising Local Moran’s I\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(lisa) +\n  tm_fill(\"ii\") +\n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8))\n\nVariable(s) \"ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(lisa) +\n  tm_fill(\"p_ii_sim\") +\n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8))\n\n\n\n\nWe avoid using p_ii under lisa as it was not run over several simulations, we would prefer to use p_ii_sim instead.\n\nlisa_sig <- lisa %>% filter(p_ii < 0.05) # to modify code to plot non-significant values as a class itself also\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(lisa) +\n  tm_polygons() + \n  tm_borders(alpha = 0.5) +\ntm_shape(lisa_sig) +\n  tm_fill(\"mean\") +\n  tm_view(set.zoom.limits = c(6,8))\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them)."
  },
  {
    "objectID": "exercises/icex08.html#visualising-p-value-of-hcsa",
    "href": "exercises/icex08.html#visualising-p-value-of-hcsa",
    "title": "In-Class Exercise 7: Spatial Weights and Applications",
    "section": "8.1 Visualising p-value of HCSA",
    "text": "8.1 Visualising p-value of HCSA\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(HCSA) +\n  tm_fill(\"p_sim\") +\n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8))"
  },
  {
    "objectID": "exercises/In-Class_Ex05/data/stores.html",
    "href": "exercises/In-Class_Ex05/data/stores.html",
    "title": "Ren Jie's IS415 Journal",
    "section": "",
    "text": "<!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’>     \n\n\n        0 0     false"
  },
  {
    "objectID": "exercises/In-Class_Ex05/data/study_area.html",
    "href": "exercises/In-Class_Ex05/data/study_area.html",
    "title": "Ren Jie's IS415 Journal",
    "section": "",
    "text": "<!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’>     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "exercises/thex01.html",
    "href": "exercises/thex01.html",
    "title": "Take-Home Exercise 01: Water Points in Osun, Nigeria",
    "section": "",
    "text": "Water is an important resource to mankind. Clean and accessible water is critical to human health. It provides a healthy environment, a sustainable economy, reduces poverty and ensures peace and security. Yet over 40% of the global population does not have access to sufficient clean water. By 2025, 1.8 billion people will be living in countries or regions with absolute water scarcity, according to UN-Water. The lack of water poses a major threat to several sectors, including food security. Agriculture uses about 70% of the world’s accessible freshwater.\nDeveloping countries are most affected by water shortages and poor water quality. Up to 80% of illnesses in the developing world are linked to inadequate water and sanitation. Despite technological advancement, providing clean water to the rural community is still a major development issues in many countries globally, especially countries in the Africa continent.\nTo address the issue of providing clean and sustainable water supply to the rural community, a global Water Point Data Exchange (WPdx) project has been initiated. The main aim of this initiative is to collect water point related data from rural areas at the water point or small water scheme level and share the data via WPdx Data Repository, a cloud-based data library. What is so special of this project is that data are collected based on WPDx Data Standard.\n\n\n\nGeospatial analytics hold tremendous potential to address complex problems facing society. In this study, you are tasked to apply appropriate spatial point patterns analysis methods to discover the geographical distribution of functional and non-function water points and their co-locations if any in Osun State, Nigeria.\n\n\n\nThe specific tasks of this take-home exercise are as follows:\n\n\n\nDerive kernel density maps of functional and non-functional water points. Using appropriate tmap functions,\nDisplay the kernel density maps on openstreetmap of Osun State, Nigeria.\nDescribe the spatial patterns revealed by the kernel density maps. Highlight the advantage of kernel density map over point map.\n\n\n\n\nIn this section, you are required to confirm statistically if the spatial distribution of functional and non-functional water points are independent from each other.\n\nFormulate the null hypothesis and alternative hypothesis and select the confidence level.\nPerform the test by using appropriate Second order spatial point patterns analysis technique.\nWith reference to the analysis results, draw statistical conclusions."
  },
  {
    "objectID": "exercises/thex01.html#data-acquisition",
    "href": "exercises/thex01.html#data-acquisition",
    "title": "Take-Home Exercise 01: Water Points in Osun, Nigeria",
    "section": "2.1 Data Acquisition",
    "text": "2.1 Data Acquisition\nThe following datasets would be used to study the geographical distribution of water points in Osun State in Nigeria.\n\n\n\nDataset Name\nSource\n\n\n\n\nWPdx+ (wpdx_nga.csv) - Filtered by #clean_country_name from the website\nWPdx Global Data Repositories\n\n\ngeoBoundaries Nigeria Level-1 Administrative Boundary (geoBoundaries-NGA-ADM1.shp) - UN OCHA CODs\ngeoBoundaries\n\n\nHumanitarian Data Exchange Nigeria Level-1 Administrative Boundary (nga_admbnda_adm1_osgof_20190417.shp)\nHumanitarian Data Exchange\n\n\n\nwpdx_nigeria.csv has been extracted to Take-Home_Ex01/data/aspatial. The two other geospatial datasets has been extracted to Take-Home_Ex01/data/geospatial."
  },
  {
    "objectID": "exercises/thex01.html#installing-and-loading-packages",
    "href": "exercises/thex01.html#installing-and-loading-packages",
    "title": "Take-Home Exercise 01: Water Points in Osun, Nigeria",
    "section": "2.2 Installing and Loading Packages",
    "text": "2.2 Installing and Loading Packages\nNext, pacman assists us by helping us load R packages that we require, sf, tidyverse and funModeling.\n\npacman::p_load(funModeling, sf, tidyverse, tmap, maptools, spatstat, raster)\n\nThe following packages assists us to accomplish the following:\n\nfunModeling helps us with performing quick Data Exploration in R\nsf helps to import, manage and process vector-based geospatial data in R\ntidyverse which includes readr to import delimited text file, tidyr for tidying data and dplyr for wrangling data\ntmap provides functions to allow us to plot high quality static or interactive maps using leaflet API\nmaptools provides us a set of tools for manipulating geographic data\nspatstat has a wide range of functions for point pattern analysis\nraster reads, writes, manipulates, analyses and model of gridded spatial data (raster)"
  },
  {
    "objectID": "exercises/thex01.html#importing-and-comparing-datasets",
    "href": "exercises/thex01.html#importing-and-comparing-datasets",
    "title": "Take-Home Exercise 01: Water Points in Osun, Nigeria",
    "section": "3.1 Importing and Comparing Datasets",
    "text": "3.1 Importing and Comparing Datasets\nWe have two geospatial shapefiles which indicates the the Nigeria Level-1 Administrative Boundary. However, we do not know which dataset is better suited for the task. Hence, we will do some data exploration to understand more about the attributes of each shapefile.\nIn the code below, dsn specifies the filepath where the dataset is located and layer provides the filename of the dataset excluding the file extension.\n\ngeoBoundaries_NGA = st_read(dsn = \"Take-Home_Ex01/data/geospatial\", layer = \"geoBoundaries-NGA-ADM1\")\n\nReading layer `geoBoundaries-NGA-ADM1' from data source \n  `C:\\renjie-teo\\IS415-GAA\\exercises\\Take-Home_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 37 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2.668534 ymin: 4.273007 xmax: 14.67882 ymax: 13.89442\nGeodetic CRS:  WGS 84\n\n\nFrom the above message, it tells us that the dataset contains multipolygon features, containing 37 multipolygon features and 6 fields in the geoBoundaries_NGA simple feature data frame and is in the WGS84 geographic coordinates system.\nLet us check the other dataset from Humanitarian data exchange.\n\nHDX_NGA = st_read(dsn = \"Take-Home_Ex01/data/geospatial\", layer = \"nga_admbnda_adm1_osgof_20190417\")\n\nReading layer `nga_admbnda_adm1_osgof_20190417' from data source \n  `C:\\renjie-teo\\IS415-GAA\\exercises\\Take-Home_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 37 features and 12 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2.668534 ymin: 4.273007 xmax: 14.67882 ymax: 13.89442\nGeodetic CRS:  WGS 84\n\n\nFrom the above message, it tells us that the dataset contains multipolygon features, containing 37 multipolygon features and 12 fields in the HDX_NGA simple feature data frame and is in the WGS84 geographic coordinates system.\nLet us compare the fields to determine which dataset would be sufficiently useful for our analysis.\n\nhead(geoBoundaries_NGA)\n\nSimple feature collection with 6 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 5.380235 ymin: 4.273007 xmax: 13.69222 ymax: 12.52145\nGeodetic CRS:  WGS 84\n  shapeName pcode level                   shapeID shapeGroup shapeType\n1      Abia NG001  ADM1 NGA-ADM1-9716203B29245989        NGA      ADM1\n2   Adamawa NG002  ADM1 NGA-ADM1-9716203B34328871        NGA      ADM1\n3 Akwa Ibom NG003  ADM1  NGA-ADM1-9716203B9380274        NGA      ADM1\n4   Anambra NG004  ADM1 NGA-ADM1-9716203B31714231        NGA      ADM1\n5    Bauchi NG005  ADM1 NGA-ADM1-9716203B69582311        NGA      ADM1\n6   Bayelsa NG006  ADM1 NGA-ADM1-9716203B92894251        NGA      ADM1\n                        geometry\n1 MULTIPOLYGON (((7.488712 4....\n2 MULTIPOLYGON (((11.85399 7....\n3 MULTIPOLYGON (((7.488712 4....\n4 MULTIPOLYGON (((7.339063 6....\n5 MULTIPOLYGON (((8.823522 10...\n6 MULTIPOLYGON (((6.60183 4.3...\n\n\n\nhead(HDX_NGA)\n\nSimple feature collection with 6 features and 12 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 5.380235 ymin: 4.273007 xmax: 13.69222 ymax: 12.52145\nGeodetic CRS:  WGS 84\n  Shape_Leng Shape_Area   ADM1_EN ADM1_PCODE  ADM1_REF ADM1ALT1EN ADM1ALT2EN\n1   4.695135  0.3965429      Abia      NG001      Abia       <NA>       <NA>\n2  11.525443  3.1130065   Adamawa      NG002   Adamawa       <NA>       <NA>\n3   5.263830  0.5494762 Akwa Ibom      NG003 Akwa Ibom       <NA>       <NA>\n4   3.595960  0.3926608   Anambra      NG004   Anambra       <NA>       <NA>\n5  13.952005  4.0110175    Bauchi      NG005    Bauchi       <NA>       <NA>\n6   5.046708  0.7767679   Bayelsa      NG006   Bayelsa       <NA>       <NA>\n  ADM0_EN ADM0_PCODE       date    validOn validTo\n1 Nigeria         NG 2016-11-29 2019-04-17    <NA>\n2 Nigeria         NG 2016-11-29 2019-04-17    <NA>\n3 Nigeria         NG 2016-11-29 2019-04-17    <NA>\n4 Nigeria         NG 2016-11-29 2019-04-17    <NA>\n5 Nigeria         NG 2016-11-29 2019-04-17    <NA>\n6 Nigeria         NG 2016-11-29 2019-04-17    <NA>\n                        geometry\n1 MULTIPOLYGON (((7.38681 6.0...\n2 MULTIPOLYGON (((13.62129 10...\n3 MULTIPOLYGON (((8.344815 4....\n4 MULTIPOLYGON (((6.932539 6....\n5 MULTIPOLYGON (((10.75125 12...\n6 MULTIPOLYGON (((6.552828 5....\n\n\nBy comparing both datasets, the dataset from geoBoundaries is more favourable. Both tables contain similar values, such as name of state, state code and the deometry.\nHumanitarian Data Exchange contains values such as its parent (ADM0). However, ADM0 is country level and since we are only looking at Osun State which is specifically in Nigeria, this data is not very relevant to our analysis.\nThe rest of the columns are not very relevant to the analysis to be conducted. Hence, we will pick geoBoundaries which has lesser irrelevant data to reduce size of data needed to compute the analysis.\nThe code below will remove the HDX_NGA dataset as we have determined that it is no longer required for our analysis.\n\nremove(HDX_NGA)"
  },
  {
    "objectID": "exercises/thex01.html#coordinate-reference-system",
    "href": "exercises/thex01.html#coordinate-reference-system",
    "title": "Take-Home Exercise 01: Water Points in Osun, Nigeria",
    "section": "3.2 Coordinate Reference System",
    "text": "3.2 Coordinate Reference System\n\n3.2.1 Checking the Coordinate Reference System\nIn the code below, we will check if the Coordinate Reference System has been specified correctly.\n\nst_crs(geoBoundaries_NGA)\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n        MEMBER[\"World Geodetic System 1984 (Transit)\"],\n        MEMBER[\"World Geodetic System 1984 (G730)\"],\n        MEMBER[\"World Geodetic System 1984 (G873)\"],\n        MEMBER[\"World Geodetic System 1984 (G1150)\"],\n        MEMBER[\"World Geodetic System 1984 (G1674)\"],\n        MEMBER[\"World Geodetic System 1984 (G1762)\"],\n        MEMBER[\"World Geodetic System 1984 (G2139)\"],\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]],\n        ENSEMBLEACCURACY[2.0]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"geodetic latitude (Lat)\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"geodetic longitude (Lon)\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    USAGE[\n        SCOPE[\"Horizontal component of 3D system.\"],\n        AREA[\"World.\"],\n        BBOX[-90,-180,90,180]],\n    ID[\"EPSG\",4326]]\n\n\nAs seen above, the file has been configured correctly, having a WGS84 Geographic Coordinate System which maps to EPSG:4326.\n\n\n3.2.2 Converting the Coordinate Reference System\nWhat coordinate system do we utilise? Nigeria emcompasses 3 Universal Traverse Mercator (UTM) Zones, Zones 31N, 32N and 33N, each having its unique Projected Coordinate System. Let us refer to the figure below.\n\n(Sylvester O et al., 2018)\nGiven that Osun State, Nigeria, has a coordinate of 7.5629° N, 4.5200° E which falls within Zone 31N, we would use the EPSG:26391 Projected Coordinate System which Zone 31N, Minna, Nigeria West Belt, corresponds to.\nIn the code below, we will convert the Geographic Coordinate Reference System from WGS84 to EPSG:26391 Projected Coordinate System:\n\nnigeria <- st_transform(geoBoundaries_NGA, crs = 26391)\n\n\nst_crs(nigeria)\n\nCoordinate Reference System:\n  User input: EPSG:26391 \n  wkt:\nPROJCRS[\"Minna / Nigeria West Belt\",\n    BASEGEOGCRS[\"Minna\",\n        DATUM[\"Minna\",\n            ELLIPSOID[\"Clarke 1880 (RGS)\",6378249.145,293.465,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4263]],\n    CONVERSION[\"Nigeria West Belt\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",4,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",4.5,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.99975,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",230738.26,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Engineering survey, topographic mapping.\"],\n        AREA[\"Nigeria - onshore west of 6°30'E, onshore and offshore shelf.\"],\n        BBOX[3.57,2.69,13.9,6.5]],\n    ID[\"EPSG\",26391]]\n\n\nAfter running the code, we can confirm that the data frame has been converted to EPSG:26391 Projected Coordinate System.\nAfter converting to Projected Coordinated System, we no longer require the original dataset that was in the WGS84 Geographic Reference System. Let us remove it now.\n\nremove(geoBoundaries_NGA)"
  },
  {
    "objectID": "exercises/thex01.html#importing-wpdx-aspatial-data",
    "href": "exercises/thex01.html#importing-wpdx-aspatial-data",
    "title": "Take-Home Exercise 01: Water Points in Osun, Nigeria",
    "section": "4.1 Importing WPdx+ Aspatial Data",
    "text": "4.1 Importing WPdx+ Aspatial Data\nSince WPdx+ data set is in csv format, we will use read_csv() of readr package to import wpdx_nigeria.csv and output it to an R object called wpdx.\n\nwpdx <- read_csv(\"Take-Home_Ex01/data/aspatial/wpdx_nga.csv\")\n\n\nlist(wpdx)\n\n[[1]]\n# A tibble: 97,478 × 74\n   row_id `#source`      #lat_…¹ #lon_…² #repo…³ #stat…⁴ #wate…⁵ #wate…⁶ #wate…⁷\n    <dbl> <chr>            <dbl>   <dbl> <chr>   <chr>   <chr>   <chr>   <chr>  \n 1 158721 Federal Minis…    5.07    6.62 02/19/… Yes     Boreho… Well    Mechan…\n 2 158892 Federal Minis…    5.09    7.09 02/06/… Yes     Boreho… Well    Hand P…\n 3 323117 Federal Minis…    5.91    8.77 08/31/… Yes     Boreho… Well    Hand P…\n 4 300176 Federal Minis…    5.23    7.32 05/17/… Yes     Boreho… Well    Mechan…\n 5 324346 Federal Minis…    6.88    3.36 08/17/… Yes     Boreho… Well    Mechan…\n 6 297273 Federal Minis…    6.59    3.29 05/26/… Yes     Boreho… Well    Mechan…\n 7 296853 Federal Minis…    6.60    3.26 06/02/… Yes     Boreho… Well    Mechan…\n 8 323866 Federal Minis…    6.20    6.73 09/18/… Yes     Boreho… Well    Mechan…\n 9 297044 Federal Minis…    6.61    3.30 05/26/… Yes     Boreho… Well    Mechan…\n10 324321 Federal Minis…    6.96    3.60 08/16/… Yes     Boreho… Well    Mechan…\n# … with 97,468 more rows, 65 more variables: `#water_tech_category` <chr>,\n#   `#facility_type` <chr>, `#clean_country_name` <chr>, `#clean_adm1` <chr>,\n#   `#clean_adm2` <chr>, `#clean_adm3` <lgl>, `#clean_adm4` <lgl>,\n#   `#install_year` <dbl>, `#installer` <lgl>, `#rehab_year` <lgl>,\n#   `#rehabilitator` <lgl>, `#management_clean` <chr>, `#status_clean` <chr>,\n#   `#pay` <chr>, `#fecal_coliform_presence` <lgl>,\n#   `#fecal_coliform_value` <lgl>, `#subjective_quality` <chr>, …\n\n\nOur output shows our wpdx tibble data frame consists of 95,478 rows and 74 columns. The useful fields we would be paying attention to is the #lat_deg and #lon_deg columns, which are in the decimal degree format. By viewing the Data Standard on wpdx’s website, we know that the latitude and longitude is in the WGS84 Geographic Coordinate System.\n\n\n\n\n\n\nNote\n\n\n\nWhile wpdx contains all possible water points within nigeria at the moment, we still do not want to filter the data as some water points may be misclassified by state name (ie. a possible water point may be classified under an adjacent state name but physically is located in one state). We will filter the unrelated water points at a later stage.\n\n\n\n4.1.1 Creating a Simple Feature Data Frame from an Aspatial Data Frame\nAs the geometry is available in wkt in the column New Georeferenced Column, we can use st_as_sfc() to import the geometry\n\nwpdx$Geometry <- st_as_sfc(wpdx$`New Georeferenced Column`)\n\nAs there is no spatial data information, firstly, we assign the original projection when converting the tibble dataframe to sf. The original is wgs84 which is EPSG:4326.\n\nwpdx <- st_sf(wpdx, crs=4326)\n\nNext, we then convert the projection to the appropriate decimal based projection system. As discussed earlier, we utilise the EPSG:26391 Projected Coordinate System as Osun falls under Minna, Nigeria West Belt.\n\nwpdx <- wpdx %>%\n  st_transform(crs = 26391)\n\n\nwpdx\n\nSimple feature collection with 97478 features and 74 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 32536.82 ymin: 33461.24 xmax: 1292096 ymax: 1091052\nProjected CRS: Minna / Nigeria West Belt\n# A tibble: 97,478 × 75\n   row_id `#source`      #lat_…¹ #lon_…² #repo…³ #stat…⁴ #wate…⁵ #wate…⁶ #wate…⁷\n *  <dbl> <chr>            <dbl>   <dbl> <chr>   <chr>   <chr>   <chr>   <chr>  \n 1 158721 Federal Minis…    5.07    6.62 02/19/… Yes     Boreho… Well    Mechan…\n 2 158892 Federal Minis…    5.09    7.09 02/06/… Yes     Boreho… Well    Hand P…\n 3 323117 Federal Minis…    5.91    8.77 08/31/… Yes     Boreho… Well    Hand P…\n 4 300176 Federal Minis…    5.23    7.32 05/17/… Yes     Boreho… Well    Mechan…\n 5 324346 Federal Minis…    6.88    3.36 08/17/… Yes     Boreho… Well    Mechan…\n 6 297273 Federal Minis…    6.59    3.29 05/26/… Yes     Boreho… Well    Mechan…\n 7 296853 Federal Minis…    6.60    3.26 06/02/… Yes     Boreho… Well    Mechan…\n 8 323866 Federal Minis…    6.20    6.73 09/18/… Yes     Boreho… Well    Mechan…\n 9 297044 Federal Minis…    6.61    3.30 05/26/… Yes     Boreho… Well    Mechan…\n10 324321 Federal Minis…    6.96    3.60 08/16/… Yes     Boreho… Well    Mechan…\n# … with 97,468 more rows, 66 more variables: `#water_tech_category` <chr>,\n#   `#facility_type` <chr>, `#clean_country_name` <chr>, `#clean_adm1` <chr>,\n#   `#clean_adm2` <chr>, `#clean_adm3` <lgl>, `#clean_adm4` <lgl>,\n#   `#install_year` <dbl>, `#installer` <lgl>, `#rehab_year` <lgl>,\n#   `#rehabilitator` <lgl>, `#management_clean` <chr>, `#status_clean` <chr>,\n#   `#pay` <chr>, `#fecal_coliform_presence` <lgl>,\n#   `#fecal_coliform_value` <lgl>, `#subjective_quality` <chr>, …"
  },
  {
    "objectID": "exercises/thex01.html#excluding-redundant-fields",
    "href": "exercises/thex01.html#excluding-redundant-fields",
    "title": "Take-Home Exercise 01: Water Points in Osun, Nigeria",
    "section": "5.1 Excluding Redundant Fields",
    "text": "5.1 Excluding Redundant Fields\nAs the nigeria sf dataframe consist of many redundant field, we use select() to select the fields which we want to retain. In our case, we will only retain the shapeName (State Name), pCode (State Code), shapeType (ADM Level) and geometry fields.\n\nnigeria <- nigeria %>%\n  dplyr::select(c(0:2, 6))"
  },
  {
    "objectID": "exercises/thex01.html#checking-for-duplicated-state-names",
    "href": "exercises/thex01.html#checking-for-duplicated-state-names",
    "title": "Take-Home Exercise 01: Water Points in Osun, Nigeria",
    "section": "5.2 Checking for Duplicated State Names",
    "text": "5.2 Checking for Duplicated State Names\nIt is important to check for duplicate name in the data main data fields. Using duplicated(), we can flag out state names that might be duplicated as shown below:\n\nnigeria$ADM1_EN[duplicated(nigeria$ADM1_EN) == TRUE]\n\nNULL\n\n\nGreat! There are no duplicate state names.\nSince our analysis is focused specifically on Osun state of Nigeria, we will extract the attributes related to Osun state into a new variable called nigeria_osun for further analysis.\n\nnigeria_osun <- nigeria %>% filter(shapeName == \"Osun\")"
  },
  {
    "objectID": "exercises/thex01.html#understanding-field-names",
    "href": "exercises/thex01.html#understanding-field-names",
    "title": "Take-Home Exercise 01: Water Points in Osun, Nigeria",
    "section": "6.1 Understanding Field Names",
    "text": "6.1 Understanding Field Names\nFirst, let us have a look at the #status_clean column which stores the information about Functional and Non-Functional data points. The code below returns all values that were used in the column.\n\nfunModeling::freq(data = wpdx,\n     input = '#status_clean')\n\n\n\n\n                      #status_clean frequency percentage cumulative_perc\n1                        Functional     47228      48.45           48.45\n2                    Non-Functional     30638      31.43           79.88\n3                              <NA>     10154      10.42           90.30\n4          Functional, needs repair      4792       4.92           95.22\n5               Non-Functional, dry      2473       2.54           97.76\n6            Functional, not in use      1775       1.82           99.58\n7          Abandoned/Decommissioned       321       0.33           99.91\n8         Functional but not in use        86       0.09          100.00\n9  Non-Functional due to dry season         7       0.01          100.01\n10      Functional but needs repair         4       0.00          100.00\n\n\nAs there might be issues performing mathematical calculations with NA labels, we will rename them to unknown.\nThe code below renames the column #status_clean to status_clean, select only the status_clean for manipulation and then replace all NA values to unknown.\n\nwpdx <- wpdx %>%\n  rename(status_clean = '#status_clean') %>%\n  dplyr::select(status_clean) %>%\n  mutate(status_clean = replace_na(status_clean, \"unknown\"))"
  },
  {
    "objectID": "exercises/thex01.html#filtering-data",
    "href": "exercises/thex01.html#filtering-data",
    "title": "Take-Home Exercise 01: Water Points in Osun, Nigeria",
    "section": "6.2 Filtering Data",
    "text": "6.2 Filtering Data\nFirstly, since the wpdx dataset contains all data from all Nigeria states which is not required, let us use st_intersection() to filter out the unnecessary datapoints for our analysis. Using the code below, we keep points that are within nigeria_osun’s state boundary.\n\n\n\n\n\n\nNote\n\n\n\nPreviously, we mentioned that some points may be misclassified as within a certain state but its coordinates may fall under another state. This method ensures that water points with its coordinates fall within the correct state boundary!\n\n\n\nwpdx <- st_intersection(wpdx, nigeria_osun)\n\nWith our previous knowledge, we can filter the data to obtain three main groups, Functional, Non-Functional and Unknown water points.\n\nwpdx <- wpdx %>% \n  mutate(status_clean = recode(status_clean, \n                         `Functional but not in use` = 'Functional',\n                         `Functional, not in use` = 'Functional', \n                         `Functional, needs repair` =  'Functional',  \n                         `Abandoned/Decommissioned` = \"Non-Functional\",\n                         `Non-Functional, dry` = \"Non-Functional\"))\n\n\nwpdx_func <- wpdx %>% \n  filter(status_clean %in% \n           c(\"Functional\", \n             \"Functional but not in use\", \n             \"Functional, not in use\",\n             \"Functional, needs repair\"))\nwpdx_nonfunc <- wpdx %>% \n  filter(status_clean %in%\n          c(\"Abandoned/Decommissioned\", \n            \"Non-Functional\",\n            \"Non-Functional, dry\"))\nwpdx_unknown <- wpdx %>%\n  filter(status_clean == \"unknown\")\nwpdx_excl_unknown <- wpdx %>%\n  filter(status_clean != \"unknown\")"
  },
  {
    "objectID": "exercises/thex01.html#plotting-map-of-water-points",
    "href": "exercises/thex01.html#plotting-map-of-water-points",
    "title": "Take-Home Exercise 01: Water Points in Osun, Nigeria",
    "section": "6.3 Plotting Map of Water Points",
    "text": "6.3 Plotting Map of Water Points\nUsing tmap, we can quickly plot a map of where the Functional, Non-Functional and Unknown water points are. We have plotted an interactive map which uses Openstreetmaps as its base layer so we can view each point’s location in relation to where roads, rivers, etc. are.\n\ntmap_mode('view')\ntm_basemap(server = \"OpenStreetMap\") +\ntm_shape(nigeria_osun) +\n  tm_polygons(alpha = 0.2) +\ntm_shape(wpdx) +\n  tm_dots(\"status_clean\", \n          alpha = 0.4,\n          size = 0.05,\n          palette = c(\"darkolivegreen2\", \"brown2\", \"cadetblue\"))\n\n\n\n\n\n\nWith the help of Openstreetmaps base map, from a quick glance, it seems that water points are typically located near roads. There is more water points in certain areas, which could be attributed to being closer to urban centers or residential areas, given the denser layouts of roads.\nIn larger urban areas such as Osogobo in Osun, Nigeria, we can see clearly that there is a greater proportion of water points closer towards the centre of town.\nHowever, it is hard for us to see the density of functional and non-functional water points from this map."
  },
  {
    "objectID": "exercises/thex01.html#converting-sf-dataframes-to-sps-spatial-class",
    "href": "exercises/thex01.html#converting-sf-dataframes-to-sps-spatial-class",
    "title": "Take-Home Exercise 01: Water Points in Osun, Nigeria",
    "section": "7.1 Converting sf Dataframes to sp’s Spatial* Class",
    "text": "7.1 Converting sf Dataframes to sp’s Spatial* Class\nWhile simple feature data frame is gaining in popularity, many geospatial analysis packages still require the input geospatial data in sp’s Spatial* classes. We will convert the sf data frames to sp’s Spatial* Class below.\n\nnigeria_osun_spat <- as_Spatial(nigeria_osun)\nwpdx_spat <- as_Spatial(wpdx)\nwpdx_func_spat <- as_Spatial(wpdx_func)\nwpdx_nonfunc_spat <- as_Spatial(wpdx_nonfunc)\nwpdx_excl_unknown_spat <- as_Spatial(wpdx_excl_unknown)\n\nNow, let’s view the information of the Spatial* classes below:\n\nnigeria_osun_spat\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 1 \nextent      : 178398.7, 292278.9, 329463.4, 452734.9  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=4 +lon_0=4.5 +k=0.99975 +x_0=230738.26 +y_0=0 +a=6378249.145 +rf=293.465 +towgs84=-92,-93,122,0,0,0,0 +units=m +no_defs \nvariables   : 3\nnames       : shapeName, pcode, shapeType \nvalue       :      Osun, NG030,      ADM1 \n\n\n\nwpdx_spat\n\nclass       : SpatialPointsDataFrame \nfeatures    : 5688 \nextent      : 178980.8, 291989.5, 338261.8, 449013.7  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=4 +lon_0=4.5 +k=0.99975 +x_0=230738.26 +y_0=0 +a=6378249.145 +rf=293.465 +towgs84=-92,-93,122,0,0,0,0 +units=m +no_defs \nvariables   : 4\nnames       : status_clean, shapeName, pcode, shapeType \nmin values  :   Functional,      Osun, NG030,      ADM1 \nmax values  :      unknown,      Osun, NG030,      ADM1 \n\n\n\nwpdx_func_spat\n\nclass       : SpatialPointsDataFrame \nfeatures    : 2740 \nextent      : 184202.3, 291989.5, 340352.2, 449013.7  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=4 +lon_0=4.5 +k=0.99975 +x_0=230738.26 +y_0=0 +a=6378249.145 +rf=293.465 +towgs84=-92,-93,122,0,0,0,0 +units=m +no_defs \nvariables   : 4\nnames       : status_clean, shapeName, pcode, shapeType \nmin values  :   Functional,      Osun, NG030,      ADM1 \nmax values  :   Functional,      Osun, NG030,      ADM1 \n\n\n\nwpdx_nonfunc_spat\n\nclass       : SpatialPointsDataFrame \nfeatures    : 2189 \nextent      : 184218.5, 291855.5, 338261.8, 448933.5  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=4 +lon_0=4.5 +k=0.99975 +x_0=230738.26 +y_0=0 +a=6378249.145 +rf=293.465 +towgs84=-92,-93,122,0,0,0,0 +units=m +no_defs \nvariables   : 4\nnames       :   status_clean, shapeName, pcode, shapeType \nmin values  : Non-Functional,      Osun, NG030,      ADM1 \nmax values  : Non-Functional,      Osun, NG030,      ADM1 \n\n\n\nwpdx_excl_unknown_spat\n\nclass       : SpatialPointsDataFrame \nfeatures    : 4929 \nextent      : 184202.3, 291989.5, 338261.8, 449013.7  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=4 +lon_0=4.5 +k=0.99975 +x_0=230738.26 +y_0=0 +a=6378249.145 +rf=293.465 +towgs84=-92,-93,122,0,0,0,0 +units=m +no_defs \nvariables   : 4\nnames       :   status_clean, shapeName, pcode, shapeType \nmin values  :     Functional,      Osun, NG030,      ADM1 \nmax values  : Non-Functional,      Osun, NG030,      ADM1 \n\n\nNow, they have been correctly converted into sp’s Spatial* classes."
  },
  {
    "objectID": "exercises/thex01.html#converting-the-spatial-class-into-generic-sp-format",
    "href": "exercises/thex01.html#converting-the-spatial-class-into-generic-sp-format",
    "title": "Take-Home Exercise 01: Water Points in Osun, Nigeria",
    "section": "7.2 Converting the Spatial* Class into Generic sp Format",
    "text": "7.2 Converting the Spatial* Class into Generic sp Format\nspstat requires the analytical data to be in ppp object form. As there is no direct method to convert Spatial* classes to ppp object, we need to convert the Spatial* classes into an intermediate Spatial object first.\nThe code below converts Spatial* Classes into generic sp objects\n\nnigeria_osun_sp <- as(nigeria_osun_spat, \"SpatialPolygons\")\nwpdx_sp <- as(wpdx_spat, \"SpatialPoints\")\nwpdx_func_sp <- as(wpdx_func_spat, \"SpatialPoints\")\nwpdx_nonfunc_sp <- as(wpdx_nonfunc_spat, \"SpatialPoints\")\n\nNext, we can check the sp object properties.\n\nnigeria_osun_sp\n\nclass       : SpatialPolygons \nfeatures    : 1 \nextent      : 178398.7, 292278.9, 329463.4, 452734.9  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=4 +lon_0=4.5 +k=0.99975 +x_0=230738.26 +y_0=0 +a=6378249.145 +rf=293.465 +towgs84=-92,-93,122,0,0,0,0 +units=m +no_defs \n\n\n\nwpdx_sp\n\nclass       : SpatialPoints \nfeatures    : 5688 \nextent      : 178980.8, 291989.5, 338261.8, 449013.7  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=4 +lon_0=4.5 +k=0.99975 +x_0=230738.26 +y_0=0 +a=6378249.145 +rf=293.465 +towgs84=-92,-93,122,0,0,0,0 +units=m +no_defs \n\n\n\nwpdx_func_sp\n\nclass       : SpatialPoints \nfeatures    : 2740 \nextent      : 184202.3, 291989.5, 340352.2, 449013.7  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=4 +lon_0=4.5 +k=0.99975 +x_0=230738.26 +y_0=0 +a=6378249.145 +rf=293.465 +towgs84=-92,-93,122,0,0,0,0 +units=m +no_defs \n\n\n\nwpdx_nonfunc_sp\n\nclass       : SpatialPoints \nfeatures    : 2189 \nextent      : 184218.5, 291855.5, 338261.8, 448933.5  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=4 +lon_0=4.5 +k=0.99975 +x_0=230738.26 +y_0=0 +a=6378249.145 +rf=293.465 +towgs84=-92,-93,122,0,0,0,0 +units=m +no_defs \n\n\nComparing the sp object and Spatial* Classes, the variables, names, min and max values are omitted from the sp object but present in Spatial* Classes."
  },
  {
    "objectID": "exercises/thex01.html#converting-the-generic-sp-format-into-spatstats-ppp-format",
    "href": "exercises/thex01.html#converting-the-generic-sp-format-into-spatstats-ppp-format",
    "title": "Take-Home Exercise 01: Water Points in Osun, Nigeria",
    "section": "7.3 Converting the Generic sp Format into spatstat’s ppp Format",
    "text": "7.3 Converting the Generic sp Format into spatstat’s ppp Format\nNow, we will use as.ppp() function of spatstat to convert the spatial data into spatstat’s ppp object format.\n\nwpdx_ppp <- as(wpdx_sp, \"ppp\")\nwpdx_func_ppp <- as(wpdx_func_sp, \"ppp\")\nwpdx_nonfunc_ppp <- as(wpdx_nonfunc_sp, \"ppp\")\nwpdx_ppp\n\nPlanar point pattern: 5688 points\nwindow: rectangle = [178980.78, 291989.51] x [338261.8, 449013.7] units\n\nwpdx_func_ppp\n\nPlanar point pattern: 2740 points\nwindow: rectangle = [184202.32, 291989.51] x [340352.2, 449013.7] units\n\nwpdx_nonfunc_ppp\n\nPlanar point pattern: 2189 points\nwindow: rectangle = [184218.48, 291855.52] x [338261.8, 448933.5] units\n\n\nWe can take a quick look at the summary statistics of the newly created ppp object by using the code below:\n\nsummary(wpdx_ppp)\n\nPlanar point pattern:  5688 points\nAverage intensity 4.544604e-07 points per square unit\n\nCoordinates are given to 2 decimal places\ni.e. rounded to the nearest multiple of 0.01 units\n\nWindow: rectangle = [178980.78, 291989.51] x [338261.8, 449013.7] units\n                    (113000 x 110800 units)\nWindow area = 12515900000 square units\n\nsummary(wpdx_func_ppp)\n\nPlanar point pattern:  2740 points\nAverage intensity 2.339417e-07 points per square unit\n\nCoordinates are given to 2 decimal places\ni.e. rounded to the nearest multiple of 0.01 units\n\nWindow: rectangle = [184202.32, 291989.51] x [340352.2, 449013.7] units\n                    (107800 x 108700 units)\nWindow area = 11712300000 square units\n\nsummary(wpdx_nonfunc_ppp)\n\nPlanar point pattern:  2189 points\nAverage intensity 1.837584e-07 points per square unit\n\nCoordinates are given to 2 decimal places\ni.e. rounded to the nearest multiple of 0.01 units\n\nWindow: rectangle = [184218.48, 291855.52] x [338261.8, 448933.5] units\n                    (107600 x 110700 units)\nWindow area = 11912400000 square units\n\n\nNote the warning message about duplicates. The statistical methodology used for spatial points pattern processes is based largely on the assumption that processes are simple, that means that the points cannot be coincident."
  },
  {
    "objectID": "exercises/thex01.html#handling-duplicated-points",
    "href": "exercises/thex01.html#handling-duplicated-points",
    "title": "Take-Home Exercise 01: Water Points in Osun, Nigeria",
    "section": "7.4 Handling duplicated points",
    "text": "7.4 Handling duplicated points\nWe can check the duplication in wpdx ppp object using the code below:\nWe can check the main wpdx_ppp as it is a superset of events consisting of Functional, Non-Functional and Unknown Water Points\n\nany(duplicated(wpdx_ppp))\n\n[1] FALSE\n\n\nThe code tells us that there is no duplication of two or more water points at one specific coordinate-pair."
  },
  {
    "objectID": "exercises/thex01.html#creating-owin-object",
    "href": "exercises/thex01.html#creating-owin-object",
    "title": "Take-Home Exercise 01: Water Points in Osun, Nigeria",
    "section": "7.5 Creating owin object",
    "text": "7.5 Creating owin object\nWhen analysing spatial point patterns, it is good practice to confine the analysis with a geographical area like Singapore boundary. In spatstat, an object called owin is specially designed to represent this polygonal region.\nThe code chunk below is used to convert the sp SpatialPolygon object into owin object of spatstat.\n\nnigeria_osun_owin <- as(nigeria_osun_sp, \"owin\")\n\nThe output object can be displayed by using plot() function.\n\nplot(nigeria_osun_owin)\n\n\n\n\nand summary() function of Base R.\n\nsummary(nigeria_osun_owin)\n\nWindow: polygonal boundary\nsingle connected closed polygon with 641 vertices\nenclosing rectangle: [178398.73, 292278.89] x [329463.4, 452734.9] units\n                     (113900 x 123300 units)\nWindow area = 8594710000 square units\nFraction of frame area: 0.612"
  },
  {
    "objectID": "exercises/thex01.html#combining-point-events-object-and-owin-object",
    "href": "exercises/thex01.html#combining-point-events-object-and-owin-object",
    "title": "Take-Home Exercise 01: Water Points in Osun, Nigeria",
    "section": "7.6 Combining Point Events Object and owin Object",
    "text": "7.6 Combining Point Events Object and owin Object\nIn this last step of geospatial data wrangling, we will extract waterpoints events that are located within Osun using the code below\n\nwpdx_ppp = wpdx_ppp[nigeria_osun_owin]\nwpdx_func_ppp = wpdx_func_ppp[nigeria_osun_owin]\nwpdx_nonfunc_ppp = wpdx_nonfunc_ppp[nigeria_osun_owin]\n\nThe output object combined both the point and polygon feature in one ppp object class as shown below.\n\nsummary(wpdx_ppp)\n\nPlanar point pattern:  5688 points\nAverage intensity 6.618021e-07 points per square unit\n\nCoordinates are given to 2 decimal places\ni.e. rounded to the nearest multiple of 0.01 units\n\nWindow: polygonal boundary\nsingle connected closed polygon with 641 vertices\nenclosing rectangle: [178398.73, 292278.89] x [329463.4, 452734.9] units\n                     (113900 x 123300 units)\nWindow area = 8594710000 square units\nFraction of frame area: 0.612\n\n\n\nplot(wpdx_ppp)"
  },
  {
    "objectID": "exercises/thex01.html#kernel-density-estimation",
    "href": "exercises/thex01.html#kernel-density-estimation",
    "title": "Take-Home Exercise 01: Water Points in Osun, Nigeria",
    "section": "8.1 Kernel Density Estimation",
    "text": "8.1 Kernel Density Estimation\n\n8.1.1 Rescaling KDE Values\nUsing the rescale() function, we can convert the unit of measurement from metres to kilometres.\n\nwpdx_ppp.km <- rescale(wpdx_ppp, 1000, \"km\")\nwpdx_func_ppp.km <- rescale(wpdx_func_ppp, 1000, \"km\")\nwpdx_nonfunc_ppp.km <- rescale(wpdx_nonfunc_ppp, 1000, \"km\")\n\n\n\n8.1.2 Computing KDE by using Adaptive Bandwidth\nThe fixed bandwidth method is very sensitive to highly skewed distribution of spatial point patterns over geographical units (eg. urban vs rural). These helps us in the case of Osun where there are more urbanised and rural areas which we can see from the Openstreetmap above.\nWe can use density.adaptive() to derive adaptive kernel density estimation\n\nkde_wpdx <- adaptive.density(wpdx_ppp.km, method = \"kernel\")\nkde_wpdx_func <- adaptive.density(wpdx_func_ppp.km, method = \"kernel\")\nkde_wpdx_nonfunc <- adaptive.density(wpdx_nonfunc_ppp.km, method = \"kernel\")\n\n\n\n8.1.3 Converting KDE Output into Grid Object\nThe results are the same, but the conversion allows us to use it for mapping purposes.\n\ngridded_kde_wpdx <- as.SpatialGridDataFrame.im(kde_wpdx)\ngridded_kde_wpdx_func <- as.SpatialGridDataFrame.im(kde_wpdx_func)\ngridded_kde_wpdx_nonfunc <- as.SpatialGridDataFrame.im(kde_wpdx_nonfunc)\n\n\n8.1.3.1 Converting Gridded Output into Raster\nNext, we will convert gridded kernel density objects into RasterLayer object using raster() of the raster object.\n\nkde_wpdx_raster <- raster(gridded_kde_wpdx)\nkde_wpdx_func_raster <- raster(gridded_kde_wpdx_func)\nkde_wpdx_nonfunc_raster <- raster(gridded_kde_wpdx_nonfunc)\n\nWe can view the properties of kde_childcareSG_bw_raster RasterLayer\n\nkde_wpdx_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.8896887, 0.9630582  (x, y)\nextent     : 178.3987, 292.2789, 329.4634, 452.7349  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : v \nvalues     : -1.256255e-15, 43.45513  (min, max)\n\n\nNote that the CRS property is NA.\n\n\n8.1.3.2 Assigning Projection Systems\nThe code below will be used to include CRS information.\n\nprojection(kde_wpdx_raster) <- CRS(\"+init=EPSG:26391 +units=km\")\nprojection(kde_wpdx_func_raster) <- CRS(\"+init=EPSG:26391 +units=km\")\nprojection(kde_wpdx_nonfunc_raster) <- CRS(\"+init=EPSG:26391 +units=km\")\nkde_wpdx_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.8896887, 0.9630582  (x, y)\nextent     : 178.3987, 292.2789, 329.4634, 452.7349  (xmin, xmax, ymin, ymax)\ncrs        : +proj=tmerc +lat_0=4 +lon_0=4.5 +k=0.99975 +x_0=230738.26 +y_0=0 +a=6378249.145 +rf=293.465 +units=km +no_defs \nsource     : memory\nnames      : v \nvalues     : -1.256255e-15, 43.45513  (min, max)\n\n\nNote that the CRS property has been included. We also include the units so that the map knows how to plot the raster based on the values later."
  },
  {
    "objectID": "exercises/thex01.html#visualising-output-in-tmap",
    "href": "exercises/thex01.html#visualising-output-in-tmap",
    "title": "Take-Home Exercise 01: Water Points in Osun, Nigeria",
    "section": "8.2 Visualising Output in tmap",
    "text": "8.2 Visualising Output in tmap\nWe can finally display the raster using tmap\n\n8.2.1 Kernel Density Estimate (KDE) of All Water Points\n\ntmap_mode('view')\ntm_basemap(server = \"OpenStreetMap\") +\ntm_shape(kde_wpdx_raster) + \n  tm_raster(\"v\",\n            title = \"No. of Water Points\",\n            alpha = 0.6,\n            palette = c(\"#eff3ff\",\"#bdd7e7\",\"#6baed6\",\"#3182bd\",\"#08519c\"))\n\n\n\n\n\nNote that the raster values are encoded explicitly onto the raster pixel using the values in the “v” field.\n\n\n8.2.2 Kernel Density Estimate (KDE) of Functional and Non-Functional Water Points\n\ntmap_mode('view')\nfunc_map <- tm_basemap(server = \"OpenStreetMap\") +\n              tm_shape(kde_wpdx_func_raster) + \n                tm_raster(\"v\",\n                          title = \"No. of Functional Water Points\",\n                          alpha = 0.6,\n                          palette = c(\"#edf8e9\",\"#c7e9c0\",\"#a1d99b\",\"#74c476\",\"#31a354\", \"#006d2c\"))\n\nnonfunc_map <- tm_basemap(server = \"OpenStreetMap\") +\n              tm_shape(kde_wpdx_nonfunc_raster) + \n                tm_raster(\"v\",\n                          title = \"No. of Non-Functional Water Points\",\n                          alpha = 0.6,\n                          palette = c(\"#fee5d9\",\"#fcae91\",\"#fb6a4a\",\"#de2d26\",\"#a50f15\")) \n\n\ntmap_arrange(func_map, nonfunc_map)\n\n\n\n\n\n\n\n\n\n\n\n\nBy comparing the Functional and Non-Functional Water Points KDE Map, we can see that where places have a higher functional water points, it is usually the case to have similar numbers of non-functional water points.\n\n\n\n\n\n\nTip\n\n\n\nKDE Plots makes it easier to see the density of features, a darker shade could imply that there are more occurences of events within that area. A point map would only show individual events and it is hard to pinpoint the density of points within the area if there are many events."
  },
  {
    "objectID": "exercises/thex01.html#analysing-spatial-point-process-using-l-function",
    "href": "exercises/thex01.html#analysing-spatial-point-process-using-l-function",
    "title": "Take-Home Exercise 01: Water Points in Osun, Nigeria",
    "section": "9.1 Analysing Spatial Point Process Using L-Function",
    "text": "9.1 Analysing Spatial Point Process Using L-Function\nIn this section, we will use Lest() of spatstat to compute L Function estimation and also perform Monte Carlo simulation test using envelope() of spatstat.\n\n9.1.1 All Water Points\n\n9.1.1.1 Computing L Function Estimation\nUsing the code below, we run the L-Function estimation using the Ripley correlation to perform edge correction and plot the graph for our initial analysis.\n\nL_wpdx = Lest(wpdx_ppp, correction = \"Ripley\")\nplot(L_wpdx, . -r ~ r, \n     ylab= \"L(d)-r\", xlab = \"d(m)\")\n\n\n\n\nFrom the L function graph, we can see that there are signs of spatial clustering for all water points at all distances since Lobs(r) > Ltheo(r). However, we would require to perform a Monte Carlo simulation of events to statistically conclude if functional and non-functional water points are significant.\n\n\n9.1.1.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, we will conduct a hypothesis test. The hypothesis and test are shown below:\n\nHo = The distribution of water points in Osun, Nigeria are randomly distributed.\nH1= The distribution of water points in Osun, Nigeria are not randomly distributed.\n\nThe null hypothesis will be rejected if p-value if smaller than alpha value of 0.05 (confidence interval of 95%).\nThe code chunk below is used to perform the hypothesis testing.\n\n\n\n\n\n\nNote\n\n\n\nWe have set to not evaluate the simulation on render. The code below is to run the simulation, save it to an RDS file so it can be imported on render to be plotted as a graph\n\n\n\nL_wpdx.csr <- envelope(wpdx_ppp, Lest, nsim = 39, rank = 1, glocal=TRUE)\n\n\n#saveRDS(L_wpdx.csr, \"Take-Home_Ex01/data/rds/L_wpdx_csr.rds\")\n\n\nL_wpdx.csr <- readRDS(\"Take-Home_Ex01/data/rds/L_wpdx_csr.rds\")\n\n\nplot(L_wpdx.csr, . - r ~ r, xlab=\"d\", ylab=\"L(d)-r\")\n\n\n\n\nFrom the graph above, for all distances, L(r) - r for water points in Osun, Nigeria are above 0 and lies outside of the lower and higher confidence interval envelope.\nHence, from this observation, since L(r) - r is outside the higher confidence interval envelope, we havesufficient evidence to reject the null hypothesis that The distribution of water points in Osun, Nigeria are randomly distributed.\nSince L(r) - r > 0, it indicates that the observed distribution is geographically concentrated.\n\n\n\n9.1.2 Functional Water Points\n\n9.1.2.1 Computing L Function Estimation\nUsing the code below, we run the L-Function estimation using the Ripley correlation to perform edge correction and plot the graph for our initial analysis.\n\nL_func = Lest(wpdx_func_ppp, correction = \"Ripley\")\nplot(L_func, . -r ~ r, \n     ylab= \"L(d)-r\", xlab = \"d(m)\")\n\n\n\n\nFrom the L function graph, we can see that there are signs of spatial clustering for all water points at all distances since Lobs(r) > Ltheo(r). However, we would require to perform a Monte Carlo simulation of events to statistically conclude if functional water points are significant.\n\n\n9.1.2.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, we will conduct a hypothesis test. The hypothesis and test are shown below:\n\nHo = The distribution of functional water points in Osun, Nigeria are randomly distributed.\nH1= The distribution of functional water points in Osun, Nigeria are not randomly distributed.\n\nThe null hypothesis will be rejected if p-value if smaller than alpha value of 0.05 (confidence interval of 95%).\nThe code chunk below is used to perform the hypothesis testing.\n\n\n\n\n\n\nNote\n\n\n\nWe have set to not evaluate the simulation on render. The code below is to run the simulation, save it to an RDS file so it can be imported on render to be plotted as a graph\n\n\n\nL_func.csr <- envelope(wpdx_func_ppp, Lest, nsim = 39, rank = 1, glocal=TRUE)\n\n\n#saveRDS(L_func.csr, \"Take-Home_Ex01/data/rds/L_func_csr.rds\")\n\n\nL_func.csr <- readRDS(\"Take-Home_Ex01/data/rds/L_func_csr.rds\")\n\n\nplot(L_func.csr, . - r ~ r, xlab=\"d\", ylab=\"L(d)-r\")\n\n\n\n\nFrom the graph above, for all distances, L(r) - r for functional water points in Osun, Nigeria are above 0 and lies outside of the lower and higher confidence interval envelope.\nHence, from this observation, since L(r) - r is outside the higher confidence interval envelope, we have sufficient evidence to reject the null hypothesis that The distribution of functional water points in Osun, Nigeria are randomly distributed.\nSince L(r) - r > 0, it indicates that the observed distribution is geographically concentrated.\n\n\n\n9.1.3 Non-Functional Water Points\n\n9.1.3.1 Computing L Function Estimation\nUsing the code below, we run the L-Function estimation using the Ripley correlation to perform edge correction and plot the graph for our initial analysis.\n\nL_nonfunc = Lest(wpdx_nonfunc_ppp, correction = \"Ripley\")\nplot(L_nonfunc, . -r ~ r, \n     ylab= \"L(d)-r\", xlab = \"d(m)\")\n\n\n\n\nFrom the L function graph, we can see that there are signs of spatial clustering for non-functional water points at all distances since Lobs(r) > Ltheo(r). However, we would require to perform a Monte Carlo simulation of events to statistically conclude if non-functional water points are significant.\n\n\n9.1.3.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, we will conduct a hypothesis test. The hypothesis and test are shown below:\n\nHo = The distribution of non-functional water points in Osun, Nigeria are randomly distributed.\nH1= The distribution of non-functional water points in Osun, Nigeria are not randomly distributed.\n\nThe null hypothesis will be rejected if p-value if smaller than alpha value of 0.05 (confidence interval of 95%).\nThe code chunk below is used to perform the hypothesis testing.\n\n\n\n\n\n\nNote\n\n\n\nWe have set to not evaluate the simulation on render. The code below is to run the simulation, save it to an RDS file so it can be imported on render to be plotted as a graph\n\n\n\nL_nonfunc.csr <- envelope(wpdx_nonfunc_ppp, Lest, nsim = 39, rank = 1, glocal=TRUE)\n\n\n#saveRDS(L_ck.csr, \"Take-Home_Ex01/data/rds/L_nonfunc.rds\")\n\n\nL_nonfunc.csr <- readRDS(\"Take-Home_Ex01/data/rds/L_nonfunc.rds\")\n\n\nplot(L_nonfunc.csr, . - r ~ r, xlab=\"d\", ylab=\"L(d)-r\")\n\n\n\n\nFrom the graph above, for all distances, L(r) - r for non-functional water points in Osun, Nigeria are above 0 and lies outside of the lower and higher confidence interval envelope.\nHence, from this observation, since L(r) - r is outside the higher confidence interval envelope, we have sufficient evidence to reject the null hypothesis that The distribution of non-functional water points in Osun, Nigeria are randomly distributed.\nSince L(r) - r > 0, it indicates that the observed non-functional water point distribution is geographically concentrated."
  },
  {
    "objectID": "exercises/thex02.html",
    "href": "exercises/thex02.html",
    "title": "Take-Home Exercise 02: Spatio-Temporal Analysis of COVID-19 Vaccination Trends in Jarkata",
    "section": "",
    "text": "Since late December 2019, an outbreak of a novel coronavirus disease (COVID-19; previously known as 2019-nCoV) was reported in Wuhan, China, which had subsequently affected 210 countries worldwide. In general, COVID-19 is an acute resolved disease but it can also be deadly, with a 2% case fatality rate.\nThe COVID-19 vaccination in Indonesia is an ongoing mass immunisation in response to the COVID-19 pandemic in Indonesia. On 13 January 2021, the program commenced when President Joko Widodo was vaccinated at the presidential palace. In terms of total doses given, Indonesia ranks third in Asia and fifth in the world.\nAccording to wikipedia, as of 5 February 2023 at 18:00 WIB (UTC+7), 204,266,655 people had received the first dose of the vaccine and 175,131,893 people had been fully vaccinated; 69,597,474 of them had been inoculated with the booster or the third dose, while 1,585,164 had received the fourth dose. Jakarta has the highest percentage of population fully vaccinated with 103.46%, followed by Bali and Special Region of Yogyakarta with 85.45% and 83.02% respectively.\nDespite its compactness, the cumulative vaccination rate are not evenly distributed within DKI Jakarta. The question is where are the sub-districts with relatively higher number of vaccination rate and how they changed over time.\n\n\n\nExploratory Spatial Data Analysis (ESDA) hold tremendous potential to address complex problems facing society. In this study, you are tasked to apply appropriate Local Indicators of Spatial Association (LISA) and Emerging Hot Spot Analysis (EHSA) to undercover the spatio-temporal trends of COVID-19 vaccination in DKI Jakarta.\n\n\n\nThe specific tasks of this take-home exercise are as follows:\n\n\n\nCompute the monthly vaccination rate from July 2021 to June 2022 at sub-district (also known as kelurahan in Bahasa Indonesia) level,\nPrepare the monthly vaccination rate maps by using appropriate tmap functions,\nDescribe the spatial patterns revealed by the choropleth maps (not more than 200 words).\n\n\n\n\nWith reference to the vaccination rate maps prepared in ESDA:\n\nCompute local Gi* values of the monthly vaccination rate,\nDisplay the Gi* maps of the monthly vaccination rate. The maps should only display the significant (i.e. p-value < 0.05)\nWith reference to the analysis results, draw statistical conclusions (not more than 250 words).\n\n\n\n\nWith reference to the local Gi* values of the vaccination rate maps prepared in the previous section:\n\nPerform Mann-Kendall Test by using the spatio-temporal local Gi* values,\nSelect three sub-districts and describe the temporal trends revealed (not more than 250 words), and\nPrepared a EHSA map of the Gi* values of vaccination rate. The maps should only display the significant (i.e. p-value < 0.05).\nWith reference to the EHSA map prepared, describe the spatial patterns revelaed. (not more than 250 words)."
  },
  {
    "objectID": "exercises/thex02.html#data-acquisition",
    "href": "exercises/thex02.html#data-acquisition",
    "title": "Take-Home Exercise 02: Spatio-Temporal Analysis of COVID-19 Vaccination Trends in Jarkata",
    "section": "2.1 Data Acquisition",
    "text": "2.1 Data Acquisition\nThe following datasets would be used to study the spatial-temporal geographical distribution of vaccination rates in Jarkata, Indonesia, between June 2021 to May 2022.\n\n\n\nDataset Name\nSource\n\n\n\n\nVaccination Data from June 2021 to May 2022 in Jarkata, Indonesia\nRiwayat File Vaksinasi DKI Jakarta\n\n\nDKI Jakarta Administration Boundary 2019\nIndonesia Geospatial Portal"
  },
  {
    "objectID": "exercises/thex02.html#installing-and-loading-packages",
    "href": "exercises/thex02.html#installing-and-loading-packages",
    "title": "Take-Home Exercise 02: Spatio-Temporal Analysis of COVID-19 Vaccination Trends in Jarkata",
    "section": "2.2 Installing and Loading Packages",
    "text": "2.2 Installing and Loading Packages\nNext, pacman assists us by helping us load R packages that we require, sf, tidyverse and funModeling.\n\npacman::p_load(readxl, sf, tidyverse, tmap, sfdep, gifski)\n\nThe following packages assists us to accomplish the following:\n\nreadxl assists us in importing .xlsx aspatial data without having to convert to .csv\nsf helps to import, manage and process vector-based geospatial data in R\ntidyverse which includes readr to import delimited text file, tidyr for tidying data and dplyr for wrangling data\ntmap provides functions to allow us to plot high quality static or interactive maps using leaflet API\ngifski helps us to handle the GIF animation for tmap"
  },
  {
    "objectID": "exercises/thex02.html#context",
    "href": "exercises/thex02.html#context",
    "title": "Take-Home Exercise 02: Spatio-Temporal Analysis of COVID-19 Vaccination Trends in Jarkata",
    "section": "2.3 Context",
    "text": "2.3 Context\nIn Indonesia, the subdivisions in Indonesia is denoted as follows, this will be important for our analysis as we will be interested in looking at spatio-temporal data of COVID-19 vaccinations at sub-district level which will be mapped to Level 4, Rural or Urban Villages (Desa or Kelurahan).\n\n\n\n\n\n\n\nLevel of Administration\nName (English) / Name (Bahasa Indonesia)\n\n\n\n\nLevel 1\nProvince / Provinsi\n\n\nLevel 2\nCities / Kota\n\n\nLevel 3\nDistricts / Kecamantan\n\n\nLevel 4\nRural or Urban Villages / Desa or Kelurahan"
  },
  {
    "objectID": "exercises/thex02.html#geospatial-dataset",
    "href": "exercises/thex02.html#geospatial-dataset",
    "title": "Take-Home Exercise 02: Spatio-Temporal Analysis of COVID-19 Vaccination Trends in Jarkata",
    "section": "3.1 Geospatial Dataset",
    "text": "3.1 Geospatial Dataset\n\n3.1.1 Importing Geospatial Dataset\nFirstly, in the code chunk below, we will import the geospatial dataset for Jarkata,\nIn the code below, dsn specifies the filepath where the dataset is located and layer provides the filename of the dataset excluding the file extension.\nWe will also convert the dataset from WGS84 Geographic Coordinate System to EPSG::23837 (DGN95) which is the national Projected Coordinate System for Jarkata.\n\njkt = st_read(dsn = \"Take-Home_Ex02/data/geospatial\", layer = \"BATAS_DESA_DESEMBER_2019_DUKCAPIL_DKI_JAKARTA\") %>% st_transform(crs = 23837)\n\nReading layer `BATAS_DESA_DESEMBER_2019_DUKCAPIL_DKI_JAKARTA' from data source \n  `C:\\renjie-teo\\IS415-GAA\\exercises\\Take-Home_Ex02\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 269 features and 161 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 106.3831 ymin: -6.370815 xmax: 106.9728 ymax: -5.184322\nGeodetic CRS:  WGS 84\n\n\n\n\n3.1.2 Preparing Geospatial Dataset\nLet us view the dataset columns:\n\nhead(jkt, 1)\n\nSimple feature collection with 1 feature and 161 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -765269.9 ymin: 811640 xmax: -764544.3 ymax: 812335.7\nProjected CRS: DGN95 / Indonesia TM-3 zone 50.1\n  OBJECT_ID  KODE_DESA      DESA   KODE    PROVINSI      KAB_KOTA  KECAMATAN\n1     25477 3173031006 KEAGUNGAN 317303 DKI JAKARTA JAKARTA BARAT TAMAN SARI\n  DESA_KELUR JUMLAH_PEN JUMLAH_KK LUAS_WILAY KEPADATAN PERPINDAHA JUMLAH_MEN\n1  KEAGUNGAN      21609      7255       0.36     60504        102         68\n  PERUBAHAN WAJIB_KTP SILAM KRISTEN KHATOLIK HINDU BUDHA KONGHUCU KEPERCAYAA\n1     20464     16027 15735    2042      927    15  2888        2          0\n   PRIA WANITA BELUM_KAWI KAWIN CERAI_HIDU CERAI_MATI   U0   U5  U10  U15  U20\n1 11049  10560      10193 10652        255        509 1572 1751 1703 1493 1542\n   U25  U30  U35  U40  U45  U50  U55 U60 U65 U70 U75 TIDAK_BELU BELUM_TAMA\n1 1665 1819 1932 1828 1600 1408 1146 836 587 312 415       3426       1964\n  TAMAT_SD SLTP SLTA DIPLOMA_I DIPLOMA_II DIPLOMA_IV STRATA_II STRATA_III\n1     2265 3660 8463        81        428       1244        74          4\n  BELUM_TIDA APARATUR_P TENAGA_PEN WIRASWASTA PERTANIAN NELAYAN AGAMA_DAN\n1       3927         81         70       8974         1       0         6\n  PELAJAR_MA TENAGA_KES PENSIUNAN LAINNYA    GENERATED KODE_DES_1 BELUM_\n1       4018         28        57    4447 30 Juni 2019 3173031006   3099\n  MENGUR_ PELAJAR_ PENSIUNA_1 PEGAWAI_ TENTARA KEPOLISIAN PERDAG_ PETANI\n1    4447     3254         80       48       4         10      31      0\n  PETERN_ NELAYAN_1 INDUSTR_ KONSTR_ TRANSP_ KARYAW_ KARYAW1 KARYAW1_1\n1       0         1        7       3       2    6735       9         0\n  KARYAW1_12 BURUH BURUH_ BURUH1 BURUH1_1 PEMBANT_ TUKANG TUKANG_1 TUKANG_12\n1         23   515      1      0        0        1      0        1         0\n  TUKANG__13 TUKANG__14 TUKANG__15 TUKANG__16 TUKANG__17 PENATA PENATA_\n1          1          0          1          7          1      0       0\n  PENATA1_1 MEKANIK SENIMAN_ TABIB PARAJI_ PERANCA_ PENTER_ IMAM_M PENDETA\n1         0      11        4     1       0        0       1      0       2\n  PASTOR WARTAWAN USTADZ JURU_M PROMOT ANGGOTA_ ANGGOTA1 ANGGOTA1_1 PRESIDEN\n1      0        7      6      0      0        0        0          0        0\n  WAKIL_PRES ANGGOTA1_2 ANGGOTA1_3 DUTA_B GUBERNUR WAKIL_GUBE BUPATI WAKIL_BUPA\n1          0          0          0      0        0          0      0          0\n  WALIKOTA WAKIL_WALI ANGGOTA1_4 ANGGOTA1_5 DOSEN GURU PILOT PENGACARA_ NOTARIS\n1        0          0          0          0     3   72     1          4       0\n  ARSITEK AKUNTA_ KONSUL_ DOKTER BIDAN PERAWAT APOTEK_ PSIKIATER PENYIA_\n1       1       1       1     16     3       7       0         0       0\n  PENYIA1 PELAUT PENELITI SOPIR PIALAN PARANORMAL PEDAGA_ PERANG_ KEPALA_\n1       0      0        0    65      0          0     379       0       0\n  BIARAW_ WIRASWAST_ LAINNYA_12 LUAS_DESA KODE_DES_3 DESA_KEL_1 KODE_12\n1       0       1370         94     25476 3173031006  KEAGUNGAN  317303\n                        geometry\n1 MULTIPOLYGON (((-764674.9 8...\n\n\nThe dataset above a variety of information, a breakdown by subdistrict level of the religion, demographic information, education, occupation etc.\nIn our analysis, we only require information related to the population count, subdistrict and district information and geometry information. Hence, we will only filter and retain information from index 0 to 9.\n\njkt <- jkt[0:9]\nhead(jkt, 1)\n\nSimple feature collection with 1 feature and 9 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -765269.9 ymin: 811640 xmax: -764544.3 ymax: 812335.7\nProjected CRS: DGN95 / Indonesia TM-3 zone 50.1\n  OBJECT_ID  KODE_DESA      DESA   KODE    PROVINSI      KAB_KOTA  KECAMATAN\n1     25477 3173031006 KEAGUNGAN 317303 DKI JAKARTA JAKARTA BARAT TAMAN SARI\n  DESA_KELUR JUMLAH_PEN                       geometry\n1  KEAGUNGAN      21609 MULTIPOLYGON (((-764674.9 8...\n\n\nNext, we will recode information from Bahasa Indonesia to English for easier processing, using rename() of dplyr.\n\njkt <- jkt %>% rename(\"SubDistrictCode\" = \"KODE_DESA\",\n                      \"SubDistrict\" = \"DESA\",\n                      \"Code\" = \"KODE\",\n                       \"Province\" = \"PROVINSI\",\n                      \"City\" = \"KAB_KOTA\",\n                      \"District\" = \"KECAMATAN\",\n                      \"SubDistrictName\" = \"DESA_KELUR\",\n                      \"TotalPop\" = \"JUMLAH_PEN\")\njkt\n\nSimple feature collection with 269 features and 9 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -814909.7 ymin: 787584.9 xmax: -747172.2 ymax: 919446.7\nProjected CRS: DGN95 / Indonesia TM-3 zone 50.1\nFirst 10 features:\n   OBJECT_ID SubDistrictCode        SubDistrict   Code    Province\n1      25477      3173031006          KEAGUNGAN 317303 DKI JAKARTA\n2      25478      3173031007             GLODOK 317303 DKI JAKARTA\n3      25397      3171031003      HARAPAN MULIA 317103 DKI JAKARTA\n4      25400      3171031006       CEMPAKA BARU 317103 DKI JAKARTA\n5      25378      3101011001     PULAU PANGGANG 310101 DKI JAKARTA\n6      25379      3101011002       PULAU KELAPA 310101 DKI JAKARTA\n7      25390      3171021001         PASAR BARU 317102 DKI JAKARTA\n8      25382      3101021002       PULAU TIDUNG 310102 DKI JAKARTA\n9      25391      3171021002       KARANG ANYAR 317102 DKI JAKARTA\n10     25394      3171021005 MANGGA DUA SELATAN 317102 DKI JAKARTA\n               City                  District    SubDistrictName TotalPop\n1     JAKARTA BARAT                TAMAN SARI          KEAGUNGAN    21609\n2     JAKARTA BARAT                TAMAN SARI             GLODOK     9069\n3     JAKARTA PUSAT                 KEMAYORAN      HARAPAN MULIA    29085\n4     JAKARTA PUSAT                 KEMAYORAN       CEMPAKA BARU    41913\n5  KEPULAUAN SERIBU    KEPULAUAN SERIBU UTARA     PULAU PANGGANG     6947\n6  KEPULAUAN SERIBU    KEPULAUAN SERIBU UTARA       PULAU KELAPA     7059\n7     JAKARTA PUSAT               SAWAH BESAR         PASAR BARU    15793\n8  KEPULAUAN SERIBU KEPULAUAN SERIBU SELATAN.       PULAU TIDUNG     5891\n9     JAKARTA PUSAT               SAWAH BESAR       KARANG ANYAR    33383\n10    JAKARTA PUSAT               SAWAH BESAR MANGGA DUA SELATAN    35906\n                         geometry\n1  MULTIPOLYGON (((-764674.9 8...\n2  MULTIPOLYGON (((-764859.9 8...\n3  MULTIPOLYGON (((-760021.3 8...\n4  MULTIPOLYGON (((-759415 810...\n5  MULTIPOLYGON (((-796698.3 8...\n6  MULTIPOLYGON (((-795419 870...\n7  MULTIPOLYGON (((-762362.7 8...\n8  MULTIPOLYGON (((-801734.4 8...\n9  MULTIPOLYGON (((-762950.3 8...\n10 MULTIPOLYGON (((-762822.4 8...\n\n\nNext, let us quickly plot the jkt geospatial data\n\ntmap_mode(\"plot\")\ntm_shape(jkt) +\n  tm_borders()\n\n\n\n\nWe can see there are many small dots to the top and left of the main Jarkata region. Those are outer islands. In this analysis, we will exclude the outer islands of Jarkata from our analysis.\nNow, let us try to identify how to identify and remove the outer islands. Below, we will plot City.\n\ntmap_mode(\"view\")\ntm_shape(jkt) +\n  tm_fill(\"City\", \n          alpha = 0.2) +\n  tm_borders()\n\n\n\n\n\n\nFrom our map above, we can tell that the outer islands are denoted by KEPULAUAN SERIBU which means Thousand Islands.\nHowever, we also spot some missing values. We will fill them in first before removing the outer islands.\n\nfilter(jkt, is.na(jkt$City))\n\nSimple feature collection with 2 features and 9 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -761893.4 ymin: 811733.2 xmax: -759659.1 ymax: 812745.6\nProjected CRS: DGN95 / Indonesia TM-3 zone 50.1\n  OBJECT_ID SubDistrictCode      SubDistrict   Code    Province City District\n1     25645        31888888     DANAU SUNTER 318888 DKI JAKARTA <NA>     <NA>\n2     25646        31888888 DANAU SUNTER DLL 318888 DKI JAKARTA <NA>     <NA>\n  SubDistrictName TotalPop                       geometry\n1            <NA>        0 MULTIPOLYGON (((-759659.1 8...\n2            <NA>        0 MULTIPOLYGON (((-760863.5 8...\n\n\nFrom the output above, we can gather that there are two Villages with NA values:\n\nDANAU SUNTER (OBJECT_ID 25645)\nDANAU SUNTER DLL (OBJECT_ID 25646)\n\nBy comparing the information from the Geospatial Information Agency of Indonesia (Badan Informasi Geospasial), we now know that these two villages are part of Pademangan Timur based on the screenshot from the website below:\n\nNow, let find out what is the OBJECT_ID of the village PADEMANGAN TIMUR where we are supposed to merge the two other villages (DANAU SUNTER and DANAU SUNTER DLL) into.\n\njkt %>% filter((jkt$SubDistrictName) == \"PADEMANGAN TIMUR\")\n\nSimple feature collection with 1 feature and 9 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -762223.7 ymin: 811885.3 xmax: -760240.1 ymax: 814736.4\nProjected CRS: DGN95 / Indonesia TM-3 zone 50.1\n  OBJECT_ID SubDistrictCode      SubDistrict   Code    Province          City\n1     25453      3172051001 PADEMANGAN TIMUR 317205 DKI JAKARTA JAKARTA UTARA\n    District  SubDistrictName TotalPop                       geometry\n1 PADEMANGAN PADEMANGAN TIMUR    45083 MULTIPOLYGON (((-760244.6 8...\n\n\nThe OBJECT_ID is 25453.\nLet’s plot a map of how the three states would look like before we merge them:\n\ntmap_mode(\"plot\")\ntm_shape(filter(jkt, jkt$OBJECT_ID == 25453 | jkt$OBJECT_ID == 25645 | jkt$OBJECT_ID == 25646)) +\n  tm_fill(\"SubDistrict\") +\n  tm_borders()\n\n\n\n\nNow, let us merge the regions together using the code chunk below using the st_union() function of sf:\n\nmerged_25453 <-\nst_union(filter(jkt,jkt$OBJECT_ID == 25453), filter(jkt,jkt$OBJECT_ID == 25645))[0:9]\n\nmerged_25453 <- st_union(merged_25453, filter(jkt, jkt$OBJECT_ID == 25646))[0:9]\n\nlist(merged_25453)\n\n[[1]]\nSimple feature collection with 1 feature and 9 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: -762223.7 ymin: 811733.2 xmax: -759659.1 ymax: 814736.4\nProjected CRS: DGN95 / Indonesia TM-3 zone 50.1\n  OBJECT_ID SubDistrictCode      SubDistrict   Code    Province          City\n1     25453      3172051001 PADEMANGAN TIMUR 317205 DKI JAKARTA JAKARTA UTARA\n    District  SubDistrictName TotalPop                       geometry\n1 PADEMANGAN PADEMANGAN TIMUR    45083 POLYGON ((-760404.9 811968....\n\n\nThe attributes of PADEMANGAN TIMUR still matches the data from before.\n\ntmap_mode(\"plot\")\ntm_shape(merged_25453) +\n  tm_fill(\"SubDistrict\") +\n  tm_borders()\n\n\n\n\nWe have successfully merged the 3 geometries together.\nNow, let us remove the NA records (filtering by default will remove NA values), KEPULAUAN SERIBU which removes the outer islands before we delete and reinsert the PADEMANGAN TIMUR stored in merged_25453 variable.\nWe check how many outer islands are there to be removed:\n\nfilter(jkt, jkt$City == \"KEPULAUAN SERIBU\")\n\nSimple feature collection with 6 features and 9 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -814909.7 ymin: 824270.9 xmax: -761447 ymax: 919446.7\nProjected CRS: DGN95 / Indonesia TM-3 zone 50.1\n  OBJECT_ID SubDistrictCode       SubDistrict   Code    Province\n1     25378      3101011001    PULAU PANGGANG 310101 DKI JAKARTA\n2     25379      3101011002      PULAU KELAPA 310101 DKI JAKARTA\n3     25382      3101021002      PULAU TIDUNG 310102 DKI JAKARTA\n4     25383      3101021003        PULAU PARI 310102 DKI JAKARTA\n5     25380      3101011003     PULAU HARAPAN 310101 DKI JAKARTA\n6     25381      3101021001 PULAU UNTUNG JAWA 310102 DKI JAKARTA\n              City                  District   SubDistrictName TotalPop\n1 KEPULAUAN SERIBU    KEPULAUAN SERIBU UTARA    PULAU PANGGANG     6947\n2 KEPULAUAN SERIBU    KEPULAUAN SERIBU UTARA      PULAU KELAPA     7059\n3 KEPULAUAN SERIBU KEPULAUAN SERIBU SELATAN.      PULAU TIDUNG     5891\n4 KEPULAUAN SERIBU KEPULAUAN SERIBU SELATAN.        PULAU PARI     3524\n5 KEPULAUAN SERIBU    KEPULAUAN SERIBU UTARA     PULAU HARAPAN     2579\n6 KEPULAUAN SERIBU KEPULAUAN SERIBU SELATAN. PULAU UNTUNG JAWA     2436\n                        geometry\n1 MULTIPOLYGON (((-796698.3 8...\n2 MULTIPOLYGON (((-795419 870...\n3 MULTIPOLYGON (((-801734.4 8...\n4 MULTIPOLYGON (((-786095.1 8...\n5 MULTIPOLYGON (((-795768.5 8...\n6 MULTIPOLYGON (((-778934.5 8...\n\n\nThere are 6 outer islands. Together with the 2 villages with NA city district and removing PADEMANGAN TIMUR, we should see 260 features remaining.\n\njkt <- jkt %>% filter(jkt$City != \"KEPULAUAN SERIBU\" & jkt$OBJECT_ID != 25453)\njkt\n\nSimple feature collection with 260 features and 9 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -779259.9 ymin: 787584.9 xmax: -747172.2 ymax: 819039\nProjected CRS: DGN95 / Indonesia TM-3 zone 50.1\nFirst 10 features:\n   OBJECT_ID SubDistrictCode        SubDistrict   Code    Province\n1      25477      3173031006          KEAGUNGAN 317303 DKI JAKARTA\n2      25478      3173031007             GLODOK 317303 DKI JAKARTA\n3      25397      3171031003      HARAPAN MULIA 317103 DKI JAKARTA\n4      25400      3171031006       CEMPAKA BARU 317103 DKI JAKARTA\n5      25390      3171021001         PASAR BARU 317102 DKI JAKARTA\n6      25391      3171021002       KARANG ANYAR 317102 DKI JAKARTA\n7      25394      3171021005 MANGGA DUA SELATAN 317102 DKI JAKARTA\n8      25386      3171011003       PETOJO UTARA 317101 DKI JAKARTA\n9      25403      3171041001              SENEN 317104 DKI JAKARTA\n10     25408      3171041006             BUNGUR 317104 DKI JAKARTA\n            City    District    SubDistrictName TotalPop\n1  JAKARTA BARAT  TAMAN SARI          KEAGUNGAN    21609\n2  JAKARTA BARAT  TAMAN SARI             GLODOK     9069\n3  JAKARTA PUSAT   KEMAYORAN      HARAPAN MULIA    29085\n4  JAKARTA PUSAT   KEMAYORAN       CEMPAKA BARU    41913\n5  JAKARTA PUSAT SAWAH BESAR         PASAR BARU    15793\n6  JAKARTA PUSAT SAWAH BESAR       KARANG ANYAR    33383\n7  JAKARTA PUSAT SAWAH BESAR MANGGA DUA SELATAN    35906\n8  JAKARTA PUSAT      GAMBIR       PETOJO UTARA    21828\n9  JAKARTA PUSAT       SENEN              SENEN     8643\n10 JAKARTA PUSAT       SENEN             BUNGUR    23001\n                         geometry\n1  MULTIPOLYGON (((-764674.9 8...\n2  MULTIPOLYGON (((-764859.9 8...\n3  MULTIPOLYGON (((-760021.3 8...\n4  MULTIPOLYGON (((-759415 810...\n5  MULTIPOLYGON (((-762362.7 8...\n6  MULTIPOLYGON (((-762950.3 8...\n7  MULTIPOLYGON (((-762822.4 8...\n8  MULTIPOLYGON (((-764144 810...\n9  MULTIPOLYGON (((-761646.2 8...\n10 MULTIPOLYGON (((-761014.1 8...\n\n\nYes, there are only 260 features remaining. Now, let us add the updated feature back into the jkt dataframe using rbind() which allows us to merge two sf dataframe objects together.\n\njkt <- rbind(jkt, merged_25453)\n\nNow, let us plot a map to see if the map has been properly fixed.\n\ntmap_mode(\"plot\")\ntm_shape(jkt) +\n  tm_fill(\"City\") +\n  tm_borders()\n\n\n\n\nNow, we are ready to perform other tasks."
  },
  {
    "objectID": "exercises/thex02.html#aspatial-data",
    "href": "exercises/thex02.html#aspatial-data",
    "title": "Take-Home Exercise 02: Spatio-Temporal Analysis of COVID-19 Vaccination Trends in Jarkata",
    "section": "3.2 Aspatial Data",
    "text": "3.2 Aspatial Data\n\n3.2.1 Importing Aspatial Datsets\nNext, we will import the aspatial datasets\n\nvac_202106 <- read_excel(\"Take-Home_Ex02/data/aspatial/20210630.xlsx\")\nvac_202107 <- read_excel(\"Take-Home_Ex02/data/aspatial/20210731.xlsx\")\nvac_202108 <- read_excel(\"Take-Home_Ex02/data/aspatial/20210831.xlsx\")\nvac_202109 <- read_excel(\"Take-Home_Ex02/data/aspatial/20210930.xlsx\")\nvac_202110 <- read_excel(\"Take-Home_Ex02/data/aspatial/20211031.xlsx\")\nvac_202111 <- read_excel(\"Take-Home_Ex02/data/aspatial/20211130.xlsx\")\nvac_202112 <- read_excel(\"Take-Home_Ex02/data/aspatial/20211231.xlsx\")\nvac_202201 <- read_excel(\"Take-Home_Ex02/data/aspatial/20220131.xlsx\")\nvac_202202 <- read_excel(\"Take-Home_Ex02/data/aspatial/20220227.xlsx\")\nvac_202203 <- read_excel(\"Take-Home_Ex02/data/aspatial/20220331.xlsx\")\nvac_202204 <- read_excel(\"Take-Home_Ex02/data/aspatial/20220430.xlsx\")\nvac_202205 <- read_excel(\"Take-Home_Ex02/data/aspatial/20220531.xlsx\")\n\n\n\n3.2.2 Preparing Aspatial Data\nLet’s have a look at one of the asptial dataset files and it’s columns:\n\nvac_202106\n\n# A tibble: 268 × 21\n   KODE KELURA…¹ WILAY…² KECAM…³ KELUR…⁴ SASARAN BELUM…⁵ JUMLA…⁶ JUMLA…⁷ TOTAL…⁸\n   <chr>         <chr>   <chr>   <chr>     <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n 1 <NA>          <NA>    <NA>    TOTAL   7739060 5113425 2623759 1179448 3803207\n 2 3172051003    JAKART… PADEMA… ANCOL     20393   13394    6992    3277   10269\n 3 3173041007    JAKART… TAMBORA ANGKE     25785   16743    9033    3217   12250\n 4 3175041005    JAKART… KRAMAT… BALE K…   25158   19068    6082    2636    8718\n 5 3175031003    JAKART… JATINE… BALI M…    8683    5816    2864    1512    4376\n 6 3175101006    JAKART… CIPAYU… BAMBU …   22768   15575    7189    3977   11166\n 7 3174031002    JAKART… MAMPAN… BANGKA    18930   12655    6269    2699    8968\n 8 3175051002    JAKART… PASAR … BARU      20267   11481    8769    4668   13437\n 9 3175041004    JAKART… KRAMAT… BATU A…   41389   30601   10777    5234   16011\n10 3171071002    JAKART… TANAH … BENDUN…   19008   11660    7341    3561   10902\n# … with 258 more rows, 12 more variables: `LANSIA\\r\\nDOSIS 1` <dbl>,\n#   `LANSIA\\r\\nDOSIS 2` <dbl>, `LANSIA TOTAL \\r\\nVAKSIN DIBERIKAN` <dbl>,\n#   `PELAYAN PUBLIK\\r\\nDOSIS 1` <dbl>, `PELAYAN PUBLIK\\r\\nDOSIS 2` <dbl>,\n#   `PELAYAN PUBLIK TOTAL\\r\\nVAKSIN DIBERIKAN` <dbl>,\n#   `GOTONG ROYONG\\r\\nDOSIS 1` <dbl>, `GOTONG ROYONG\\r\\nDOSIS 2` <dbl>,\n#   `GOTONG ROYONG TOTAL\\r\\nVAKSIN DIBERIKAN` <dbl>,\n#   `TENAGA KESEHATAN\\r\\nDOSIS 1` <dbl>, `TENAGA KESEHATAN\\r\\nDOSIS 2` <dbl>, …\n\n\nThe dataset contains many columns, telling us about the specific breakdown of vaccinatation rates by targeted population (SASARAN), yet to be vaccinated (BELUM VAKSIN), breakdowns of vaccination and doses taken by different user groups and total number of vaccinations.\nSince we are only interested in visualising and analysing the monthly vaccination rate in Jarkata, we only require the targeted population (SASARAN) and yet to be vaccinated (BELUM VAKSIN) columns and derive the formula:\n\n\n\n\n\n\nNote\n\n\n\nPercentage of the cumulative vaccination rate = (targeted / total population)\n\n\nLet us also check what City Areas (WILAYAH KOTA) the dataset contains:\n\nunique(vac_202106$`WILAYAH KOTA`)\n\n[1] NA                   \"JAKARTA UTARA\"      \"JAKARTA BARAT\"     \n[4] \"JAKARTA TIMUR\"      \"JAKARTA SELATAN\"    \"JAKARTA PUSAT\"     \n[7] \"KAB.ADM.KEP.SERIBU\"\n\n\nSince we do not want the outer islands, we should remove values with City Area KAB.ADM.KEP.SERIBU.\nAlso, we can see there is an NA value, attributed to the first row which contains the Total count, which we want to remove.\nLet’s check how many rows we should expect in our tidied dataframe per month:\n\nvac_202106 %>% filter(vac_202106$`WILAYAH KOTA` != \"KAB.ADM.KEP.SERIBU\")\n\n# A tibble: 261 × 21\n   KODE KELURA…¹ WILAY…² KECAM…³ KELUR…⁴ SASARAN BELUM…⁵ JUMLA…⁶ JUMLA…⁷ TOTAL…⁸\n   <chr>         <chr>   <chr>   <chr>     <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n 1 3172051003    JAKART… PADEMA… ANCOL     20393   13394    6992    3277   10269\n 2 3173041007    JAKART… TAMBORA ANGKE     25785   16743    9033    3217   12250\n 3 3175041005    JAKART… KRAMAT… BALE K…   25158   19068    6082    2636    8718\n 4 3175031003    JAKART… JATINE… BALI M…    8683    5816    2864    1512    4376\n 5 3175101006    JAKART… CIPAYU… BAMBU …   22768   15575    7189    3977   11166\n 6 3174031002    JAKART… MAMPAN… BANGKA    18930   12655    6269    2699    8968\n 7 3175051002    JAKART… PASAR … BARU      20267   11481    8769    4668   13437\n 8 3175041004    JAKART… KRAMAT… BATU A…   41389   30601   10777    5234   16011\n 9 3171071002    JAKART… TANAH … BENDUN…   19008   11660    7341    3561   10902\n10 3175031002    JAKART… JATINE… BIDARA…   32331   23675    8652    4030   12682\n# … with 251 more rows, 12 more variables: `LANSIA\\r\\nDOSIS 1` <dbl>,\n#   `LANSIA\\r\\nDOSIS 2` <dbl>, `LANSIA TOTAL \\r\\nVAKSIN DIBERIKAN` <dbl>,\n#   `PELAYAN PUBLIK\\r\\nDOSIS 1` <dbl>, `PELAYAN PUBLIK\\r\\nDOSIS 2` <dbl>,\n#   `PELAYAN PUBLIK TOTAL\\r\\nVAKSIN DIBERIKAN` <dbl>,\n#   `GOTONG ROYONG\\r\\nDOSIS 1` <dbl>, `GOTONG ROYONG\\r\\nDOSIS 2` <dbl>,\n#   `GOTONG ROYONG TOTAL\\r\\nVAKSIN DIBERIKAN` <dbl>,\n#   `TENAGA KESEHATAN\\r\\nDOSIS 1` <dbl>, `TENAGA KESEHATAN\\r\\nDOSIS 2` <dbl>, …\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe code block above tells us we are expecting 261 rows per month, a total of 3132 rows for our combined vaccination dataset over 12 months\n\n\nThe creates a function proc_data() which processes the imported dataset to do the following:\n\nRemove the “Total” row\nRemove the outer islands records\nDrop unnecessary columns not required for processing\nRecode Bahasa Indonesia column names to English for easy processing\nAdd a period column which indicates the month\nCalculate vaccination rate (VaccinationRate) utilising formula stated above\nMerge the geometry from jkt into the new dataframe\n\n\nproc_data <- function(df, date){\n    df <- filter(df, df$KELURAHAN != \"TOTAL\")\n    df <- filter(df, df$`WILAYAH KOTA` != \"KAB.ADM.KEP.SERIBU\")\n    new_df <- left_join(jkt, df,\n                          by = c(\"SubDistrictCode\" = \"KODE KELURAHAN\"))\n    \n    # recode column names to english\n    new_df <- new_df %>% rename(\n                      \"CityArea\" = \"WILAYAH KOTA\",\n                      \"TargetPop\" = \"SASARAN\",\n                      \"YetToBeVac\" = \"BELUM VAKSIN\")\n    \n    new_df <- new_df[,c(\"OBJECT_ID\",\n                   \"SubDistrictCode\",\n                   \"SubDistrict\",\n                   \"Code\",\n                   \"Province\",\n                   \"City\",\n                   \"District\",\n                   \"SubDistrictName\",\n                   \"TotalPop\",\n                   \"CityArea\",\n                   \"TargetPop\",\n                   \"YetToBeVac\"\n                   )]\n    \n    new_df$period = as.Date(date, \"%Y-%m-%d\") \n    \n    new_df <- new_df %>%\n      mutate(VaccinationRate = (new_df$TargetPop - new_df$YetToBeVac) / new_df$TargetPop)\n    \n    return (new_df)\n}\n\nThe code chunk below assists us in the vaccination processing the raw vaccination data to create an sf object with geometry using the proc_data() function we have created earlier above.\n\nproc2106 <- proc_data(vac_202106, \"2021-06-01\")\nproc2107 <- proc_data(vac_202107, \"2021-07-01\")\nproc2108 <- proc_data(vac_202108, \"2021-08-01\")\nproc2109 <- proc_data(vac_202109, \"2021-09-01\")\nproc2110 <- proc_data(vac_202110, \"2021-10-01\")\nproc2111 <- proc_data(vac_202111, \"2021-11-01\")\nproc2112 <- proc_data(vac_202112, \"2021-12-01\")\nproc2201 <- proc_data(vac_202201, \"2022-01-01\")\nproc2202 <- proc_data(vac_202202, \"2022-02-01\")\nproc2203 <- proc_data(vac_202203, \"2022-03-01\")\nproc2204 <- proc_data(vac_202204, \"2022-04-01\")\nproc2205 <- proc_data(vac_202205, \"2022-05-01\")\n\nUsing rbind() we merge all sf objects of each month into a singular sf object.\n\ncombined_jkt_vac <- rbind(proc2106, proc2107, proc2108, proc2109, proc2110, proc2111, proc2112, proc2201, proc2202, proc2203, proc2204, proc2205)\n\nLet us inspect the combined_jkt_vac sf object now.\n\nglimpse(combined_jkt_vac)\n\nRows: 3,132\nColumns: 15\n$ OBJECT_ID       <dbl> 25477, 25478, 25397, 25400, 25390, 25391, 25394, 25386…\n$ SubDistrictCode <chr> \"3173031006\", \"3173031007\", \"3171031003\", \"3171031006\"…\n$ SubDistrict     <chr> \"KEAGUNGAN\", \"GLODOK\", \"HARAPAN MULIA\", \"CEMPAKA BARU\"…\n$ Code            <dbl> 317303, 317303, 317103, 317103, 317102, 317102, 317102…\n$ Province        <chr> \"DKI JAKARTA\", \"DKI JAKARTA\", \"DKI JAKARTA\", \"DKI JAKA…\n$ City            <chr> \"JAKARTA BARAT\", \"JAKARTA BARAT\", \"JAKARTA PUSAT\", \"JA…\n$ District        <chr> \"TAMAN SARI\", \"TAMAN SARI\", \"KEMAYORAN\", \"KEMAYORAN\", …\n$ SubDistrictName <chr> \"KEAGUNGAN\", \"GLODOK\", \"HARAPAN MULIA\", \"CEMPAKA BARU\"…\n$ TotalPop        <dbl> 21609, 9069, 29085, 41913, 15793, 33383, 35906, 21828,…\n$ CityArea        <chr> \"JAKARTA BARAT\", \"JAKARTA BARAT\", \"JAKARTA PUSAT\", \"JA…\n$ TargetPop       <dbl> 15262, 7192, 19987, 27330, 11656, 23056, 24940, 16084,…\n$ YetToBeVac      <dbl> 10407, 3622, 13778, 18618, 6162, 15233, 16405, 10609, …\n$ period          <date> 2021-06-01, 2021-06-01, 2021-06-01, 2021-06-01, 2021-…\n$ VaccinationRate <dbl> 0.3181103, 0.4963849, 0.3106519, 0.3187706, 0.4713452,…\n$ geometry        <MULTIPOLYGON [m]> MULTIPOLYGON (((-764674.9 8..., MULTIPOLY…\n\n\nChecking back with our previous calculations, we have 3132 rows here, hence, the data preparation has been done correctly!"
  },
  {
    "objectID": "exercises/thex02.html#gathering-requisite-data",
    "href": "exercises/thex02.html#gathering-requisite-data",
    "title": "Take-Home Exercise 02: Spatio-Temporal Analysis of COVID-19 Vaccination Trends in Jarkata",
    "section": "5.1 Gathering Requisite Data",
    "text": "5.1 Gathering Requisite Data\nWe will create another function to come up with the data format required for the spacetime cube:\nThe creates a function proc_timeseries_raw_data() which processes the imported dataset to do the following:\n\nRemove the “Total” row\nRemove the outer islands records\nDrop unnecessary columns not required for processing\nRecode Bahasa Indonesia column names to English for easy processing\nAdd a period column which indicates the month\nCalculate vaccination rate (VaccinationRate) utilising formula stated above\n\n\nproc_timeseries_raw_data <- function(df, date){\n    df <- filter(df, df$KELURAHAN != \"TOTAL\")\n    df <- filter(df, df$`WILAYAH KOTA` != \"KAB.ADM.KEP.SERIBU\")\n    \n    # recode column names to english\n    new_df <- df %>% rename(\n                      \"SubDistrict\" = \"KELURAHAN\",\n                      \"SubDistrictCode\" = \"KODE KELURAHAN\",\n                      \"CityArea\" = \"WILAYAH KOTA\",\n                      \"TargetPop\" = \"SASARAN\",\n                      \"YetToBeVac\" = \"BELUM VAKSIN\")\n    \n    new_df <- new_df[,c(\n                   \"SubDistrictCode\",\n                   \"SubDistrict\",\n                   \"CityArea\",\n                   \"TargetPop\",\n                   \"YetToBeVac\"\n                   )]\n    \n    new_df$period = as.Date(date, \"%Y-%m-%d\") \n    \n    new_df <- new_df %>%\n      mutate(VaccinationRate = (new_df$TargetPop - new_df$YetToBeVac) / new_df$TargetPop)\n    \n    return (new_df)\n}\n\nThe code chunk below uses the proc_timeseries_raw_data() function to process the original imported vaccination data into data usable for the time series cube. We will use rbind() to combine all the tables together\n\njkt_vac <-\nrbind(proc_timeseries_raw_data(vac_202106, \"2021-06-01\"),\n      proc_timeseries_raw_data(vac_202107, \"2021-07-01\"),\n      proc_timeseries_raw_data(vac_202108, \"2021-08-01\"),\n      proc_timeseries_raw_data(vac_202109, \"2021-09-01\"),\n      proc_timeseries_raw_data(vac_202110, \"2021-10-01\"),\n      proc_timeseries_raw_data(vac_202111, \"2021-11-01\"),\n      proc_timeseries_raw_data(vac_202112, \"2021-12-01\"),\n      proc_timeseries_raw_data(vac_202201, \"2022-01-01\"),\n      proc_timeseries_raw_data(vac_202202, \"2022-02-01\"),\n      proc_timeseries_raw_data(vac_202203, \"2022-03-01\"),\n      proc_timeseries_raw_data(vac_202204, \"2022-04-01\"),\n      proc_timeseries_raw_data(vac_202205, \"2022-05-01\")\n      )\n\nWe will also reload the map and perform the required transformations that were done above. The only difference in jkt_geo is that we will just drop the two polygons which has no City, District or Subdistrict filled in instead of merging to PADEMANGAN TIMUR:\n\nDANAU SUNTER (OBJECT_ID 25645)\nDANAU SUNTER DLL (OBJECT_ID 25646)\n\nThis is done as there would be errors in computing the weights later on using the originally merged geometry.\n\njkt_geo <- st_read(dsn = \"Take-Home_Ex02/data/geospatial\", layer = \"BATAS_DESA_DESEMBER_2019_DUKCAPIL_DKI_JAKARTA\") %>% st_transform(crs = 23837) \n\nReading layer `BATAS_DESA_DESEMBER_2019_DUKCAPIL_DKI_JAKARTA' from data source \n  `C:\\renjie-teo\\IS415-GAA\\exercises\\Take-Home_Ex02\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 269 features and 161 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 106.3831 ymin: -6.370815 xmax: 106.9728 ymax: -5.184322\nGeodetic CRS:  WGS 84\n\njkt_geo  <- jkt_geo[0:9] \njkt_geo <- jkt_geo %>% rename(\"SubDistrictCode\" = \"KODE_DESA\",\n                      \"SubDistrict\" = \"DESA\",\n                      \"Code\" = \"KODE\",\n                       \"Province\" = \"PROVINSI\",\n                      \"City\" = \"KAB_KOTA\",\n                      \"District\" = \"KECAMATAN\",\n                      \"SubDistrictName\" = \"DESA_KELUR\",\n                      \"TotalPop\" = \"JUMLAH_PEN\") \njkt_geo <- jkt_geo %>% \n  filter(jkt_geo$City != \"KEPULAUAN SERIBU\")"
  },
  {
    "objectID": "exercises/thex02.html#creating-spatio-temporal-time-series-cube",
    "href": "exercises/thex02.html#creating-spatio-temporal-time-series-cube",
    "title": "Take-Home Exercise 02: Spatio-Temporal Analysis of COVID-19 Vaccination Trends in Jarkata",
    "section": "5.2 Creating Spatio-Temporal Time Series Cube",
    "text": "5.2 Creating Spatio-Temporal Time Series Cube\nUsing the code below, we will use spacetime() of sfdep package to create a spatio-temporal cube\n\njkt_st <- spacetime(.data = jkt_vac, .geometry = jkt_geo,\n                    .loc_col = \"SubDistrictCode\",\n                    .time_col = \"period\")\n\nNext, we will check if the spacetime cube has been created correctly with the code below:\n\nis_spacetime_cube(jkt_st)\n\n[1] TRUE\n\n\nThe TRUE return means that the jkt_st space time cube has been created successfully."
  },
  {
    "objectID": "exercises/thex02.html#computing-gi",
    "href": "exercises/thex02.html#computing-gi",
    "title": "Take-Home Exercise 02: Spatio-Temporal Analysis of COVID-19 Vaccination Trends in Jarkata",
    "section": "6.1 Computing Gi*",
    "text": "6.1 Computing Gi*\nNext, we will compute the local Gi* statistics\n\n6.1.1 Deriving Spatial Weights\nUsing the code chunk below, we will be able to identify neighbours and derive inverse distance weights, which will be necessary to compute the local GI* statistics.\n\njkt_nb <- jkt_st %>%\n  activate(\"geometry\") %>%\n  mutate(nb = include_self(st_contiguity(geometry)),\n         wt = st_inverse_distance(nb, geometry,\n                                  scale = 1,\n                                  alpha = 1),\n         .before = 1) %>%\n  set_nbs(\"nb\") %>%\n  set_wts(\"wt\")\n\nNow, let us check the variable jkt_nb\n\nhead(jkt_nb)\n\n# A tibble: 6 × 9\n  SubDistrictCode SubDi…¹ CityA…² Targe…³ YetTo…⁴ period     Vacci…⁵ nb    wt   \n  <chr>           <chr>   <chr>     <dbl>   <dbl> <date>       <dbl> <lis> <lis>\n1 3173031006      KEAGUN… JAKART…   15262   10407 2021-06-01   0.318 <int> <dbl>\n2 3173031007      GLODOK  JAKART…    7192    3622 2021-06-01   0.496 <int> <dbl>\n3 3171031003      HARAPA… JAKART…   19987   13778 2021-06-01   0.311 <int> <dbl>\n4 3171031006      CEMPAK… JAKART…   27330   18618 2021-06-01   0.319 <int> <dbl>\n5 3171021001      PASAR … JAKART…   11656    6162 2021-06-01   0.471 <int> <dbl>\n6 3171021002      KARANG… JAKART…   23056   15233 2021-06-01   0.339 <int> <dbl>\n# … with abbreviated variable names ¹​SubDistrict, ²​CityArea, ³​TargetPop,\n#   ⁴​YetToBeVac, ⁵​VaccinationRate\n\n\nWe can see that the neighbour (nb) and weights (wt) has been calculated.\n\n\n6.1.2 Computing Gi* Values\nUtilising the code chunk below, we use local_gstar_perm() of sfdep package and group by period to manually calculate the local GI* statistic for each subdistrict. After which, we can use unnest() to unnest the gi_star column of the new dataframe.\n\ngistars <- jkt_nb %>%\n  group_by(period) %>%\n  mutate(gi_star = local_gstar_perm(\n    VaccinationRate, nb, wt)) %>%\n  tidyr::unnest(gi_star)\n\nWith the statistic, we can merge our geometry to be able to plot and see the statistical trends of the local GI* statistic\n\ngistar_map <- left_join(jkt_geo, gistars,\n                          by = c(\"SubDistrictCode\" = \"SubDistrictCode\"))\n\nWe create the tmap plot for gi_star statistic. Note we use p_sim to used the simulated values and used fixed style and breaks to plot the values that were P < 0.05 which are areas that are significant.\n\ngistar_map <- gistar_map %>% mutate(`P-Value` = case_when(p_sim < 0.05 ~ '< 0.05',  p_sim >= 0.05 ~ 'Not-Significant'))\n\ngistar_tmap <-\n  tm_shape(gistar_map) + \n    tm_fill(\"P-Value\") +\n    tm_borders(lwd = 0.1) +\n    tm_facets(along = \"period\", free.coords = FALSE)\n\nNow, we plot the tmap plot of areas where the Gi* statistic is significant.\n\ngistar_tmap\n\n\n\n\n=============\n\n\n\n\n\n=======\n\n\n\n\n\n=======\n\n\n\n\n\n======\n\n\n\n\n\n=======\n\n\n\n\n\n=======\n\n\n\n\n\n======\n\n\n\n\n\n=======\n\n\n\n\n\n=======\n\n\n\n\n\n======\n\n\n\n\n\n=======\n\n\n\n\n\nWhat it means is that for values in yellow, since the P Value is <0.05 which is significant, we know that the area is significantly either associated with higher or lower vaccination rate values than the surrounding areas.\nThe Central Jarkata region consistently remained as significantly different from its surrounding regions throughout the 12 months. From about October 2021 onwards until May 2022, we can see most of Jarkata Selatan’s subdistricts are significant. Part of Jarkata Timur’s subdistricts, particularly those in the middle and south of the city area are significant too.\nNow, we will conduct a Emerging Hot Spot Analysis to conclusively tell if the area that is significant is a cold or hot spot."
  },
  {
    "objectID": "exercises/thex02.html#mann-kendall-test",
    "href": "exercises/thex02.html#mann-kendall-test",
    "title": "Take-Home Exercise 02: Spatio-Temporal Analysis of COVID-19 Vaccination Trends in Jarkata",
    "section": "7.1 Mann-Kendall Test",
    "text": "7.1 Mann-Kendall Test\nWe utilise the group_by and MannKendall() function to perform the Mann-Kendall test to identify if the Vaccination Rates are increasing or decreasing over time.\n\nehsa <- gistars %>%\n  group_by(SubDistrict) %>%\n  summarise(mk = list(\n    unclass(\n      Kendall::MannKendall(gi_star)))) %>%\n  tidyr::unnest_wider(mk)\n\n\n7.1.0.1 Selecting 3 Districts to Evaluate the Temporal Trends Revealed\nHypothesis:\nH0: No monotonic trend in series\nH1: A trend exists, it can be positive, negative, or non-null\n\nKAPUK MUARA (3172011003)\n\nplotdata <- gistars %>% \n  ungroup() %>% \n  filter(SubDistrictCode == \"3172011003\") |> \n  select(SubDistrict, period, gi_star)\n\nggplot(data = plotdata, \n       aes(x = period, \n           y = gi_star)) +\n  geom_line() +\n  theme_light()\n\n\n\n\nFirstly, we can see theres a sharp upward and then gradual downward trend.\n\nehsa %>% filter(SubDistrict == \"KAPUK MUARA\") \n\n# A tibble: 1 × 6\n  SubDistrict    tau        sl     S     D  varS\n  <chr>        <dbl>     <dbl> <dbl> <dbl> <dbl>\n1 KAPUK MUARA -0.909 0.0000521   -60  66.0  213.\n\n\nNext, since the p_value < 0.05, we can reject the null hypothesis that there is no monotonic trend. Hence, we can conclude that we can say that the vaccination rate for Kapuk Muara is significantly a osciliating hotspot trend.\nHALIM PERDANA KUSUMAH (3175081004)\n\nplotdata <- gistars %>% \n  ungroup() %>% \n  filter(SubDistrictCode == \"3175081004\") |> \n  select(SubDistrict, period, gi_star)\n\nggplot(data = plotdata, \n       aes(x = period, \n           y = gi_star)) +\n  geom_line() +\n  theme_light()\n\n\n\n\nFirstly, we can see theres mostly a general upward trend most of the time. Meaning that the vaccination rates are increasing.\n\nehsa %>% filter(SubDistrict == \"HALIM PERDANA KUSUMAH\") \n\n# A tibble: 1 × 6\n  SubDistrict             tau        sl     S     D  varS\n  <chr>                 <dbl>     <dbl> <dbl> <dbl> <dbl>\n1 HALIM PERDANA KUSUMAH 0.939 0.0000287    62  66.0  213.\n\n\nNext, since the p_value < 0.05, we can reject the null hypothesis that there is no monotonic trend. Hence, we can conclude that we can say that the vaccination rate for Halim Perdana Kusuma is significantly a osciliating hotspot trend.\nKEBON MELATI (3171071005)\n\nplotdata <- gistars %>% \n  ungroup() %>% \n  filter(SubDistrictCode == \"3171071005\") |> \n  select(SubDistrict, period, gi_star)\n\nggplot(data = plotdata, \n       aes(x = period, \n           y = gi_star)) +\n  geom_line() +\n  theme_light()\n\n\n\n\nFirstly, we can see theres mostly a downward trend of vaccination most of the time.\n\nehsa %>% filter(SubDistrict == \"KEBON MELATI\") \n\n# A tibble: 1 × 6\n  SubDistrict     tau        sl     S     D  varS\n  <chr>         <dbl>     <dbl> <dbl> <dbl> <dbl>\n1 KEBON MELATI -0.909 0.0000521   -60  66.0  213.\n\n\nNext, since the p-value is < 0.05, we reject the null hypothesis that there is no monotonic trend. Hence, we can conclude that we can say that the vaccination rate for Kebon Melati is significantly a osciliating hotspot trend.\n\n\n\n7.1.1 Arranging to Show Significant Emerging Hot/Cold Spots\n\nemerging <- ehsa %>%\n  arrange(sl, abs(tau)) %>%\n  slice(1:5)\n\n\n\n7.1.2 Performing Emerging Hotspot Analysis\nUtilising the emerging_hotspot_analysis() function of sfdep, it tasks a space time object jkt_st which we created before and the variable name which we are interested in VaccinationRate.\nBy default we leave k = 1 which is for time lag. nsim in this case is number of simulations to be performed, the more simulations the more stable the result.\n\nehsa <- emerging_hotspot_analysis(\n  x = jkt_st, \n  .var = \"VaccinationRate\", \n  k = 1, \n  nsim = 99\n)\n\n\n\n7.1.3 Visualising the Distribution of EHSA Classes\nUsing the code chunk below, we use ggplot2 functions to see the distribution of EHSA classes in a bar chart.\n\nggplot(data = ehsa,\n       aes(x = classification)) +\n  geom_bar()\n\n\n\n\nHere, we can see most subdistricts are an oscilating hotspot meaning that statistically, many of these hotspots are a statistically significant cold spot during a prior month and less than 90% of the months, it has been a statistically significant hot spot. We can verify this as in the previous chloropleth map plotted, the vaccination rates changed at different rates, hence, a subdistrict’s which is initially lower could become higher than other subdistricts surrounding it int he next month.\nSecondly, many of the subdistricts were sporadic cold spots, which means that they have these subdistricts have a history of being on and off-again cold spots, less than 90% of the months it has been statistically cold spots and it has never been a significant hot spot.\nBy 90% of months, given that there are 12 months, 90% would mean requiring to be a significant hot or cold spot for at least 11 out of the 12 months.\n\n\n7.1.4 Visualising EHSA\nNow, we will join the EHSA values with the geometry of Jarkata subdistrict map to see the distribution.\n\njkt_ehsa <- left_join(jkt_geo, ehsa,\n                          by = c(\"SubDistrictCode\" = \"location\"))\n\nNext, we will plot the map, we utilise mutate to filter non-significant values out as non-significant. Significant values with P-value < 0.05 will have its its hot or cold spot pattern indicated.\n\nehsa_sig <- jkt_ehsa\nehsa_sig <- ehsa_sig %>% mutate(classification = case_when(\n    `p_value` >= 0.05 ~ \"not-Significant\", \n    TRUE ~ classification \n))\ntmap_mode(\"plot\")\ntm_shape(jkt_ehsa) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(ehsa_sig) +\n  tm_fill(\"classification\") + \n  tm_borders(alpha = 0.4)\n\n\n\n\nFrom the EHSA Map, we can see that:\n\nThere are three states where no pattern is detected. These means that they do not fall into any of the hot spot or cold spot categories.\nThere are no subdistrict that is persistently hot or cold as compared to its surrounding subdistricts. This means that no one subdistrict has had a consistently higher vaccination rate than its neighbours\nOscillating Hotspots, coldspots and sporadic coldspots subdistricts are interspersed between each other. These cause their patterns to change as one subdistrict affects the other.\nThere are subdistricts where it is not significant to tell the EHSA patterns, these regions are commonly located around neighbours that are all some variant of coldspot or hotspot, hence, their vaccination rates might be similar to that of its neighbours."
  },
  {
    "objectID": "exercises/thex03.html",
    "href": "exercises/thex03.html",
    "title": "Take-Home Exercise 03: Predicting HDB Public Housing Resale Prices Using Geographically Weighted Methods",
    "section": "",
    "text": "<add context>\nbal bla we are lookign at 5 storey HDB bla bla\n\n\n\nExploratory Spatial Data Analysis (ESDA) hold tremendous potential to address complex problems facing society. In this study, you are tasked to apply appropriate Local Indicators of Spatial Association (LISA) and Emerging Hot Spot Analysis (EHSA) to undercover the spatio-temporal trends of COVID-19 vaccination in DKI Jakarta.\n\n\n\nIn this take-home exercise, you are tasked to predict HDB resale prices at the sub-market level (i.e. HDB 3-room, HDB 4-room and HDB 5-room) for the month of January and February 2023 in Singapore. The predictive models must be built by using by using conventional OLS method and GWR methods. You are also required to compare the performance of the conventional OLS method versus the geographical weighted methods."
  },
  {
    "objectID": "exercises/thex03.html#data-acquisition",
    "href": "exercises/thex03.html#data-acquisition",
    "title": "Take-Home Exercise 03: Predicting HDB Public Housing Resale Prices Using Geographically Weighted Methods",
    "section": "2.3 Data Acquisition",
    "text": "2.3 Data Acquisition\nThe following datasets would be used to create the predictive models using conventional OLS and GWR methods for HDB Resale Prices.\n\n\n\nDataset Name\nRemarks\nSource\n\n\n\n\nURA Master Plan 2019 Subzone Boundary\nFor visualisation purposes\ndata.gov.sg\n\n\nURA Master Plan 2019 Planning Area Boundary\nFor visualisation purposes and extract Central AreW\nProf Kam\n\n\nHDB Resale Flat Prices\n\ndata.gov.sg\n\n\nHDB MUP/HIP Status\nManual Web Scraping\nhdb.gov.sg\n\n\nChildcare\n\n\n\n\nKindergartens\n\n\n\n\nEldercare\n\n\n\n\nFoodcourt/Hawker\n\n\n\n\nSupermarket\n\n\n\n\nCurrent and Future MRT/LRT Stations\nExcludes Cross Region Line Punggol Branch\ndata.gov.sg\n\n\nFuture MRT Station (CRL Punggol Branch)\nManually merge into MRT/LRT Station Dataset\nwikipedia.org : Elias MRT Stn\nwikipedia.org : Riveria MRT Stn\n\n\nMRT/LRT Railway Line\nFilter elevated sections of MRT line\ndata.gov.sg\n\n\nBus Stops\n\ndatamall.lta.gov.sg\n\n\nParks\n\n\n\n\nPrimary Schools\n\n\n\n\nCHAS Clinics\nExtracted using Excel from PDF\nchas.sg"
  },
  {
    "objectID": "exercises/thex03.html#installing-and-loading-packages",
    "href": "exercises/thex03.html#installing-and-loading-packages",
    "title": "Take-Home Exercise 03: Predicting HDB Public Housing Resale Prices Using Geographically Weighted Methods",
    "section": "2.1 Installing and Loading Packages",
    "text": "2.1 Installing and Loading Packages\nNext, pacman assists us by helping us load R packages that we require, sf, tidyverse and funModeling.\n\npacman::p_load(readxl, sf, tidyverse, tmap, sfdep, gifski, httr, jsonlite)\n\nThe following packages assists us to accomplish the following:\n\nreadxl assists us in importing .xlsx aspatial data without having to convert to .csv\nsf helps to import, manage and process vector-based geospatial data in R\ntidyverse which includes readr to import delimited text file, tidyr for tidying data and dplyr for wrangling data\ntmap provides functions to allow us to plot high quality static or interactive maps using leaflet API\ngifski helps us to handle the GIF animation for tmap"
  },
  {
    "objectID": "exercises/thex03.html#section",
    "href": "exercises/thex03.html#section",
    "title": "Take-Home Exercise 03: Predicting HDB Public Housing Resale Prices Using Geographically Weighted Methods",
    "section": "2.2 ",
    "text": "2.2"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Ren Jie’s IS415 Journal",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n  \n\n\n\n\nTake-Home Exercise 03: Predicting HDB Public Housing Resale Prices Using Geographically Weighted Methods\n\n\n\n\n\nConducting a Spatial-Temporal Analysis of COVID-19 trends at Sub-district level in Jarkata, Indonesia between June 2021 to May 2022\n\n\n\n\n\n\nMar 12, 2023\n\n\nTeo Ren Jie\n\n\n2 min\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 8: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method\n\n\n\n\n\n\n\n\n\n\n\n\nMar 5, 2023\n\n\nTeo Ren Jie\n\n\n13 min\n\n\n\n\n\n\n  \n\n\n\n\nTake-Home Exercise 02: Spatio-Temporal Analysis of COVID-19 Vaccination Trends in Jarkata\n\n\n\n\n\nConducting a Spatial-Temporal Analysis of COVID-19 trends at Sub-district level in Jarkata, Indonesia between June 2021 to May 2022\n\n\n\n\n\n\nMar 1, 2023\n\n\nTeo Ren Jie\n\n\n28 min\n\n\n\n\n\n\n  \n\n\n\n\nIn-Class Exercise 7: Spatial Weights and Applications\n\n\n\n\n\nComputing Contiguity and Distance-Based Weights in Hunan, China\n\n\n\n\n\n\nFeb 20, 2023\n\n\nTeo Ren Jie\n\n\n5 min\n\n\n\n\n\n\n  \n\n\n\n\nIn-Class Exercise 7: Spatial Weights and Applications\n\n\n\n\n\nComputing Contiguity and Distance-Based Weights in Hunan, China\n\n\n\n\n\n\nFeb 20, 2023\n\n\nTeo Ren Jie\n\n\n5 min\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 5: Global and Local Measures of Spatial Autocorrelation\n\n\n\n\n\n\n\n\n\n\n\n\nFeb 18, 2023\n\n\nTeo Ren Jie\n\n\n8 min\n\n\n\n\n\n\n  \n\n\n\n\nIn-Class Exercise 6: Spatial Weights and Applications\n\n\n\n\n\nComputing Contiguity and Distance-Based Weights in Hunan, China\n\n\n\n\n\n\nFeb 13, 2023\n\n\nTeo Ren Jie\n\n\n5 min\n\n\n\n\n\n\n  \n\n\n\n\nIn-Class Exercise 5: Local Colocation Quotients\n\n\n\n\n\nCalculating and Visualising the Local Colocation of 7-Eleven and Family Mart Convenience Store Chains in Taipei\n\n\n\n\n\n\nFeb 6, 2023\n\n\nTeo Ren Jie\n\n\n1 min\n\n\n\n\n\n\n  \n\n\n\n\nIn-Class Exercise 4: 2nd Order Spatial Point Patterns Analysis Methods\n\n\n\n\n\nSpatial Point Pattern Analysis of Distribution of Childcare Centres in Singapore\n\n\n\n\n\n\nJan 30, 2023\n\n\nTeo Ren Jie\n\n\n12 min\n\n\n\n\n\n\n  \n\n\n\n\nTake-Home Exercise 01: Water Points in Osun, Nigeria\n\n\n\n\n\nCalculating and discovering the spatial point patterns and geographical distribution of functional and non-functional water points in Osun, Nigeria\n\n\n\n\n\n\nJan 30, 2023\n\n\nTeo Ren Jie\n\n\n25 min\n\n\n\n\n\n\n  \n\n\n\n\nHands-on Exercise 3: 1st Order Spatial Point Patterns Analysis Methods\n\n\n\n\n\nSpatial Point Pattern Analysis of Distribution of Childcare Centres in Singapore\n\n\n\n\n\n\nJan 29, 2023\n\n\nTeo Ren Jie\n\n\n19 min\n\n\n\n\n\n\n  \n\n\n\n\nIn-Class Exercise 3: Analytical Mapping\n\n\n\n\n\nVisualising Functional and Non-Functional Water Pumps in Nigeria at LGA level\n\n\n\n\n\n\nJan 25, 2023\n\n\nTeo Ren Jie\n\n\n4 min\n\n\n\n\n\n\n  \n\n\n\n\nHands-on Exercise 2: Choropleth Mapping with R\n\n\n\n\n\nChloropleth Mapping of Singapore Resident Planning Area / Subzone, Age, Sex and Type of Dwelling\n\n\n\n\n\n\nJan 24, 2023\n\n\nTeo Ren Jie\n\n\n27 min\n\n\n\n\n\n\n  \n\n\n\n\nIn-Class Exercise 2: Geospatial Data Wrangling\n\n\n\n\n\nVisualising proportion of functional and non-functional water pumps in Nigeria at LGA level\n\n\n\n\n\n\nJan 16, 2023\n\n\nTeo Ren Jie\n\n\n10 min\n\n\n\n\n\n\n  \n\n\n\n\nHands-on Exercise 1: Geospatial Data Handling and Wrangling\n\n\n\n\n\nIn this exercise, I learn how to handle, perform geoprocessing and EDA using sf, tidyverse, ggplot2 and other packages.\n\n\n\n\n\n\nJan 15, 2023\n\n\nTeo Ren Jie\n\n\n11 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "exercises/thex03.html#data-fields",
    "href": "exercises/thex03.html#data-fields",
    "title": "Take-Home Exercise 03: Predicting HDB Public Housing Resale Prices Using Geographically Weighted Methods",
    "section": "2.4 Data Fields",
    "text": "2.4 Data Fields\nThe data fields we are looking to incorporate and work with in our predictive models includes:\n\nStructural FactorsVocational Factors\n\n\n\nArea of the unit\nFloor level\nRemaining lease\nAge of the unit\nMain Upgrading Program (MUP) completed\n\nExtracted MUP and Home Improvment Programme (HIP) data from HDB website\nFor HDB units that has received HIP, their home value may be affected positively than a similar aged flat that has not received it\n\nRelative Age of Remaining Lead to Mean of Remaining Lease Left within 1km (+ if newer, - if older than area)\n\nIf a HDB estate is relatively newer than HDBs in the area, homeowners might be enticed to buy newer HDB units in the area\n\nApartment Type (eg. DBSS/Standard/Premium)\n\nDesign Build Sell Scheme (DBSS) flats may call for a higher value than regular HDB flats as they are designed, build and sold by 3rd party developers although they are still HDB Flats. They are supposed to be better than premium flats\nPremium flats which come with pre-installed fittings and furnishings over standard apartments which comes with none\nReference: https://www.teoalida.com/singapore/hdbflattypes/\n\nApartment Multi-story (Maisonette or Loft)\n\nSome homeowners may prefer multi-story HDBs over single-story ones\n\n\n\n\n\nProximity to CBD\nProximity to eldercare\nProximity to foodcourt/hawker centres\nProximity to MRT\nProximity to park\nProximity to good primary school\nProximity to shopping mall\nProximity to supermarket\nNumbers of kindergartens within 350m\nNumbers of childcare centres within 350m\nNumbers of bus stop within 350m\nNumbers of primary school within 1km\nProximity to Overhead MRT Line [noise concern] (if <300m)\n\nThe closer a HDB unit is to the MRT track, the home value might be affected due to noise concerns. We measure the proximity of HDB units using its euclidean distance to the closest part of the MRT track if it is less than 300metres away.\n\nNumber of Future MRT stops within 800m (10min walk)\n\nHere, I want to explore how the resale values of HDBs could be affected by future MRT stations that are announced but not yet built. Home owners may be enticed to buy houses near future MRT lines in hopes that the house values will increase and also due to increased connectivity\n\nNumber of LRT Stops within 350m\n\nThe metric is necessary as LRT serves as a feeder within the town and is typically used short-haul vs MRT which is between various towns. The 350m metric is derived from Bus Stops differentiates the weight between a LRT stop and MRT stop especially if the LRT stop is far away from the MRT stop in towns such as Sengkang, Punggol and Pasir Ris"
  },
  {
    "objectID": "exercises/thex03.html#data-preparation-geocoding-data",
    "href": "exercises/thex03.html#data-preparation-geocoding-data",
    "title": "Take-Home Exercise 03: Predicting HDB Public Housing Resale Prices Using Geographically Weighted Methods",
    "section": "2.5 Data Preparation: Geocoding Data",
    "text": "2.5 Data Preparation: Geocoding Data\nSome geospatial data come with addresses in the form of Block Number, Street Name and/or Postal code. However, these attributes are insufficient to plot out the spatial points onto a tmap. Hence, we need to convert these ‘text-based’ addresses into SVY21 Projected Coordinate System to be able to plot and analyse the data.\nBelow, we have written a script in python that takes an excel file and uses the OneMap Search API to parse an address which returns use the X and Y required in SVY21. We save them as a list in X and Y variables before merging them back to the main DataFrame as X and Y columns before reexporting it.\nimport requests\nimport pandas as pd\nimport time\n\nONEMAP = \"https://developers.onemap.sg\"\nINPUT_FILE = \"HDB_HIP-MUP-20230312.xlsx\"\n\nargs = {\"email\": \"<REDACTED>\",\n        \"password\": \"<REDACTED>\"}\nresp = requests.post(\"https://developers.onemap.sg/privateapi/auth/post/getToken\", args)\n\nprint(resp.status_code)\nprint(resp.content)\n\naccess_token = resp.json()[\"access_token\"]\nsearch_url = ONEMAP + \"/commonapi/search\" \n\ndf = pd.read_excel(INPUT_FILE)\n\nmax_rows = len(df)\n            \nx = []\ny = []\nerrors = []\n\nfor i in range (0, max_rows):\n    \n    row_df = df.loc[i]\n    addr = row_df[\"COMBINED_BLK_STREET\"]\n    \n    searchtxt = \"searchVal=\" + addr\n    returngeom = \"&returnGeom=Y\"\n    getaaddr = \"&getAddrDetails=N\"\n    \n    api_url = search_url + \"?\" + searchtxt + returngeom + getaaddr\n    \n    stuff = requests.get(api_url)\n    \n    data = stuff.json()\n    \n    try:\n        x.append(data['results'][0]['X'])\n        y.append(data['results'][0]['Y'])\n    except:\n        x.append(\"Not Found\")\n        y.append(\"Not Found\")\n        erorrs.append(addr)\n\n    time.sleep(0.3)\n\ndf['x'] = x\ndf['y'] = y\n\ndf.to_excel('geocode' + INPUT_FILE)\nNote that when the X or Y values cannot be found for any reason (eg. address not found), Not Found is appended in place, where we can manually fix those values later on.\nAlso note that time.sleep(0.3) is used to reduce the number of API Calls as OneMap restricts a maximum of 250 API Calls per min."
  },
  {
    "objectID": "exercises/thex03.html#importing-aspatial-data",
    "href": "exercises/thex03.html#importing-aspatial-data",
    "title": "Take-Home Exercise 03: Predicting HDB Public Housing Resale Prices Using Geographically Weighted Methods",
    "section": "4.1 Importing Aspatial Data",
    "text": "4.1 Importing Aspatial Data\nIn the various tabs below, we will import each individual dataset from its respective folders, with a brief explanation of the use cases of each dataset.\n\nCHAS ClinicsHDB HIP MUPHDB Resale Flat Pricing\n\n\n\nCHAS_raw = read_xlsx(\"Take-Home_Ex03/aspatial/CHAS.xlsx\") \nglimpse(CHAS_raw)\n\nRows: 1,910\nColumns: 7\n$ Name                   <chr> \"1 Aljunied Medical\", \"1 BISHAN MEDICAL\", \"1 ME…\n$ Address                <chr> \"Singapore 367874\", \"283, Bishan Street, #01- 1…\n$ Postal                 <chr> \"367874\", \"570283\", \"560410\", \"560704\", \"600135…\n$ Telephone              <chr> NA, \"64561600\", \"62517030\", \"96311728\", \"977017…\n$ Type                   <chr> \"Medical\", \"Medical, Cervical\\r\\nCancer Screen\"…\n$ Website                <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ `Pap Test\\r\\nServices` <chr> \"No\", \"Yes\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\"…\n\n\n\n\n\nhdb_hip_mup_raw = read_xlsx(\"Take-Home_Ex03/aspatial/HDB_HIP-MUP-20230312.xlsx\")\nglimpse(hdb_hip_mup_raw)\n\nRows: 2,769\nColumns: 4\n$ BLK    <chr> \"218\", \"219\", \"220\", \"221\", \"222\", \"223\", \"225\", \"226\", \"226B\",…\n$ STREET <chr> \"ANG MO KIO AVE 1\", \"ANG MO KIO AVE 1\", \"ANG MO KIO AVE 1\", \"AN…\n$ TYPE   <chr> \"HIP\", \"HIP\", \"HIP\", \"HIP\", \"HIP\", \"HIP\", \"HIP\", \"HIP\", \"HIP\", …\n$ TOWN   <chr> \"ANG MO KIO\", \"ANG MO KIO\", \"ANG MO KIO\", \"ANG MO KIO\", \"ANG MO…\n\n\n\n\n\nhdb_resale_raw = read_csv(\"Take-Home_Ex03/aspatial/resale-flat-prices-based-on-registration-date-from-jan-2017-onwards.csv\")\nglimpse(hdb_resale_raw)\n\nRows: 148,373\nColumns: 11\n$ month               <chr> \"2017-01\", \"2017-01\", \"2017-01\", \"2017-01\", \"2017-…\n$ town                <chr> \"ANG MO KIO\", \"ANG MO KIO\", \"ANG MO KIO\", \"ANG MO …\n$ flat_type           <chr> \"2 ROOM\", \"3 ROOM\", \"3 ROOM\", \"3 ROOM\", \"3 ROOM\", …\n$ block               <chr> \"406\", \"108\", \"602\", \"465\", \"601\", \"150\", \"447\", \"…\n$ street_name         <chr> \"ANG MO KIO AVE 10\", \"ANG MO KIO AVE 4\", \"ANG MO K…\n$ storey_range        <chr> \"10 TO 12\", \"01 TO 03\", \"01 TO 03\", \"04 TO 06\", \"0…\n$ floor_area_sqm      <dbl> 44, 67, 67, 68, 67, 68, 68, 67, 68, 67, 68, 67, 67…\n$ flat_model          <chr> \"Improved\", \"New Generation\", \"New Generation\", \"N…\n$ lease_commence_date <dbl> 1979, 1978, 1980, 1980, 1980, 1981, 1979, 1976, 19…\n$ remaining_lease     <chr> \"61 years 04 months\", \"60 years 07 months\", \"62 ye…\n$ resale_price        <dbl> 232000, 250000, 262000, 265000, 265000, 275000, 28…"
  },
  {
    "objectID": "exercises/icex09.html",
    "href": "exercises/icex09.html",
    "title": "In-Class Exercise 9: XXX",
    "section": "",
    "text": "Pacman assists us by helping us load R packages that we require, sf, sfdep, tidyverse, plotly and tmap.\n\npacman::p_load(sf, GWmodel, SpatialML, tidyverse, tmap, ggpubr, olsrr, evtools, tidymodels)\n\nWarning: package 'evtools' is not available for this version of R\n\nA version of this package for your version of R might be available elsewhere,\nsee the ideas at\nhttps://cran.r-project.org/doc/manuals/r-patched/R-admin.html#Installing-packages\n\n\nWarning: unable to access index for repository http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/4.2:\n  cannot open URL 'http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/4.2/PACKAGES'\n\n\nWarning: 'BiocManager' not available.  Could not check Bioconductor.\n\nPlease use `install.packages('BiocManager')` and then retry.\n\n\nWarning in p_install(package, character.only = TRUE, ...):\n\n\nWarning in library(package, lib.loc = lib.loc, character.only = TRUE,\nlogical.return = TRUE, : there is no package called 'evtools'\n\n\nWarning in pacman::p_load(sf, GWmodel, SpatialML, tidyverse, tmap, ggpubr, : Failed to install/load:\nevtools\n\n\nPlotly helps to make our charts interactive.\n\n\n\nThe following datasets are used:\n\n\n\nDataset Name\nSource\n\n\n\n\nHunan (Hunan.shp)\nProf Kam\n\n\nHunan 2021 (Hunan-2021.csv)\nProf Kam"
  },
  {
    "objectID": "exercises/icex09.html#reading-data-file-from-rds",
    "href": "exercises/icex09.html#reading-data-file-from-rds",
    "title": "In-Class Exercise 9: XXX",
    "section": "2.1 Reading data file from rds",
    "text": "2.1 Reading data file from rds\n\nmdata <- read_rds(\"In-Class_Ex09/data/aspatial/mdata.rds\")"
  },
  {
    "objectID": "exercises/icex09.html#data-sampling",
    "href": "exercises/icex09.html#data-sampling",
    "title": "In-Class Exercise 9: XXX",
    "section": "2.2 Data Sampling",
    "text": "2.2 Data Sampling\n\nset.seed(1234)\nresale_split <- initial_split(mdata,\n                              prop = 6.5/10)\ntrain_data <- training(resale_split)\ntest_data <- testing(resale_split)\n\n\nwrite_rds(train_data, \"In-Class_Ex09/data/aspatial/train.rds\")\nwrite_rds(test_data, \"In-Class_Ex09/data/aspatial/test.rds\")\n\n\ntrain_data <- read_rds(\"In-Class_Ex09/data/aspatial/train.rds\")\ntest_data <- read_rds(\"In-Class_Ex09/data/aspatial/test.rds\")"
  },
  {
    "objectID": "exercises/icex09.html#building-a-non-spatial-multiple-linear-regression",
    "href": "exercises/icex09.html#building-a-non-spatial-multiple-linear-regression",
    "title": "In-Class Exercise 9: XXX",
    "section": "2.3 Building a non-spatial multiple linear regression",
    "text": "2.3 Building a non-spatial multiple linear regression\n\nprice_mlr <- lm(resale_price ~ floor_area_sqm + storey_order + \n                remaining_lease_mths + PROX_CBD + PROX_ELDERLYCARE + \n                PROX_HAWKER + PROX_MRT + PROX_PARK + PROX_MALL + \n                PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN + \n                WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + \n                WITHIN_1KM_PRISCH , data = train_data)\n\nsummary(price_mlr)\n\n\nCall:\nlm(formula = resale_price ~ floor_area_sqm + storey_order + remaining_lease_mths + \n    PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + PROX_MRT + PROX_PARK + \n    PROX_MALL + PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN + \n    WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + WITHIN_1KM_PRISCH, \n    data = train_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-205193  -39120   -1930   36545  472355 \n\nCoefficients:\n                           Estimate Std. Error t value Pr(>|t|)    \n(Intercept)              107601.073  10601.261  10.150  < 2e-16 ***\nfloor_area_sqm             2780.698     90.579  30.699  < 2e-16 ***\nstorey_order              14299.298    339.115  42.167  < 2e-16 ***\nremaining_lease_mths        344.490      4.592  75.027  < 2e-16 ***\nPROX_CBD                 -16930.196    201.254 -84.124  < 2e-16 ***\nPROX_ELDERLYCARE         -14441.025    994.867 -14.516  < 2e-16 ***\nPROX_HAWKER              -19265.648   1273.597 -15.127  < 2e-16 ***\nPROX_MRT                 -32564.272   1744.232 -18.670  < 2e-16 ***\nPROX_PARK                 -5712.625   1483.885  -3.850 0.000119 ***\nPROX_MALL                -14717.388   2007.818  -7.330 2.47e-13 ***\nPROX_SUPERMARKET         -26881.938   4189.624  -6.416 1.46e-10 ***\nWITHIN_350M_KINDERGARTEN   8520.472    632.812  13.464  < 2e-16 ***\nWITHIN_350M_CHILDCARE     -4510.650    354.015 -12.741  < 2e-16 ***\nWITHIN_350M_BUS             813.493    222.574   3.655 0.000259 ***\nWITHIN_1KM_PRISCH         -8010.834    491.512 -16.298  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 61650 on 10320 degrees of freedom\nMultiple R-squared:  0.7373,    Adjusted R-squared:  0.737 \nF-statistic:  2069 on 14 and 10320 DF,  p-value: < 2.2e-16\n\n\n\nwrite_rds(price_mlr, \"In-Class_Ex09/data/aspatial/price-mlr.rds\")"
  },
  {
    "objectID": "exercises/icex09.html#converting-the-sf-dataframe-to-sptial-point-data-frame",
    "href": "exercises/icex09.html#converting-the-sf-dataframe-to-sptial-point-data-frame",
    "title": "In-Class Exercise 9: XXX",
    "section": "3.1 Converting the sf DataFrame to Sptial Point Data Frame",
    "text": "3.1 Converting the sf DataFrame to Sptial Point Data Frame\n\ntrain_data_sp <- as_Spatial(train_data)\ntrain_data_sp\n\nclass       : SpatialPointsDataFrame \nfeatures    : 10335 \nextent      : 11597.31, 42623.63, 28217.39, 48741.06  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 17\nnames       : resale_price, floor_area_sqm, storey_order, remaining_lease_mths,          PROX_CBD,     PROX_ELDERLYCARE,        PROX_HAWKER,           PROX_MRT,          PROX_PARK,   PROX_GOOD_PRISCH,        PROX_MALL,            PROX_CHAS,     PROX_SUPERMARKET, WITHIN_350M_KINDERGARTEN, WITHIN_350M_CHILDCARE, ... \nmin values  :       218000,             74,            1,                  555, 0.999393538715878, 1.98943787433087e-08, 0.0333358643817954, 0.0220407324774434, 0.0441643212802781, 0.0652540365486641,                0, 6.20621206270077e-09, 1.21715176356525e-07,                        0,                     0, ... \nmax values  :      1186888,            133,           17,                 1164,  19.6500691667807,     3.30163731686804,   2.86763031236184,   2.13060636038504,   2.41313695915468,   10.6223726149914, 2.27100643784442,    0.808332738794272,     1.57131703651196,                        7,                    20, ..."
  },
  {
    "objectID": "exercises/icex09.html#building-adaptive-bandwidth-gwr-model",
    "href": "exercises/icex09.html#building-adaptive-bandwidth-gwr-model",
    "title": "In-Class Exercise 9: XXX",
    "section": "3.2 Building Adaptive Bandwidth GWR Model",
    "text": "3.2 Building Adaptive Bandwidth GWR Model\n\n3.2.1 Computing the adaptive bandwidth\n\nbw.adaptive <- bw.gwr(formula = resale_price ~ floor_area_sqm + storey_order + \n                remaining_lease_mths + PROX_CBD + PROX_ELDERLYCARE + \n                PROX_HAWKER + PROX_MRT + PROX_PARK + PROX_MALL + \n                PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN + \n                WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + \n                WITHIN_1KM_PRISCH, \n                      data=train_data_sp, \n                      approach=\"CV\", \n                      kernel=\"gaussian\", \n                      adaptive=TRUE, \n                      longlat=FALSE)\n\n\n\n3.2.2 Constructing the adaptive bandwidth gwr model\n\ngwr.adaptive <- gwr.basic(formula = resale_price ~ floor_area_sqm + storey_order + \n                remaining_lease_mths + PROX_CBD + PROX_ELDERLYCARE + \n                PROX_HAWKER + PROX_MRT + PROX_PARK + PROX_MALL + \n                PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN + \n                WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + \n                WITHIN_1KM_PRISCH, \n                          data=train_data_sp, bw=bw.adaptive, \n                          kernel = 'gaussian', \n                          adaptive=TRUE, \n                          longlat = FALSE)\n\n\ngwr.adaptive"
  },
  {
    "objectID": "exercises/In-Class_Ex09/data/geospatial/MPSZ-2019.html",
    "href": "exercises/In-Class_Ex09/data/geospatial/MPSZ-2019.html",
    "title": "Ren Jie's IS415 Journal",
    "section": "",
    "text": "<!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’>     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "exercises/Take-Home_Ex03/geospatial/MPSZ-2019.html",
    "href": "exercises/Take-Home_Ex03/geospatial/MPSZ-2019.html",
    "title": "Ren Jie's IS415 Journal",
    "section": "",
    "text": "<!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’>     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "exercises/thex03.html#filtering-hdb-resale-flat-data",
    "href": "exercises/thex03.html#filtering-hdb-resale-flat-data",
    "title": "Take-Home Exercise 03: Predicting HDB Public Housing Resale Prices Using Geographically Weighted Methods",
    "section": "4.2 Filtering HDB Resale Flat Data",
    "text": "4.2 Filtering HDB Resale Flat Data\nWe will now filter the HDB Resale to focus on the target months, Jan 2020 to Feb 2023, and 5 Room HDBs to construct the predictive model. We will use:\n\nfilter() to filter out the desired room type and months\nunique() to check if the desired room type and months has been filtered correctly\nglimpse() to check the data structure of the filtered dataset\n\n\nFilter CodeGlimpse VariablesUnique Month and Flat_Type\n\n\n\nhdb_resale <- filter(hdb_resale_raw, flat_type == \"5 ROOM\") %>%\n              filter(month >= \"2020-01\" & month <= \"2023-02\")\n\n\n\n\nglimpse(hdb_resale)\n\nRows: 21,500\nColumns: 11\n$ month               <chr> \"2020-01\", \"2020-01\", \"2020-01\", \"2020-01\", \"2020-…\n$ town                <chr> \"ANG MO KIO\", \"ANG MO KIO\", \"ANG MO KIO\", \"ANG MO …\n$ flat_type           <chr> \"5 ROOM\", \"5 ROOM\", \"5 ROOM\", \"5 ROOM\", \"5 ROOM\", …\n$ block               <chr> \"439\", \"401\", \"439\", \"458\", \"101\", \"423\", \"501\", \"…\n$ street_name         <chr> \"ANG MO KIO AVE 10\", \"ANG MO KIO AVE 10\", \"ANG MO …\n$ storey_range        <chr> \"01 TO 03\", \"01 TO 03\", \"10 TO 12\", \"16 TO 18\", \"0…\n$ floor_area_sqm      <dbl> 119, 119, 119, 120, 117, 133, 121, 118, 117, 110, …\n$ flat_model          <chr> \"Improved\", \"Improved\", \"Improved\", \"Improved\", \"S…\n$ lease_commence_date <dbl> 1979, 1979, 1979, 1980, 1978, 1993, 1981, 1980, 19…\n$ remaining_lease     <chr> \"58 years 01 month\", \"58 years 04 months\", \"58 yea…\n$ resale_price        <dbl> 485000, 465000, 535000, 580000, 450000, 700000, 53…\n\n\n\n\n\nunique(hdb_resale$month)\n\n [1] \"2020-01\" \"2020-02\" \"2020-03\" \"2020-04\" \"2020-05\" \"2020-06\" \"2020-07\"\n [8] \"2020-08\" \"2020-09\" \"2020-10\" \"2020-11\" \"2020-12\" \"2021-01\" \"2021-02\"\n[15] \"2021-03\" \"2021-04\" \"2021-05\" \"2021-06\" \"2021-07\" \"2021-08\" \"2021-09\"\n[22] \"2021-10\" \"2021-11\" \"2021-12\" \"2022-01\" \"2022-02\" \"2022-03\" \"2022-04\"\n[29] \"2022-05\" \"2022-06\" \"2022-07\" \"2022-08\" \"2022-09\" \"2022-10\" \"2022-11\"\n[36] \"2022-12\" \"2023-01\" \"2023-02\"\n\n\n\nunique(hdb_resale$flat_type)\n\n[1] \"5 ROOM\"\n\n\n\n\n\nFrom the code and results in the respective tabs (Glimpse Variables and Unique Month and Flat Type), we can see that:\n\nThere are 21,500 transactions between Jan 2020 to Feb 2023.\nThe month and flat_type has been extracted correctly."
  },
  {
    "objectID": "exercises/thex03.html#transforming-aspatial-data",
    "href": "exercises/thex03.html#transforming-aspatial-data",
    "title": "Take-Home Exercise 03: Predicting HDB Public Housing Resale Prices Using Geographically Weighted Methods",
    "section": "3.3 Transforming Aspatial Data",
    "text": "3.3 Transforming Aspatial Data\n\n#tmap_mode(\"view\")\n#tm_shape(hdb_resale) +\n#  tm_dots(\"resale_price\",\n#          popup.vars=c(\"month\"=\"month\", \"town\"=\"town\", \"block\" = \"block\", \"street_name\" = \"street_name\"))\n\n\nmpsz = st_read(dsn = \"Take-Home_Ex03/geospatial\", layer=\"MPSZ-2019\")\n\nReading layer `MPSZ-2019' from data source \n  `C:\\renjie-teo\\IS415-GAA\\exercises\\Take-Home_Ex03\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "exercises/thex03.html#transforming-aspatial-data---create-new-columns-with-values",
    "href": "exercises/thex03.html#transforming-aspatial-data---create-new-columns-with-values",
    "title": "Take-Home Exercise 03: Predicting HDB Public Housing Resale Prices Using Geographically Weighted Methods",
    "section": "4.3 Transforming Aspatial Data - Create New Columns with Values",
    "text": "4.3 Transforming Aspatial Data - Create New Columns with Values\nNext, we transform the Aspatial Datasets into more meaningful values:\n\nCHAS Clinics - There is nothing to transform, since as noted earlier, there is already a postal column provided\nHDB HIP MUP - We need to obtain the address for geocoding (obtaining the SVY21 X and Y coordinates) by combining the BLK and STREET fields\nHDB Resale Flat Pricing - We need to obtain the address for geocoding (obtaining the SVY21 X and Y coordinates) by combining the block and street_name fields, and also convert the remaining lease from the form of YY years MM months to a more machine-readable format (ie. MM months)\n\nThe code chunks will assist with the transformation using mutate() further explained below:\n\nHDB HIP MUPHDB Resale Flat Pricing\n\n\nWe mutate() the hdb_hip_mup_raw dataset by pasting the BLK and STREET columns together into the address column to a new sf dataframe called hdb_hip_mup_trans\n\nhdb_hip_mup_trans <- hdb_hip_mup_raw %>%\n  mutate(hdb_hip_mup_raw, address = paste(BLK, STREET))\n\n\n\nWe mutate() the hdb_resale dataset by pasting the block and street_name columns together into the address column to a new variable called hdb_hip_mup_trans. We also used mutate() to modify the existing remaining_lease data to the form of MM.\nThe first section of the code as.integer(str_sub(remaining_lease, 0, 2)) * 12 extracts the year numbers as YY and converts it into string and then multiplying it by 12 to convert it to number of months.\nThe next part of the code checks if there is any numerical MM (month) present, if there is no month present, the value will be NA and 0 will be assigned in place of NA. Else, if present, we take the MM.\nThe integer month is summed with the year in months to form this column remaining_lease_mths in the new sf dataframe hdb_resale_trans\n\nhdb_resale_trans <- hdb_resale %>%\n  mutate(hdb_resale, address = paste(block, street_name)) %>%\n  mutate(hdb_resale, remaining_lease_mths = (as.integer(str_sub(remaining_lease, 0, 2)) * 12 + ifelse(is.na(as.integer(str_sub(remaining_lease, 9, 11))), 0,  as.integer(str_sub(remaining_lease, 9, 11)))))\n\nNext, let us left join the HDB HIP MUP data into HDB Resale Transactions so that we know which HDB units have already completed their upgrading.\n\nhdb_resale_trans <- left_join(hdb_resale_trans, hdb_hip_mup_trans)\nglimpse(hdb_resale_trans)\n\nRows: 21,548\nColumns: 17\n$ month                <chr> \"2020-01\", \"2020-01\", \"2020-01\", \"2020-01\", \"2020…\n$ town                 <chr> \"ANG MO KIO\", \"ANG MO KIO\", \"ANG MO KIO\", \"ANG MO…\n$ flat_type            <chr> \"5 ROOM\", \"5 ROOM\", \"5 ROOM\", \"5 ROOM\", \"5 ROOM\",…\n$ block                <chr> \"439\", \"401\", \"439\", \"458\", \"101\", \"423\", \"501\", …\n$ street_name          <chr> \"ANG MO KIO AVE 10\", \"ANG MO KIO AVE 10\", \"ANG MO…\n$ storey_range         <chr> \"01 TO 03\", \"01 TO 03\", \"10 TO 12\", \"16 TO 18\", \"…\n$ floor_area_sqm       <dbl> 119, 119, 119, 120, 117, 133, 121, 118, 117, 110,…\n$ flat_model           <chr> \"Improved\", \"Improved\", \"Improved\", \"Improved\", \"…\n$ lease_commence_date  <dbl> 1979, 1979, 1979, 1980, 1978, 1993, 1981, 1980, 1…\n$ remaining_lease      <chr> \"58 years 01 month\", \"58 years 04 months\", \"58 ye…\n$ resale_price         <dbl> 485000, 465000, 535000, 580000, 450000, 700000, 5…\n$ address              <chr> \"439 ANG MO KIO AVE 10\", \"401 ANG MO KIO AVE 10\",…\n$ remaining_lease_mths <dbl> 697, 700, 696, 708, 685, 867, 720, 715, 718, 983,…\n$ BLK                  <chr> \"439\", \"401\", \"439\", \"458\", \"101\", \"423\", \"501\", …\n$ STREET               <chr> \"ANG MO KIO AVE 10\", \"ANG MO KIO AVE 10\", \"ANG MO…\n$ TYPE                 <chr> \"HIP\", \"HIP\", \"HIP\", \"MUP\", \"MUP\", \"MUP\", \"HIP\", …\n$ TOWN                 <chr> \"ANG MO KIO\", \"ANG MO KIO\", \"ANG MO KIO\", \"ANG MO…\n\n\nThen we’ll select only the unnecessary columns:\n\nhdb_resale_trans <- hdb_resale_trans %>% select(c(1:13, 16))"
  },
  {
    "objectID": "exercises/thex03.html#retrieving-svy21-coordinate-of-addresses",
    "href": "exercises/thex03.html#retrieving-svy21-coordinate-of-addresses",
    "title": "Take-Home Exercise 03: Predicting HDB Public Housing Resale Prices Using Geographically Weighted Methods",
    "section": "4.4 Retrieving SVY21 Coordinate of Addresses",
    "text": "4.4 Retrieving SVY21 Coordinate of Addresses\nThis section will focus on retrieving relavant data such as coordinates of the address which we could use in further spatial analysis to obtain proximity to locational factors later.\nWe are interested in obtaining the SVY21 X and Y coordinates as they are in the Projected Coordinate System, which allows us to perform measure directly without any additional transformations.\n\n4.4.1 Create a List Storing Unique Addresses/Postal Codes\nSince some addresses/postal codes are duplicated, we store and check unique addresses to reduce the amount of GET requests sent to the OneMap API:\n\nFaster\nOneMap API has a rate limit of 250 API calls a minute\nIt makes it easier for us to locate errors and correct it\n\nHere, we will obtain a list of unique addresses/postal codes for each data set.\n\nCHAS ClinicsHDB Resale Flat Pricing\n\n\n\naddr_lst.chas <- sort(unique(CHAS_raw$Postal))\nglimpse(addr_lst.chas)\n\n chr [1:1128] \"018935\" \"018972\" \"018981\" \"018982\" \"018984\" \"018987\" ...\n\n\n\n\n\naddr_lst.resale <- sort(unique(hdb_resale_trans$address))\nglimpse(addr_lst.resale)\n\n chr [1:4283] \"1 CHAI CHEE RD\" \"1 DELTA AVE\" \"1 EVERTON PK\" \"1 MARINE TER\" ...\n\n\n\n\n\n\n\n4.4.2 Create Function to Retrieve Coordinates from OneMap.sg API\nThe following function uses OneMap.sg Search API to obtain coordinates (SVY21 X, Y) using part of an address or postal code.\nThis is how the function get_coordinates() below will work:\n\nnew_coords datafame is created to store all the new coordinate data and its original address that is input to the GET request API\nfor each addr in addr_lst where addr_lst is the list passed into the function, we will query each record and append accordingly:\n\nIf there is 1 or more records, we append the top record’s SVY21 X, Y coordinates and addr to a temporary dataframe called new_row,\nElse, NA for it’s X and Y columns and the addr is stored in new_row.\n\nThe GET Request has various parameters:\n\nsearchVal - the value to pass to OneMap Search to obtain the Geocode (in this case we are interested in SVY21 X, Y coordinates)\nreturnGeom - return details about geometry (ie. SVY21 X, Y or Lat Lon), Y in this case as we want SVY21 X, Y coordinates\ngetAddrDetails - get more details about the address, N in this case as we don’t require further information.\n\nfromJSON() helps us convert the JSON format to a list format for manipulation\n\nthe function rawToChar() was used as the received type for reply$content is RAW, which requires conversion before we can read the values\n\nLastly, we will combine the new_row data into the main new_coords dataframe using rbind() as they are both dataframes.\n\n\n\nget_coordinates <- function(addr_lst){\n  \n  # Create a data frame to store all retrieved coordinates\n  new_coords <- data.frame()\n    \n  for (addr in addr_lst){\n    #print(i)\n\n    reply <- GET('https://developers.onemap.sg/commonapi/search?',\n           query = list(searchVal = addr,\n                        returnGeom = 'Y',\n                        getAddrDetails = 'N'))\n    \n    output <- fromJSON(rawToChar(reply$content))\n    found <- output$found\n    res <- output$results\n    \n    # Create a new data frame for each address\n    new_row <- data.frame()\n    \n    # If single result, append \n    if (found >= 1){\n      res_1 <- head(res, n = 1)\n      x <- res_1$X\n      y <- res_1$Y\n      new_row <- data.frame(address = addr, x = x, y = y)\n    }\n\n    else {\n      new_row <- data.frame(address = addr, x = NA, y = NA)\n    }\n    \n    # Add the row\n    new_coords <- rbind(new_coords, new_row)\n  }\n  return(new_coords)\n}\n\n\n\n\n4.4.3 Call get_coordinates() Function to Obtain Coordinates\nWe use get_coordinates() function created earlier to obtain the coordinates of the address. glimpse() allows us to view and check if the data has been properly created.\nRDS Scripts contains scripts to import/export the coordinates R objects to RDS file format (R Data Serialisation) prevent having to call the API each time on every render.\n\nget_coordinates() FunctionRDS ScriptsGlimpse Records\n\n\nCHAS Clinics\n\ncoords_chas <- get_coordinates(addr_lst.chas)\n\nHDB Resale Flat Pricing\n\ncoords_resale <- get_coordinates(addr_lst.resale)\n\n\n\nWriting RDS\n\nwrite_rds(coords_chas, \"Take-Home_Ex03/rds/coords_chas.rds\")\nwrite_rds(coords_resale, \"Take-Home_Ex03/rds/coords_resale.rds\")\n\nReading RDS\n\ncoords_chas <- read_rds(\"Take-Home_Ex03/rds/coords_chas.rds\")\ncoords_resale <- read_rds(\"Take-Home_Ex03/rds/coords_resale.rds\")\n\n\n\nCHAS Clinics\n\nglimpse(coords_chas)\n\nRows: 1,128\nColumns: 3\n$ address <chr> \"018935\", \"018972\", \"018981\", \"018982\", \"018984\", \"018987\", \"0…\n$ x       <chr> \"30173.1125663621\", \"30856.1576845003\", \"30325.5481859585\", \"3…\n$ y       <chr> \"28870.8731260244\", \"29629.71109147\", \"29166.1214467622\", \"290…\n\n\nHDB Resale Flat Pricing\n\nglimpse(coords_resale)\n\nRows: 4,283\nColumns: 3\n$ address <chr> \"1 CHAI CHEE RD\", \"1 DELTA AVE\", \"1 EVERTON PK\", \"1 MARINE TER…\n$ x       <chr> \"37949.0264732633\", \"27473.0907973954\", \"28899.2285061181\", \"3…\n$ y       <chr> \"34465.7385691088\", \"30496.6361175738\", \"28663.7158067878\", \"3…"
  },
  {
    "objectID": "exercises/thex03.html#section-1",
    "href": "exercises/thex03.html#section-1",
    "title": "Take-Home Exercise 03: Predicting HDB Public Housing Resale Prices Using Geographically Weighted Methods",
    "section": "3.5 ",
    "text": "3.5 \n\n#tmap_mode(\"view\")\n#tm_shape(hdb_resale) +\n#  tm_dots(\"resale_price\",\n#          popup.vars=c(\"month\"=\"month\", \"town\"=\"town\", \"block\" = \"block\", \"street_name\" = \"street_name\"))\n\n\nmpsz = st_read(dsn = \"Take-Home_Ex03/geospatial\", layer=\"MPSZ-2019\")\n\nReading layer `MPSZ-2019' from data source \n  `C:\\renjie-teo\\IS415-GAA\\exercises\\Take-Home_Ex03\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "exercises/thex03.html#data-verification-for-coordinate-data",
    "href": "exercises/thex03.html#data-verification-for-coordinate-data",
    "title": "Take-Home Exercise 03: Predicting HDB Public Housing Resale Prices Using Geographically Weighted Methods",
    "section": "4.5 Data Verification for Coordinate Data",
    "text": "4.5 Data Verification for Coordinate Data\nWith the retrieved data, we need to inspect and verify the data received and correct any errors made along the way. We will do all the steps in parallel for each dataset, outlined in step format below:\n\nMerge coordinate data and original dataframe\n\nWe do this as the CHAS Clinics coordinates are derived from Postal Code and it might be hard to figure out which place are we looking at by looking at just the postal code\n\nCheck for NA X/Y values and manually amend if required\nConvert DataFrame into a sf Object\nPlot a tmap and check if points are plotted in the correct regions\n\nAt any step if there are issues, we will detail steps to fix or recover from it.\n\n4.5.1 CHAS Clinics\n\nMerge Coordinate Data and Original Dataframe\n\ntemp_chas <- left_join(CHAS_raw, coords_chas, by=c(\"Postal\" = \"address\"))\n\nCheck for NA X/Y values and manually amend if required\n\nfilter(temp_chas, is.na(x) == TRUE)\n\n# A tibble: 8 × 9\n  Name                  Address Postal Telep…¹ Type  Website Pap T…² x     y    \n  <chr>                 <chr>   <chr>  <chr>   <chr> <chr>   <chr>   <chr> <chr>\n1 \"Atlantic Dental Sur… \"189, … 188332 633871… Dent… <NA>    No      <NA>  <NA> \n2 \"DA CLINIC @ TAMAN\\r… \"140, … 610410 695410… Medi… <NA>    No      <NA>  <NA> \n3 \"International Denta… \"6, Ge… 69249  637200… Dent… <NA>    No      <NA>  <NA> \n4 \"Lifecare Family Cli… \"102, … 760102 675804… Medi… <NA>    No      <NA>  <NA> \n5 \"Lok Dentist\"         \"34, C… 089673 622501… Dent… <NA>    No      <NA>  <NA> \n6 \"People's Dental Sur… \"1, Ro… 180001 629276… Dent… <NA>    No      <NA>  <NA> \n7 \"Raffles Medical (Ou… \"51, T… 529684 631121… Medi… <NA>    No      <NA>  <NA> \n8 \"Unity Denticare (GS… \"50, M… 048940 659044… Dent… <NA>    No      <NA>  <NA> \n# … with abbreviated variable names ¹​Telephone, ²​`Pap Test\\r\\nServices`\n\n\nHere, using filter() and is.na(), we find out which records do not have a valid location assigned to it. Now, let us manually check through the records and fix the issue.\n\n\n\n\n\n\n\nCHAS Clinic Address\nIssue\n\n\n\n\n189, Selegie Road, Selegie Centre, #01- 05, Singapore 188332\nNo longer exists based on Onemap and Google Map, we will remove it\n\n\n140, Corporation Drive, #01- 03\nPostal Code number 610140 according to OneMap, we will amend accordingly\n\n\n6, Gemmill Lane\nPostal Code number 069249 according to OneMap, we will amend accordingly\n\n\n102, Yishun Avenue 5, #01- 133, Singapore\\r\\n760102\nNo longer exists based on Onemap and Google Map, we will remove it\n\n\n34, Craig Road, Chinatown Plaza, #01- 04,\\r\\nSingapore 089673\nNo longer exists based on Onemap and Google Map, we will remove it\n\n\n1, Rochor Road, Rochor Centre, #03- 516,\\r\\nSingapore 180001\nNo longer exists based on Onemap and Google Map, we will remove it\n\n\n51, TAMPINES AVENUE 4, OUR TAMPINES\\r\\nHUB, #B1- 04/05\nRecords are appended as 528523 on OneMap, we will amend accordingly\n\n\n50, Market Street, Golden Shoe Car Park,\\r\\n#01- 30, Singapore 048940\nNo longer exists based on OneMap and Google Map, we will remove it\n\n\n\nNow, let us update\n\n1. Update Records2. Rerun get_coordinates()3. Combine DataFrame and verify\n\n\nWe remove the clinics that are non-existent using filter()\n\nchas_updated <- filter(CHAS_raw, !Address %in%\n  c(\"189, Selegie Road, Selegie Centre, #01- 05,\\r\\nSingapore 188332\",\n    \"102, Yishun Avenue 5, #01- 133, Singapore\\r\\n760102\",\n    \"34, Craig Road, Chinatown Plaza, #01- 04,\\r\\nSingapore 089673\",\n    \"1, Rochor Road, Rochor Centre, #03- 516,\\r\\nSingapore 180001\",\n    \"50, Market Street, Golden Shoe Car Park,\\r\\n#01- 30, Singapore 048940\"))\n\nNext, we use mutate() and ifelse() condition to update the Postal Codes of the clinics at the relavant addresses.\n\nchas_updated <- chas_updated %>% \n  mutate(Postal = ifelse(Address == \"140, Corporation Drive, #01- 03\", \"610140\", Postal)) %>%\n  mutate(Postal = ifelse(Address == \"6, Gemmill Lane\", \"069249\", Postal)) %>%\n  mutate(Postal = ifelse(Address == \"51, TAMPINES AVENUE 4, OUR TAMPINES\\r\\nHUB, #B1- 04/05\", \"528523\", Postal))\n\nLastly, we regenerate the list of unique Postal Codes to be geocoded.\n\naddr_lst.chas_upd <- sort(unique(chas_updated$Postal))\nglimpse(addr_lst.chas_upd)\n\n chr [1:1122] \"018935\" \"018972\" \"018981\" \"018982\" \"018984\" \"018987\" ...\n\n\n\n\nWe get the SVY21 X,Y coordinates using our get_coordinates() function\n\ncoords_chas_upd <- get_coordinates(addr_lst.chas_upd)\n\nSaving the DataFrame as .rds for future use to prevent rerunning get_coordinates() GET API everytime a render is run\n\nwrite_rds(coords_chas_upd, \"Take-Home_Ex03/rds/coords_chas_upd.rds\")\n\nLoad the DataFrame from .rds\n\ncoords_chas_upd <- read_rds(\"Take-Home_Ex03/rds/coords_chas_upd.rds\")\n\n\n\nWe left join the chas_updated main table and coordinates and filter the x column for any null values\n\ntemp_chas <- left_join(chas_updated, coords_chas_upd, by=c(\"Postal\" = \"address\"))\nfilter(temp_chas, is.na(x) == TRUE)\n\n# A tibble: 0 × 9\n# … with 9 variables: Name <chr>, Address <chr>, Postal <chr>, Telephone <chr>,\n#   Type <chr>, Website <chr>, Pap Test\nServices <chr>, x <chr>, y <chr>\n\n\nNo null values found, we have completed this step!\n\n\n\nConvert a DataFrame into a sf Object\nWe specify the SVY21 X and Y coordinates to be used as the coordinate geometry. The crs specified is 3414 which refers to SVY21.\n\nchas_sf <- st_as_sf(temp_chas,\n                        coords = c(\"x\", \"y\"),\n                        crs = 3414)\n\nPlot a tmap and check if points are plotted in the correct regions\nNow, we will plot an interactive tmap to check if our points are correct.\n\ntmap_mode(\"view\")\ntm_shape(chas_sf) +\n  tm_dots(\"Type\",\n          popup.vars=c(\"Name\"=\"Name\", \"Address\"=\"Address\", \"Type\" = \"Type\", \"Telephone\" = \"Telephone\"))\n\n\n\n\n\n\nFrom our analysis, the points looks to be correctly located.\n\n\n\n4.5.2 HDB Resale Flat Pricing\n\nMerge Coordinate Data and Original Dataframe\n\ntemp_hdb_resale_trans <- left_join(hdb_resale_trans, coords_resale, by=c(\"address\" = \"address\"))\n\nCheck for NA X/Y values and manually amend if required\n\nfilter(temp_hdb_resale_trans, is.na(x) == TRUE)\n\n# A tibble: 0 × 16\n# … with 16 variables: month <chr>, town <chr>, flat_type <chr>, block <chr>,\n#   street_name <chr>, storey_range <chr>, floor_area_sqm <dbl>,\n#   flat_model <chr>, lease_commence_date <dbl>, remaining_lease <chr>,\n#   resale_price <dbl>, address <chr>, remaining_lease_mths <dbl>, TYPE <chr>,\n#   x <chr>, y <chr>\n\n\nNo NA values, great!\nConvert a DataFrame into a sf Object\nWe specify the SVY21 X and Y coordinates to be used as the coordinate geometry. The crs specified is 3414 which refers to SVY21.\n\nhdb_resale_sf <- st_as_sf(temp_hdb_resale_trans,\n                        coords = c(\"x\", \"y\"),\n                        crs = 3414)\n\nPlot a tmap and check if points are plotted in the correct regions\nNow, we will plot an interactive tmap to check if our points are correct. We overlay the URA Master Plan Regions for a quick overlay to roughly check if the HDBs are located in the correct areas. Do note that HDB Towns differ from URA Planning Areas.\n\ntmap_mode(\"view\")\ntmap_options(check.and.fix = TRUE)\ntm_shape(mpsz) +\n  tm_polygons(\"REGION_N\",\n              alpha = 0.5) +\ntm_shape(hdb_resale_sf) +\n  tm_dots(\"town\",\n          popup.vars=c(\"block\"=\"block\", \"street_name\"=\"street_name\", \"flat_model\" = \"flat_model\", \"town\" = \"town\", \"resale_price\" = \"resale_price\", \"remaining_lease_mths\", \"remaining_lease_mths\"))\n\n\n\n\n\n\nOddly, 27 Marine Cres appeared as a point on Sembcorp Marine Tuas Crescent and 54 Kent Rd somehow appeared on 54J SOUTH BUONA VISTA ROAD KENT RIDGE HILL RESIDENCES. There are also some other differences, so let us now recode some of the addresses to get them to the right locations:\n\n1. Update Records2. Rerun get_coordinates()3. Combine DataFrame and verify4. Convert a DataFrame into a sf Object5. Plot a tmap and check if points are plotted in the correct regions\n\n\nWe use mutate() to replace the existing addresses with more specific ones that we found on OneMap.\n\nmod_hdb_resale_trans <- hdb_resale_trans %>% \n  mutate(address = ifelse(address == \"10 JLN BATU\", \"10 JALAN BATU DI TANJONG RHU\", address)) %>%\n  mutate(address = ifelse(address == \"11 JLN BATU\", \"11 JALAN BATU DI TANJONG RHU\", address)) %>%     \n  mutate(address = ifelse(address == \"54 KENT RD\", \"54 KENT ROAD KENT VILLE\", address)) %>%    \n  mutate(address = ifelse(address == \"27 MARINE CRES\", \"27 MARINE CRESCENT MARINE CRESCENT VILLE\", address))\n\n\ntemp_hdb_resale_trans <- left_join(mod_hdb_resale_trans, coords_resale, by=c(\"address\" = \"address\"))\n\nLastly, we regenerate the list of unique Postal Codes to be geocoded.\n\naddr_lst.resale_upd <- sort(unique(mod_hdb_resale_trans$address))\nglimpse(addr_lst.resale_upd)\n\n chr [1:4283] \"1 CHAI CHEE RD\" \"1 DELTA AVE\" \"1 EVERTON PK\" \"1 MARINE TER\" ...\n\n\n\n\nWe get the SVY21 X,Y coordinates using our get_coordinates() function\n\ncoords_resale_upd <- get_coordinates(addr_lst.resale_upd)\n\nSaving the DataFrame as .rds for future use to prevent rerunning get_coordinates() GET API everytime a render is run\n\nwrite_rds(coords_resale_upd, \"Take-Home_Ex03/rds/coords_resale_upd.rds\")\n\nLoad the DataFrame from .rds\n\ncoords_resale_upd <- read_rds(\"Take-Home_Ex03/rds/coords_resale_upd.rds\")\n\n\n\nWe left join the hdb_hip_mup_trans_upd main table and coordinates and filter the x column for any null values\n\ntemp_hdb_resale_trans <- left_join(mod_hdb_resale_trans, coords_resale_upd, by=c(\"address\" = \"address\"))\nfilter(temp_hdb_resale_trans, is.na(x) == TRUE)\n\n# A tibble: 0 × 16\n# … with 16 variables: month <chr>, town <chr>, flat_type <chr>, block <chr>,\n#   street_name <chr>, storey_range <chr>, floor_area_sqm <dbl>,\n#   flat_model <chr>, lease_commence_date <dbl>, remaining_lease <chr>,\n#   resale_price <dbl>, address <chr>, remaining_lease_mths <dbl>, TYPE <chr>,\n#   x <chr>, y <chr>\n\n\nNo null values found, we have completed this step!\n\n\n\nhdb_resale_sf <- st_as_sf(temp_hdb_resale_trans,\n                        coords = c(\"x\", \"y\"),\n                        crs = 3414)\n\n\n\n\ntmap_mode(\"view\")\ntmap_options(check.and.fix = TRUE)\ntm_shape(mpsz) +\n  tm_polygons(\"REGION_N\",\n              alpha = 0.5) +\ntm_shape(hdb_resale_sf) +\n  tm_dots(\"town\",\n          popup.vars=c(\"block\"=\"block\", \"street_name\"=\"street_name\", \"flat_model\" = \"flat_model\", \"town\" = \"town\", \"resale_price\" = \"resale_price\", \"remaining_lease_mths\", \"remaining_lease_mths\"))\n\n\n\n\n\n\n\n\n\n\n\n#tmap_mode(\"view\")\n#tm_shape(hdb_resale) +\n#  tm_dots(\"resale_price\",\n#          popup.vars=c(\"month\"=\"month\", \"town\"=\"town\", \"block\" = \"block\", \"street_name\" = \"street_name\"))"
  },
  {
    "objectID": "exercises/thex03.html#importing-master-plan-subzone-2019",
    "href": "exercises/thex03.html#importing-master-plan-subzone-2019",
    "title": "Take-Home Exercise 03: Predicting HDB Public Housing Resale Prices Using Geographically Weighted Methods",
    "section": "3.1 Importing Master Plan Subzone 2019",
    "text": "3.1 Importing Master Plan Subzone 2019\n\nmpsz = st_read(dsn = \"Take-Home_Ex03/geospatial\", layer=\"MPSZ-2019\")\n\nReading layer `MPSZ-2019' from data source \n  `C:\\renjie-teo\\IS415-GAA\\exercises\\Take-Home_Ex03\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "exercises/thex03.html#transforming-master-plan-subzone-2019",
    "href": "exercises/thex03.html#transforming-master-plan-subzone-2019",
    "title": "Take-Home Exercise 03: Predicting HDB Public Housing Resale Prices Using Geographically Weighted Methods",
    "section": "3.2 Transforming Master Plan Subzone 2019",
    "text": "3.2 Transforming Master Plan Subzone 2019\n\nmpsz <- st_transform(mpsz,3414)"
  }
]